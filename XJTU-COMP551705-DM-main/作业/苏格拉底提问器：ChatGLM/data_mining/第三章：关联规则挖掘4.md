ANJIA0TO UNIVERSITY 西安交通大學


![](https://web-api.textin.com/ocr_image/external/e4454a611ca0f6fd.jpg)

XI'AN JIAOTONG UNIVERSITY

## 数据挖掘

## 第三章：关联规则挖掘

刘均

陕西省天地网技术重点实验室

西安交通大学计算机学院

1 关联规则挖掘的基本概念


![](https://web-api.textin.com/ocr_image/external/501fe24fd2f88907.jpg)

2 由事务数据库挖掘单维布尔关联规则

3 多层关联规则挖掘


![](https://web-api.textin.com/ocr_image/external/a1ef52a0b4da9a14.jpg)

4 多维关联规则挖掘


![](https://web-api.textin.com/ocr_image/external/59cccbb3eb9aafb1.jpg)

5 关联规则、相关性、因果关系的区别

基本要求：掌握关联规则、多层关联规则、多维关联规则的基本概念，掌握各种关联规则挖掘的算法

## 本章内容

3.1 关联规则挖掘的基本概念

3.2 由事务数据库挖掘单维布尔关联规则

3.3 多层关联规则挖掘

3.4 多维关联规则挖掘

3.5 关联规则、相关性、因果关系的区别

西安交通大學


![](https://web-api.textin.com/ocr_image/external/e17f4a47d0ebf3ef.jpg)

XIAN JAOIOSG ENIVIRSITY

### 3.1 基本概念

## 关联规则挖掘：从事务数据库中发现项集之间有趣的关联.

应用： 购物篮分析（Basket data analysis）、交叉营销（cross-marketing）、产品目录设计（catalog design）等

## 例子：

规则形式：“Body → Head ［support， confidence］”.

buys(x,“diapers”)→ buys(x, “beers” ) [0.5%, 60%]

major(x,“CS”)^takes(x,“DB”)→ grade(x, “A”)[1%,75%]

西安交通大學


![](https://web-api.textin.com/ocr_image/external/d86e093baf020d68.jpg)

XIAN JAOIOSG ENIVIRSITY

## 3.1 基本概念

### 布尔型与数值型关联规则（基于要处理的数据类型）

buys(x, “SQLServer”) ^ buys(x, “DMBook”)→buys(x, “DBMiner”)[0.2%,60%]

age(x, “30..39”) ^income(x, “42..48K”)→buys(x,“PC”)[1%,75%]

## 单维与多维关联规则

## 单层与多层关联规则

What brands of beers are associated with what brands of diapers?

西安交通大學

xIAN JAOIOSG ENIVIRSITY

### 3.1 基本概念

# 规则度量：支持度和置信度

<table border="1" ><tr>
<td colspan="1" rowspan="1">Customerbuys bothCustomerbuysdiaperCustomerbuys beer</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">TID</td>
<td colspan="1" rowspan="1">Item</td>
</tr><tr>
<td colspan="1" rowspan="1">2000</td>
<td colspan="1" rowspan="1">A,B,C</td>
</tr><tr>
<td colspan="1" rowspan="1">1000</td>
<td colspan="1" rowspan="1">A,C</td>
</tr><tr>
<td colspan="1" rowspan="1">4000</td>
<td colspan="1" rowspan="1">A,D</td>
</tr><tr>
<td colspan="1" rowspan="1">5000</td>
<td colspan="1" rowspan="1">B,E,F</td>
</tr></table>

支持度s是指事务集D 中包含AuB的百分比

Support(A→B)=P(A)B)


![](https://web-api.textin.com/ocr_image/external/8bf96716ef326bea.jpg)

置信度c是指D中包含A的事务同时也包含B的百分比

·Confidence(A → B)=P(B|A)

=P(Au B)/P(A)

A→C? C→A?

西安交通大學


![](https://web-api.textin.com/ocr_image/external/56325b24d33d2a53.jpg)

XIAN JAOIOSG ENIIRSITY

## 3.1 基本概念

# 规则度量：支持度和置信度

Shirt→ Tie (support = 13.5% and confidence = 70%).

<!-- Confidence When a customer buys a shirt, in 70% of cases, he or she will also buy a tie! We find this happens in 13.5% of all purchases. Support  -->
![](https://web-api.textin.com/ocr_image/external/145f019952c65f9f.jpg)

设最小支持度阈值为50％，最小置信度阈值为50％，则有如下规则

·A → C (50%, 66.6%)

·C→A(50%,100%)

同时满足最小支持度阈值和最小置信度阈值的规则称作强规则

西安交通大學


![](https://web-api.textin.com/ocr_image/external/5168ccccaf51bfa4.jpg)

XIAN JAOIOSG ENIVIRSITY

## 3.1 基本概念

# 关联规则的形式化表示

Let /= {/, 12, '"·, i} be a set of items. Let D be a set of transactions, where each transaction Tis a set of items such that Tc/.

A transaction T contains X, a set of some items in /, if X c T.

An association rule is an implication of the form X→ Y,where Xcl,Yc /, and Xn Y=ø.

X→ Yholds in the transaction set Dwith confidence c if c% of transactions in D that contain Xalso contain Y.

X→Yhas supports% in the transaction set Dif s% of transactions in D contain Xu Y.

西安交通大學


![](https://web-api.textin.com/ocr_image/external/a58653b81d0a8e99.jpg)

XIAN JAOIOSG ENIVIESITY

## 3.1 基本概念

### 事务数据：商场购物数据

### Market basket transactions:

t1: {bread, cheese, milk}

t2: {apple, eggs, salt, yogurt}

tn: {biscuit, eggs, milk}

### Concepts:

An item: an item/article in a basket

/: the set of all items sold in the store

A transaction: items purchased in a basket; it may have TID (transaction ID)

A transactional dataset: A set of transactions

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1c646047df4e3e2f.jpg)

XIAN JAOIOSGENIVIRSITY

## 3.1 基本概念

# 事务数据：文档数据集


![](https://web-api.textin.com/ocr_image/external/c3cfce687d32cad8.jpg)

## ✓每个文档都可以看作一个词袋（ bag of words）

doc1: Student, Teach,School

doc2: Student, School

doc3: Teach, School, City, Game

doc4: Baseball,Basketball

doc5: Basketball, Player, Spectator

doc6: Baseball, Coach, Game,Team

doc7: Basketball,Team, City,Game

雨安交通大學


![](https://web-api.textin.com/ocr_image/external/fc0f55da73eaa53d.jpg)

XIAN JAOIOSG ENIVIRSITY

## 本章内容

3.1 关联规则挖掘的基本概念

3.2 由事务数据库挖掘单维布尔关联规则

3.3 多层关联规则挖掘

3.4 多维关联规则挖掘

3.5 关联规则、相关性、因果关系的区别

西安交通大學


![](https://web-api.textin.com/ocr_image/external/55703490c988762f.jpg)

XIAN JAOIOSG ENIVIRSITY

### 3.2由事务数据库挖掘布尔关联规则

## 关联规则挖掘的原始算法：枚举每个可能的规则，

## 计算其支持度与置信度。

# 包含d个项目的数据集中可能的规则数目为

$R = 3 ^ { d } - 2 ^ { d + 1 } + 1$

$R = \sum _ { k = 1 } ^ { d - 1 } [ ( \begin{matrix} d \\ k ] { k } ) \times \sum _ { j = 1 } ^ { d - k } [ \frac { d - k } { j } ]$

<!-- 6 \times 1 0 ^ { 4 } 5 seln능o1eCunN 4 3 2 1 02 3 4 5 6 7 8 9 10 d  -->
![](https://web-api.textin.com/ocr_image/external/d5e7d90deb399c3b.jpg)

$= 3 ^ { d } - 2 ^ { d + 1 } + 1$

lfd=6,R=602 rules

西安交通大學


![](https://web-api.textin.com/ocr_image/external/b0f52c1378ec3425.jpg)

XIAN HAO1NGUNIVIESSIEY

## 3.2由事务数据库挖掘布尔关联规则

### 频繁项集性质

向下封闭性质（Downward closure）：频繁项集的任意子集都是频繁的

·如果 ｛beer， diaper， nuts｝ 是频繁的， 则 ｛beer， diaper｝也是频繁的

· 任何含有 ｛beer， diaper， nuts｝ 的事务数据也包含｛beer，diaper}

Apriori 修剪原理：非频繁项集的任意超集都是非频繁的，无需生成与测试

西安交通大學


![](https://web-api.textin.com/ocr_image/external/c60459d345f20877.jpg)

XIAN JAOIOSG LNIVIRSITY

## 3.2由事务数据库挖掘布尔关联规则

<!-- null A B C D E AB AC AD AE BC BD BE CD CE DE Found to be Infrequent ABC ABD ABE ACD ACE ADE BCD BCE BDE CDE ABCD ABCE ABDE ACDE BCDE Pruned supersets ABCDE  -->
![](https://web-api.textin.com/ocr_image/external/4ab5aac5e71dd2ab.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1d5f2dfc1add5fa0.jpg)

XIAN JAOIOSG ENIIRSITY

## 3.2由事务数据库挖掘布尔关联规则


![](https://web-api.textin.com/ocr_image/external/d7e936db314346a0.jpg)

A long pattern contains a combinatorial number of sub-patterns, e.g., {a1, ", a1oo} contains$( 1 0 0 ^ { 1 ) + ( 1 0 0 ^ { 2 )$)+⋯(10000)=2100-1 = 1.27*1030 sub-patterns!

Solution: Mine closed patterns and max-patterns instead

An itemset X is closed if X is frequent and there exists no super-pattern YaX,with the same support as X

An itemset X is a max-pattern if X is frequent and there exists no frequent super-pattern Y= X

Closed pattern is a lossless compression of freq. patterns

西安交通大學

XIAN JIADIOSG LNIVEESIIY

## 3.2由事务数据库挖掘布尔关联规则

### Closed Patterns and Max-Patterns

a maximal itemset is a closed itemset but a closed itemset is not necessarily a maximal itemset.

<!-- Frequent Itemsets Closed Frequent Itemsets Maximal Frequent Itemsets  -->
![](https://web-api.textin.com/ocr_image/external/01e97b274447ae55.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/400f08b11c3b38fd.jpg)

XIAN JAOIOSG ENIVIRSITY

## 3.2由事务数据库挖掘布尔关联规则

### Closed Patterns and Max-Patterns

Exercise.$D B = \{ < a _ { 1 } ,$""", a100&gt;,&lt;a1,""",$, a _ { 5 0 } > \}$

Min_sup = 1.

## What is the set of closed itemset?

&lt;a1, """, a100&gt;: ?

$< a _ { 1 } ,$·"", a5o&gt;:?

&lt; a1, "", a49&gt;:

What is the set of max-pattern?

&lt;a1, """, a1oo&gt;:?

What is the set of all patterns?

!!

西安交通大學


![](https://web-api.textin.com/ocr_image/external/710e3d09454bb3d8.jpg)

XIAN JAOIOSG ENIVIESITY

### 3.2由事务数据库挖掘布尔关联规则


![](https://web-api.textin.com/ocr_image/external/50cf303a3bae4c83.jpg)

#### Apriori算法

Ck:候选 k-项集

Lk:频繁k-项集


![](https://web-api.textin.com/ocr_image/external/f34a2df1f781a0d0.jpg)


![](https://web-api.textin.com/ocr_image/external/c33e4b706b8256bf.jpg)

Join 阶段：Ck由Lk-1链接而成


![](https://web-api.textin.com/ocr_image/external/cecc5e0c05fdc7f6.jpg)

Prune阶段：任何包含非频繁的（k-1）-项集都不可能是频繁的k-项集

西安交通大學


![](https://web-api.textin.com/ocr_image/external/4490e12be487dc60.jpg)

XIAN JAOIOSG ENIVIRSITY

##### 3.2由事务数据库挖掘布尔关联规则


![](https://web-api.textin.com/ocr_image/external/67e1bc860c038300.jpg)

###### Apriori算法

1) L1 = {large 1-itemsets};

2) for$( k = 2 ; L _ { k - 1 } \neq \varnothing ;$k++1do begin

3) $C _ { k } = a p$ $\pi i o r i - g e n ( L _ { k - 1 } ) ;$ // New candidates

4) forall transactions t E D do begin

5) $C _ { t } = \sup b \sec t / C _ { k } ,$t);//Caniontained in t

6) forall candidates c e C do

7) c.count++;

8) end

9) $L _ { k } = \{ c$c∈C|c.count ≥ minsup}

10) end

11) $A n s w e r = U _ { k } L _ { k } ;$

西安交通大學


![](https://web-api.textin.com/ocr_image/external/4beb83007766a3c4.jpg)

XIAN JAOIOSG ENIVIRSITY

###### 3.2由事务数据库挖掘布尔关联规则

###### Apriori候选集生成


![](https://web-api.textin.com/ocr_image/external/a9f564cb39e80b85.jpg)

apriori-gen 函数以所有的（k-1）项集的集合$L _ { k - 1 }$为输入，返回所有k-项集的集合Ck.

首先，在join 阶段：

insert into Ck

select p.item,, p.item2, ""·, p.itemk-1,q.itemk-1

from Lk-1P,,Lk-19

where p.item, = q.item,, ···, p.itemk-2 = q.itemk-2,p.itemk-1&lt;q.itemk-1

其次，在 prune 阶段，删除所有的满足（k- 1）子集不在$L _ { k 1 }$的项集ceCk：

forall itemsets$C \in C _ { k } d O$

forall (k - 1)-subsets s of c do

计(f(s∉)SLK1) then

delete c from Ck

西安交通大學


![](https://web-api.textin.com/ocr_image/external/5168ccccaf51bfa4.jpg)

XIAN JAOIOSG ENIVIESITY

###### 3.2由事务数据库挖掘布尔关联规则

L3= {abc, abd, acd, ace, bcd}

Self-joining: L3*L3

abcd from abc and abd

. acde from acd and ace

# Pruning:

acde is removed because ade is not in L3

C{abcd}

西安交通大學

XIAN JAOIOSG ENIVIRSITY

## 3.2由事务数据库挖掘布尔关联规则


![](https://web-api.textin.com/ocr_image/external/a01efd2abfbc6dca.jpg)

### Apriori算法举例

Database D L1C1

<table border="1" ><tr>
<td colspan="1" rowspan="1">itemset</td>
<td colspan="1" rowspan="1">sup.</td>
</tr><tr>
<td colspan="1" rowspan="1">{1}</td>
<td colspan="1" rowspan="1">2</td>
</tr><tr>
<td colspan="1" rowspan="1">{2}</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">{3}</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">{5}</td>
<td colspan="1" rowspan="1">3</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">itemset</td>
<td colspan="1" rowspan="1">sup</td>
</tr><tr>
<td colspan="1" rowspan="1">{1}</td>
<td colspan="1" rowspan="1">2</td>
</tr><tr>
<td colspan="1" rowspan="1">{2}</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">{3}</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">{4}</td>
<td colspan="1" rowspan="1">1</td>
</tr><tr>
<td colspan="1" rowspan="1">{5}</td>
<td colspan="1" rowspan="1">3</td>
</tr></table>

Scan D

<table border="1" ><tr>
<td colspan="1" rowspan="1">TID</td>
<td colspan="1" rowspan="1">Items</td>
</tr><tr>
<td colspan="1" rowspan="1">100<br>200<br>300<br>400</td>
<td colspan="1" rowspan="1">134<br>235<br>1235<br>25</td>
</tr></table>


![](https://web-api.textin.com/ocr_image/external/df766ea6e1a40726.jpg)

C2 C2

L2

Scan D

<table border="1" ><tr>
<td colspan="1" rowspan="1">itemset</td>
</tr><tr>
<td colspan="1" rowspan="1">{1 2}</td>
</tr><tr>
<td colspan="1" rowspan="1">{1 3}</td>
</tr><tr>
<td colspan="1" rowspan="1">{1 5}2 3</td>
</tr><tr>
<td colspan="1" rowspan="1">{}{2 5}</td>
</tr><tr>
<td colspan="1" rowspan="1">{3 5}</td>
</tr></table>


![](https://web-api.textin.com/ocr_image/external/82588900891ca29e.jpg)

<table border="1" ><tr>
<td colspan="1" rowspan="1">itemset</td>
<td colspan="1" rowspan="1">sup</td>
</tr><tr>
<td colspan="1" rowspan="1">{1 2}{13}{1 5}{2 3}{2 5}{3 5}</td>
<td colspan="1" rowspan="1">12<br>1<br>2<br>3<br>2</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">itemset</td>
<td colspan="1" rowspan="1">sup</td>
</tr><tr>
<td colspan="1" rowspan="1">{1 3}{2 3}{2 5}{3 5}</td>
<td colspan="1" rowspan="1">2<br>2<br>3<br>2</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">itemset</td>
</tr><tr>
<td colspan="1" rowspan="1">{235}</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">itemset</td>
<td colspan="1" rowspan="1">sup</td>
</tr><tr>
<td colspan="1" rowspan="1">{235}</td>
<td colspan="1" rowspan="1">2</td>
</tr></table>

<!-- Scan D L3  -->
![](https://web-api.textin.com/ocr_image/external/34f65b30e861a58a.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/74d88189d5dcd256.jpg)

XIAN JIADIOSGENIVIRSIIY

#### 3.2由事务数据库挖掘布尔关联规则

# 由频繁项集产生关联规则


![](https://web-api.textin.com/ocr_image/external/84615b05b01fbf25.jpg)

✓同时满足最小支持度和最小置信度的才是强关联规则，从频繁项集产生的规则都满足支持度要求，而其置信度则可由以下公式计算：

$c o n f d e n c e ( A \Rightarrow B ) = P ( A \vert B ) = \frac { \sup p O r t _ { - } c o u n t ( A \cup B ) } { S u p p o r t _ { - } c o u n t ( A ) }$

## ✓每个关联规则可由如下过程产生：

·对于每个频繁项集I，产生I的所有非空子集；

·对于每个非空子集s，如果 $\frac { \sup p p o r t - \cot n t ( l ) } { \sup p p o r t - \cot n t ( s ) } \geq \min _ c o n f$

则输出规则“S⇒(l-s)"

## 有多少个候选规则？

西安交通大學


![](https://web-api.textin.com/ocr_image/external/cb0360a395fa3574.jpg)

XIAN JAOIOSG ENIVIRSITY

## 3.2由事务数据库挖掘布尔关联规则

## 如果｛A，B，C，D｝频繁项集，候选规则为：

ABC→D, ABD→C, ACD→B, BCD→A,

A→BCD, B→ACD, C→ABD, D →ABC

AB→CD, AC →BD, AD→BC, BC→AD,

BD→AC, CD→AB

如果｜L｜＝k，那么有2k- 2候选规则（忽略L and Ø→L)

候选规则天生满足最小支持度，关键是需要判断是否满足最小置信度

西安交通大學


![](https://web-api.textin.com/ocr_image/external/d86e093baf020d68.jpg)

XIAN JAOIOSGENIVIRSITY

## 3.2由事务数据库挖掘布尔关联规则

### 如何有效地从频繁项集生成关联规则

# 》一般来说，置信度不具有反单调性

c(ABC →D) can be larger or smaller than c(AB →D)

# 有相同项集生成的规则的置信度具有反单调性

如果规则X→Y-X不满足置信度阈值，则形如$X ^ { \prime } \rightarrow Y - X ^ { \prime }$的规则一定也不满足置信度阈值，其中X＇是X的子集。

e.9.,L={A,B,C,D}: 为什么？

c(ABC→D)≥c(AB→CD)≥c(A→BCD)

西安交通大學

XIAN JAOIOSG ENIVIRSITY

## 3.2由事务数据库挖掘布尔关联规则

对于频繁k-项集(k &gt; 2)


![](https://web-api.textin.com/ocr_image/external/ecd4a57a254079d8.jpg)

计算规则头中只有一个项的规则的置信度


![](https://web-api.textin.com/ocr_image/external/31c92e6eea580ef2.jpg)

利用这些规则，迭代方法增加规则头中项集大小，计算置信度

如果置信度小于阈值，则裁剪

# {Bread, Milk, Diaper}

1-item rules

{Bread,Milk} →

{Diaper}

{Milk,Diaper}

{Bread}

{Diaper, Bread}{Milk}

2-item rules

{Bread} → {Milk,

Diaper}

{Diaper} → {Milk,

Bread}

{Milk} → {Diaper,Bread}

西安交通大學


![](https://web-api.textin.com/ocr_image/external/4490e12be487dc60.jpg)

XIAN JAOIOAGUNIVERSIEY

## 3.2由事务数据库挖掘布尔关联规则

# 例子（Association Rule.ipynb）

西安交通大學


![](https://web-api.textin.com/ocr_image/external/85a40a06d0147fcf.jpg)

XIAN JAOIOSG ENIVIRSITY

## 3.2由事务数据库挖掘布尔关联规则

Min_sup 40%(2/5)

<table border="1" ><tr>
<td colspan="1" rowspan="1">TID List of Items</td>
</tr><tr>
<td colspan="1" rowspan="1">1 Beer,Diaper,BabyPowder,Bread,Umbrella</td>
</tr><tr>
<td colspan="1" rowspan="1">2 Diaper,Baby Powder</td>
</tr><tr>
<td colspan="1" rowspan="1">3 Beer,Diaper,Milk</td>
</tr><tr>
<td colspan="1" rowspan="1">4 Beer,Diaper,Detergent</td>
</tr><tr>
<td colspan="1" rowspan="1">5 Beer,Milk,Coca-Cola</td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/4beb83007766a3c4.jpg)

XIAN JAOIOSG ENIVIRSITY

## 3.2由事务数据库挖掘布尔关联规则


![](https://web-api.textin.com/ocr_image/external/325878d8f1c9d738.jpg)

C1


![](https://web-api.textin.com/ocr_image/external/e15cd3f94e734f4e.jpg)

<!-- L1  -->
![](https://web-api.textin.com/ocr_image/external/05259402ef762e1c.jpg)

<table border="1" ><tr>
<td colspan="1" rowspan="1">Item Support</td>
</tr><tr>
<td colspan="1" rowspan="1">Beer "4/5"</td>
</tr><tr>
<td colspan="1" rowspan="1">Diaper "4/5"</td>
</tr><tr>
<td colspan="1" rowspan="1">Baby Powder "2/5"</td>
</tr><tr>
<td colspan="1" rowspan="1">Bread "1/5"</td>
</tr><tr>
<td colspan="1" rowspan="1">Umbrella "1/5"</td>
</tr><tr>
<td colspan="1" rowspan="1">Milk "2/5"</td>
</tr><tr>
<td colspan="1" rowspan="1">Detergent "1/5"</td>
</tr><tr>
<td colspan="1" rowspan="1">Coca-Cola "1/5"</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">Item Support</td>
</tr><tr>
<td colspan="1" rowspan="1">Beer "4/5"</td>
</tr><tr>
<td colspan="1" rowspan="1">Diaper "4/5"</td>
</tr><tr>
<td colspan="1" rowspan="1">Baby "2/5"Powder</td>
</tr><tr>
<td colspan="1" rowspan="1">Milk "2/5"</td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/74d88189d5dcd256.jpg)

XIAN JADIOSGENIVIRSITY

## 3.2由事务数据库挖掘布尔关联规则


![](https://web-api.textin.com/ocr_image/external/6ef7480bfe7fb8e1.jpg)

C2 L2


![](https://web-api.textin.com/ocr_image/external/f1b4d07118815969.jpg)

<table border="1" ><tr>
<td colspan="1" rowspan="1">Item</td>
<td colspan="1" rowspan="1">Suppo</td>
</tr><tr>
<td colspan="1" rowspan="1">Beer, Diaper</td>
<td colspan="1" rowspan="1">"3/5"</td>
</tr><tr>
<td colspan="1" rowspan="1">Beer,Milk</td>
<td colspan="1" rowspan="1">"2/5"</td>
</tr><tr>
<td colspan="1" rowspan="1">Diaper,BabyPowder</td>
<td colspan="1" rowspan="1">"2/5"</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">Item Support</td>
</tr><tr>
<td colspan="1" rowspan="1">Beer,DiaperBeer,Baby PowderBeer,MilkDiaper,BabyPowderDiaper,MilkBaby Powder,Milk</td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/4490e12be487dc60.jpg)

XIAN JAOIOSG ENIVIRSITY

## 3.2由事务数据库挖掘布尔关联规则


![](https://web-api.textin.com/ocr_image/external/f755369370c2dc95.jpg)

C3 empty


![](https://web-api.textin.com/ocr_image/external/0e087f0e1e5374bc.jpg)

<table border="1" ><tr>
<td colspan="1" rowspan="1">Item Support</td>
</tr><tr>
<td colspan="1" rowspan="1">Beer, Diaper,Baby PowderBeer, Diaper,Milk</td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/400f08b11c3b38fd.jpg)

XIAN JAOIOSG ENIVIESITY

## 3.2由事务数据库挖掘布尔关联规则

### 例子

# min_sup=40% min_conf=70%

<table border="1" ><tr>
<td colspan="1" rowspan="1">Item Support(A,B) Suport A Confidence</td>
</tr><tr>
<td colspan="1" rowspan="1">Beer,DiaperBeer,MilkDiaper,Baby PowderDiaper,BeerMilk,BeerBaby Powder, Diaper</td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/cb0360a395fa3574.jpg)

XIAN JAOIONGUNIVERSIY

## 3.2由事务数据库挖掘布尔关联规则


![](https://web-api.textin.com/ocr_image/external/fd11e0ba4e31143f.jpg)

### 例子

Beer →Diaper

support 60%, confidence 75%

Diaper → Beer

support 60%, confidence 75%

Milk → Beer

support 40%, confidence 100%

Baby_Powder → Diaper

support 40%, confidence 100%

西安交通大學


![](https://web-api.textin.com/ocr_image/external/b0f52c1378ec3425.jpg)

XIAN JADIOSG ENIVIESITY

## 3.2由事务数据库挖掘布尔关联规则

Apriori算法通常是可行的（三个因素：单调性、稀疏性、支持度）

提高Apriori算法的有效性

Apriori算法主要的挑战

·要对数据进行多次扫描；

·会产生大量的候选项集；

·对候选项集的支持度计算非常繁琐；

Assume the total number of items be 100.

<table border="1" ><tr>
<td colspan="1" rowspan="1">Cardinalityof Itemsets</td>
<td colspan="1" rowspan="1">Number of Itemsets</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">100</td>
</tr><tr>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">4,950</td>
</tr><tr>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">161,700</td>
</tr><tr>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">3,921,225</td>
</tr><tr>
<td colspan="1" rowspan="1">5</td>
<td colspan="1" rowspan="1">75,287,529</td>
</tr><tr>
<td colspan="1" rowspan="1">6</td>
<td colspan="1" rowspan="1">1,192,052,400</td>
</tr><tr>
<td colspan="1" rowspan="1">7</td>
<td colspan="1" rowspan="1">16,007,560,800</td>
</tr><tr>
<td colspan="1" rowspan="1">8</td>
<td colspan="1" rowspan="1">186,087,894,300</td>
</tr></table>

If a typical supermarket has at least 1,0000 different items, there are almost 50,000,000 possible 2-itemsets (i.e., itemset with the cardinality of 2) and over 1,000,000,000 possible 3-itemsets.

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1c646047df4e3e2f.jpg)

XIAN JAOIOSG ENIIRSITY

## 3.2由事务数据库挖掘布尔关联规则


![](https://web-api.textin.com/ocr_image/external/68a4fd1785d67a39.jpg)

### 提高Apriori算法的有效性

### 解决思路

·减少对数据的扫描次数；

·缩小产生的候选项集；

·改进对候选项集的支持度计算方法

西安交通大學


![](https://web-api.textin.com/ocr_image/external/960f974238f3a85b.jpg)

XIAN JAOIOSG ENIVIRSITY

#### 3.2由事务数据库挖掘布尔关联规则

##### AprioriTid算法

1．同Apriori算法一样利用Apriori-gen 过程生成候选项集；

2．与Apriori算法的重要区别是支持度的确定：仅用扫描一次数据库

3．用集合C＇k代替数据库

4．每个C＇k的元素形如＜TID，$\{ X _ { k } \} >$ 每个$X _ { k }$是事务TID包含的k项集

5．C＇1对应于数据库D．

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1c646047df4e3e2f.jpg)

XIAN JAOIOSGENIVIRSITY

Database

$C ^ { \wedge } _ { 1 }$

<table border="1" ><tr>
<td colspan="1" rowspan="1">TID</td>
<td colspan="1" rowspan="1">Set-of-itemsets</td>
</tr><tr>
<td colspan="1" rowspan="1">100</td>
<td colspan="1" rowspan="1">{ {1},{3},{4} }</td>
</tr><tr>
<td colspan="1" rowspan="1">200</td>
<td colspan="1" rowspan="1">{ {2},{3},{5} }</td>
</tr><tr>
<td colspan="1" rowspan="1">300</td>
<td colspan="1" rowspan="1">{{1},{2},{3},{5}}</td>
</tr><tr>
<td colspan="1" rowspan="1">400</td>
<td colspan="1" rowspan="1">{ {2},{5} }</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">TID</td>
<td colspan="1" rowspan="1">Items</td>
</tr><tr>
<td colspan="1" rowspan="1">100</td>
<td colspan="1" rowspan="1">134</td>
</tr><tr>
<td colspan="1" rowspan="1">200</td>
<td colspan="1" rowspan="1">235</td>
</tr><tr>
<td colspan="1" rowspan="1">300</td>
<td colspan="1" rowspan="1">1235</td>
</tr><tr>
<td colspan="1" rowspan="1">400</td>
<td colspan="1" rowspan="1">25</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">TID</td>
<td colspan="1" rowspan="1">Set-of-itemsets</td>
</tr><tr>
<td colspan="1" rowspan="1">100</td>
<td colspan="1" rowspan="1">{{13}}</td>
</tr><tr>
<td colspan="1" rowspan="1">200</td>
<td colspan="1" rowspan="1">{{2 3},{2 5} {3 5}}</td>
</tr><tr>
<td colspan="1" rowspan="1">300</td>
<td colspan="1" rowspan="1">{{1 2},{1 3},{15},{2 3}, {2 5}, {3 5} }</td>
</tr><tr>
<td colspan="1" rowspan="1">400</td>
<td colspan="1" rowspan="1">{{25}}</td>
</tr></table>

$C _ { 2 }$

$C ^ { \wedge } _ { 3 }$

<table border="1" ><tr>
<td colspan="1" rowspan="1">TID</td>
<td colspan="1" rowspan="1">Set-of-itemsets</td>
</tr><tr>
<td colspan="1" rowspan="1">200</td>
<td colspan="1" rowspan="1">{{235}}</td>
</tr><tr>
<td colspan="1" rowspan="1">300</td>
<td colspan="1" rowspan="1">{{2 3 5}}</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">itemset</td>
</tr><tr>
<td colspan="1" rowspan="1">{12}</td>
</tr><tr>
<td colspan="1" rowspan="1">{13}</td>
</tr><tr>
<td colspan="1" rowspan="1">{15}</td>
</tr><tr>
<td colspan="1" rowspan="1">{2 3}</td>
</tr><tr>
<td colspan="1" rowspan="1">{25}</td>
</tr><tr>
<td colspan="1" rowspan="1">{35}</td>
</tr></table>

C3

<table border="1" ><tr>
<td colspan="1" rowspan="1">itemset</td>
</tr><tr>
<td colspan="1" rowspan="1">{235}</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">Itemset</td>
<td colspan="1" rowspan="1">Support</td>
</tr><tr>
<td colspan="1" rowspan="1">{1}</td>
<td colspan="1" rowspan="1">2</td>
</tr><tr>
<td colspan="1" rowspan="1">{2}</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">{3}</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">{5}</td>
<td colspan="1" rowspan="1">3</td>
</tr></table>

L2

<table border="1" ><tr>
<td colspan="1" rowspan="1">Itemset</td>
<td colspan="1" rowspan="1">Support</td>
</tr><tr>
<td colspan="1" rowspan="1">{13}</td>
<td colspan="1" rowspan="1">2</td>
</tr><tr>
<td colspan="1" rowspan="1">{2 3}</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">{25}</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">{3 5}</td>
<td colspan="1" rowspan="1">2</td>
</tr></table>

L3

<table border="1" ><tr>
<td colspan="1" rowspan="1">Itemset</td>
<td colspan="1" rowspan="1">Support</td>
</tr><tr>
<td colspan="1" rowspan="1">{235}</td>
<td colspan="1" rowspan="1">2</td>
</tr></table>

###### 3.2由事务数据库挖掘布尔关联规则

###### Apriori算法

计算项集的支持度需要花费大量时间，需要检查数据库中的每个事务，涉及大量I／O资源

###### AprioriTid算法

初始阶段候选项集较大.时间开销和 Apriori 相当，并且要占用大量的内存开销

西安交通大學

XIAN JAOIOSG ENIVIRSITY

###### 3.2由事务数据库挖掘布尔关联规则

###### Apriori Hybrid算法


![](https://web-api.textin.com/ocr_image/external/6f9b8a6f4c2ae4bc.jpg)

初始阶段：Apriori 性能较好

✓后续阶段：AprioriTid性能较好

Apriori Hybrid:

在初始阶段使用Apriori算法，后续使用AprioriTid算法

缺点：Apriori 向AprioriTid过度会带来额外开销

西安交通大學


![](https://web-api.textin.com/ocr_image/external/d86e093baf020d68.jpg)

XIAN JAOIOSGENIVIRSITY

###### 3.2由事务数据库挖掘布尔关联规则

关联规则的兴趣度度量

客观度量：支持度、置信度

主观度量：最终，只有用户才能确定一个规则是否有趣的，而且这种判断是主观的，因不同的用户而异；通常认为一个规则（模式）是有趣的，如果：

·它是出人意料的

·可行动的（用户可以使用该规则做某些事情）

西安交通大學


![](https://web-api.textin.com/ocr_image/external/4beb83007766a3c4.jpg)

XIAN JAOIOSG ENIVIRSITY

###### 3.2由事务数据库挖掘布尔关联规则

# 关联规则可视化


![](https://web-api.textin.com/ocr_image/external/cde7e7d670c23a4f.jpg)

###### 表格


![](https://web-api.textin.com/ocr_image/external/2ea212335dc52634.jpg)

<table border="1" ><tr>
<td colspan="1" rowspan="1">Antecedent</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">Consequent</td>
<td colspan="1" rowspan="1">Support</td>
<td colspan="1" rowspan="1">Confidence</td>
</tr><tr>
<td colspan="1" rowspan="1">PC,Monitor</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">Printer</td>
<td colspan="1" rowspan="1">90%</td>
<td colspan="1" rowspan="1">85%</td>
</tr><tr>
<td colspan="1" rowspan="1">PC</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">Printer, Monitor</td>
<td colspan="1" rowspan="1">90%</td>
<td colspan="1" rowspan="1">75%</td>
</tr><tr>
<td colspan="1" rowspan="1">Printer,Monitor</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">PC</td>
<td colspan="1" rowspan="1">80%</td>
<td colspan="1" rowspan="1">70%</td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/e4faee2de424d166.jpg)

XIAN JAOIOSGENIVIRSITY

## 3.2由事务数据库挖掘布尔关联规则

# 关联规则可视化

## 有向图

<!-- PC Printer  -->
![](https://web-api.textin.com/ocr_image/external/b1b70c945d853bf0.jpg)

<!-- Monitor PC Printer  -->
![](https://web-api.textin.com/ocr_image/external/d0de49048a08e236.jpg)

<!-- Monitor Printer PC  -->
![](https://web-api.textin.com/ocr_image/external/e03edb3b32a2ca70.jpg)

Monitor

西安交通大學


![](https://web-api.textin.com/ocr_image/external/279298cab96343e7.jpg)

XIAN JAOIOSGENIVIRSITY

<table border="1" ><tr>
<td colspan="5" rowspan="1">文件（F） 编辑（E） 选定项（S）查看（V） 帮助（H）</td>
<td colspan="1" rowspan="1"></td>
</tr><tr>
<td colspan="1" rowspan="1"></td>
<td colspan="2" rowspan="1"></td>
<td colspan="2" rowspan="1">小 日十 </td>
<td colspan="1" rowspan="1"></td>
</tr><tr>
<td colspan="2" rowspan="1">规则 项目集合</td>
<td colspan="2" rowspan="1">统计信息</td>
<td colspan="2" rowspan="1"></td>
</tr><tr>
<td colspan="6" rowspan="1">［中聪慧性＋［］＋［中怀疑性］［中敏感性］＋［中紧张性］ ［中有恒性］＋［中优虑性］ ［中幻想性］＋［中有恒性］5 % 50%1 54 ［中紧张性］＋［中世故性］ 1.05356% 51%50%1.051 1.064［中聪慧性］＋［甲感性］ 1.0391.078［中稳定性］＋［中怀疑性］ 56%52% ［中自律性］ 1.06 56% ［中有恒性］＋［中怀疑性］52% ［中恃强性］1.037［中聪慧性］＋［中紧张性］ 1.037［中有恒性］＋［中乐群性］56% ［中紧张性］＋［中有恒性］ ［中恃强性］＋［中忧虑性］54%1.0561.0753%［中敏感性］＋［中实529］ 53%1.0791.05453% 1.041 54%1.069 1.052［中聪慧性55％［中紧张性］＋［中怀疑性］ 1.061［中紧张性］＋［中实验性］ ［中优虑性］＋［中自律性］52%1.059 ［中自律性］＋［中乐群性］54%1.059［中乐群性1中实验码］</td>
</tr></table>

规则颜色：支持度 规则宽度：提升

50.00% 50.63% 51.26% 51.89% 52.53% 53.16% 54.11% 55.06% 56.02% 1.037 1.042 1.047 1.053 1.058 1.063 1.069 1.074 1.079

项目集合颜色：支持度

<table border="1" ><tr>
<td colspan="2" rowspan="1">50.00% 53.44% 56.89% 60.16% 63.43% 66.71% 69.98% 73.26% 76.53% 79.81% 83.08%</td>
</tr><tr>
<td colspan="1" rowspan="1">模型中有270个项目集合和20个规则</td>
<td colspan="1" rowspan="1">只读</td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/49ee36c4b29db527.jpg)

XIAN JADIOSGENIVIRSITY

## 3.2由事务数据库挖掘布尔关联规则

<!-- 关联规则可视化 Color.Corfidence 1%-100%, Height: Supporl 3D可视化 LHS Format(x) =ipd Formal(x) = ipg neight(x) = 3 = 300.00\~400.00 neight(x) = 4 size(x): mogeDamoin( size(x): size(x) = 'Smal 00.00\~400.00 height(x) = '400.00\~500.00 width(x) : widtr(x) =Small www.boeing.com 00.00\~500.00 height(x) size(x) = Medium' = 'Mediurn' W ='400.00\~500.00 600.00\~700.00 x) = www.boeing.com = '400.00\~500.00 in(x)= = 600.00\~700.00 ImageDoma = width(x) ( widthx)  -->
![](https://web-api.textin.com/ocr_image/external/9de78c9232828f52.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/206b91b6d810da3c.jpg)

XIAN JAOIONG LNIVERSIY

## 本章内容

3.1 关联规则挖掘的基本概念

3.2 由事务数据库挖掘单维布尔关联规则

3.3 多层关联规则挖掘

3.4 多维关联规则挖掘

3.5 关联规则、相关性、因果关系的区别

西安交通大學


![](https://web-api.textin.com/ocr_image/external/55703490c988762f.jpg)

XIAN JAOIOSG ENIVIRSITY

### 3.3 多层关联规则挖掘

数据项中经常会形

成概念分层

<!-- All computer software printer Computer accessory desktop laptop financial edu. color mouse b/w wrist pad IBM Microsoft HP Sony Logitech Ergoway  -->
![](https://web-api.textin.com/ocr_image/external/1719ad2dc2f915ba.jpg)

底层数据项，其支持度往往也较低


![](https://web-api.textin.com/ocr_image/external/f0c96e7734e32e68.jpg)

挖掘底层数据项之间的关联规则必须定义不同的支持度

<table border="1" ><tr>
<td colspan="1" rowspan="1">TIDItems</td>
<td colspan="1" rowspan="1"></td>
</tr><tr>
<td colspan="1" rowspan="1">T1{IBM D/C,Sony b/w}</td>
<td colspan="1" rowspan="1"></td>
</tr><tr>
<td colspan="1" rowspan="1">T2 {Ms.edu.Sw.,Ms.fin.Sw</td>
<td colspan="1" rowspan="1">.}</td>
</tr><tr>
<td colspan="1" rowspan="1">T3 {Logi. mouse, Ergoway wrist</td>
<td colspan="1" rowspan="1"> pad}</td>
</tr><tr>
<td colspan="1" rowspan="1">T4 {IBM D/C,Ms.Fin.Sw.}</td>
<td colspan="1" rowspan="1"></td>
</tr><tr>
<td colspan="1" rowspan="1">T5 {IBM D/C}</td>
<td colspan="1" rowspan="1"></td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/b5076cff4e564192.jpg)

XIAN JADIOSGENIVIRSITY

### 3.3 多层关联规则挖掘

在适当的等级挖掘出来的数据项间的关联规则可能是非常有用的

事务数据库中的数据也是根据维和概念分层来进行储存的

这为从事务数据库中挖掘不同层次的关联规则提供了可能。

在多个抽象层挖掘关联规则，并在不同的抽象层进行转化，是数据挖掘系统应该提供的能力

西安交通大學


![](https://web-api.textin.com/ocr_image/external/55703490c988762f.jpg)

XIAN JAOIOSG ENIVIRSITY

### 3.3多层关联规则挖掘

## 多层关联规则的挖掘还是使用置信度-支持度框架，可以采用自顶向下策略

概念分层中，一个节点的支持度肯定不小于该节点的任何子节点的支持度（为什么？）

由概念层1开始向下，到较低的更特定的概念层，对每个概念层的频繁项计算累加计数

每一层的关联规则挖掘可以使用Apriori等多种方法

例如：

·先找高层的关联规则：computer -＞ printer ［20％， 60％］

·再找较低层的关联规则：laptop -＞ color printer ［10％，50%]

西安交通大學


![](https://web-api.textin.com/ocr_image/external/b5076cff4e564192.jpg)

XIAN JAOIONG LNIVERSIY

## 3.3 多层关联规则挖掘

##  一致支持度：对所有层都使用一致的最小支持度

优点：搜索时容易采用优化策略，即一个项如果不满足最小支持度，它的所有子项都可以不用搜索

缺点：最小支持度值设置困难

·太高：将丢掉出现在较低抽象层中有意义的关联规则

·太低：会在较高层产生太多的无兴趣的规则

西安交通大學


![](https://web-api.textin.com/ocr_image/external/cb0360a395fa3574.jpg)

XIAN JAOIOSG ENIVIRSITY

## 3.3 多层关联规则挖掘

使用递减支持度，可以解决使用一致支持度时在最小支持度值上设定的困难

Computer

[support=10%]

递减支持度：在较低层 min_sup=5%使用递减的最小支持度

Laptop Desktop

[support=6%] [support=4%]


![](https://web-api.textin.com/ocr_image/external/ea6f2d8fa180cb1f.jpg)

每一层都有自己的一个独立的最小支持度$\min _ { - } s u p = 3 \%$

抽象层越低，对应的最小支持度越小

西安交通大學


![](https://web-api.textin.com/ocr_image/external/cb0360a395fa3574.jpg)

XIAN JAOIOSG ENIVIRSITY

## 3.3 多层关联规则挖掘

### 多层关联-基于分组的支持度


![](https://web-api.textin.com/ocr_image/external/7ec8f5a52998b923.jpg)

用户和专家清楚哪些分组比其他分组更加重要，在挖掘多层关联规则时，使用用户指定的基于项或者基于分组的最小支持度阈值

·E.g.对laptop＿computer或者flash＿drives设置特别低的支持度阈值，以便特别关注这类商品的管理模式

西安交通大學


![](https://web-api.textin.com/ocr_image/external/0cc5283056ec8354.jpg)

XIAN JAOIOSG ENIVIRSITY

#### 3.3 多层关联规则挖掘

#### Hierarchy-information encoded

##### transaction table: T[1]

<table border="1" ><tr>
<td colspan="1" rowspan="1">TID</td>
<td colspan="1" rowspan="1">Items</td>
</tr><tr>
<td colspan="1" rowspan="1">T1</td>
<td colspan="1" rowspan="1">{111, 121,211,221}</td>
</tr><tr>
<td colspan="1" rowspan="1">T2</td>
<td colspan="1" rowspan="1">{111,211,222,323}</td>
</tr><tr>
<td colspan="1" rowspan="1">T3</td>
<td colspan="1" rowspan="1">{112,122,221,411}</td>
</tr><tr>
<td colspan="1" rowspan="1">T4</td>
<td colspan="1" rowspan="1">{111,121}</td>
</tr><tr>
<td colspan="1" rowspan="1">Ts</td>
<td colspan="1" rowspan="1">{111,122,211,221,413}</td>
</tr><tr>
<td colspan="1" rowspan="1">T6</td>
<td colspan="1" rowspan="1">{211,323,524}</td>
</tr><tr>
<td colspan="1" rowspan="1">T7</td>
<td colspan="1" rowspan="1">{323,411,524,713}</td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/0cc5283056ec8354.jpg)

XIAN JAOIOSGENIVIRSITY

##### 3.3 多层关联规则挖掘

## minsup[1]=4

<!-- 1  -->
![](https://web-api.textin.com/ocr_image/external/a1b215486ae7a64f.jpg)

<!-- 3  -->
![](https://web-api.textin.com/ocr_image/external/26aa1f72ada9e1e1.jpg)

Level-1 large 1-itemsets:L[1,1] Level-1 large 2-itemsets:L[1,2]

<table border="1" ><tr>
<td colspan="1" rowspan="1">Itemset</td>
<td colspan="1" rowspan="1">Support</td>
</tr><tr>
<td colspan="1" rowspan="1">{1**</td>
<td colspan="1" rowspan="1">5</td>
</tr><tr>
<td colspan="1" rowspan="1">{2**</td>
<td colspan="1" rowspan="1">5</td>
</tr></table>

- Use L[1,1] and T[2]

<!-- 2  -->
![](https://web-api.textin.com/ocr_image/external/814ae20f5fa924b6.jpg)

Filtered transaction table:T[2] L[1,1] is used to filter:

(1) any item which is not large in a transaction

<table border="1" ><tr>
<td colspan="1" rowspan="1">TID</td>
<td colspan="1" rowspan="1">Items</td>
</tr><tr>
<td colspan="1" rowspan="1">$T _ { 1 }$</td>
<td colspan="1" rowspan="1">{111,121,211,221}</td>
</tr><tr>
<td colspan="1" rowspan="1">$T _ { 2 }$</td>
<td colspan="1" rowspan="1">{111,211,222}</td>
</tr><tr>
<td colspan="1" rowspan="1">$T _ { 3 }$</td>
<td colspan="1" rowspan="1">{112,122,221}</td>
</tr><tr>
<td colspan="1" rowspan="1">$T _ { 4 }$</td>
<td colspan="1" rowspan="1">{111,121}</td>
</tr><tr>
<td colspan="1" rowspan="1">$T _ { 5 }$</td>
<td colspan="1" rowspan="1">{111,122,211,221}</td>
</tr><tr>
<td colspan="1" rowspan="1">$T _ { 6 }$</td>
<td colspan="1" rowspan="1">{211}</td>
</tr></table>

(2) the transactions in T[1]which contain only small items

西安交通大學


![](https://web-api.textin.com/ocr_image/external/56325b24d33d2a53.jpg)

XIAN JAOIOSG ENIVIESITY

## 3.3 多层关联规则挖掘

### minsup[2]=3

### Level-2 large 1-itemsets: Level-2 large 2-itemsets: Level-2 large 3-itemsets:

L[2,1] (Note 1) L[2,2](Note 2) L[2,3](Note 3)

<table border="1" ><tr>
<td colspan="1" rowspan="1">Itemset</td>
<td colspan="1" rowspan="1">Support</td>
</tr><tr>
<td colspan="1" rowspan="1">{11*,12*,22*}</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">{11*, 21*, 22*}</td>
<td colspan="1" rowspan="1">3</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">Itemset</td>
<td colspan="1" rowspan="1">Support</td>
</tr><tr>
<td colspan="1" rowspan="1">{11*}</td>
<td colspan="1" rowspan="1">5</td>
</tr><tr>
<td colspan="1" rowspan="1">{12*]</td>
<td colspan="1" rowspan="1">4</td>
</tr><tr>
<td colspan="1" rowspan="1">{21*}</td>
<td colspan="1" rowspan="1">4</td>
</tr><tr>
<td colspan="1" rowspan="1">{22*}</td>
<td colspan="1" rowspan="1">4</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">Itemset</td>
<td colspan="1" rowspan="1">Support</td>
</tr><tr>
<td colspan="1" rowspan="1">{11*, 12*}</td>
<td colspan="1" rowspan="1">4</td>
</tr><tr>
<td colspan="1" rowspan="1">{11*, 21*}</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">{11*,22*}</td>
<td colspan="1" rowspan="1">4</td>
</tr><tr>
<td colspan="1" rowspan="1">{12*, 22*}</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">{21*, 22*}</td>
<td colspan="1" rowspan="1">3</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">TID</td>
<td colspan="1" rowspan="1">Items</td>
</tr><tr>
<td colspan="1" rowspan="1">T1</td>
<td colspan="1" rowspan="1">{111, 121, 211, 221}</td>
</tr><tr>
<td colspan="1" rowspan="1">T2</td>
<td colspan="1" rowspan="1">{111,211, 222}</td>
</tr><tr>
<td colspan="1" rowspan="1">T3</td>
<td colspan="1" rowspan="1">{112, 122, 221}</td>
</tr><tr>
<td colspan="1" rowspan="1">T4</td>
<td colspan="1" rowspan="1">{111, 121}</td>
</tr><tr>
<td colspan="1" rowspan="1">Ts</td>
<td colspan="1" rowspan="1">{111, 122, 211, 221}</td>
</tr><tr>
<td colspan="1" rowspan="1">T6</td>
<td colspan="1" rowspan="1">{211}</td>
</tr></table>

西步交通大學


![](https://web-api.textin.com/ocr_image/external/40e5f12256a738f5.jpg)

XIAN JAOIOSG ENIVIESITY

## 3.3 多层关联规则挖掘

### minsup[3]=3

Level-3 large 1-itemsets: Level-3 large 2-itemsets:

L[3,1] (Note 1) L[3,2]

<table border="1" ><tr>
<td colspan="1" rowspan="1">Itemset</td>
<td colspan="1" rowspan="1">Support</td>
</tr><tr>
<td colspan="1" rowspan="1">{111, 211}</td>
<td colspan="1" rowspan="1">3</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">Itemset</td>
<td colspan="1" rowspan="1">Support</td>
</tr><tr>
<td colspan="1" rowspan="1">{111}</td>
<td colspan="1" rowspan="1">4</td>
</tr><tr>
<td colspan="1" rowspan="1">{211}</td>
<td colspan="1" rowspan="1">4</td>
</tr><tr>
<td colspan="1" rowspan="1">{221}</td>
<td colspan="1" rowspan="1">3</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">TID</td>
<td colspan="1" rowspan="1">Items</td>
</tr><tr>
<td colspan="1" rowspan="1">T1</td>
<td colspan="1" rowspan="1">{111, 121, 211, 221}</td>
</tr><tr>
<td colspan="1" rowspan="1">T2</td>
<td colspan="1" rowspan="1">{111, 211, 222}</td>
</tr><tr>
<td colspan="1" rowspan="1">T3</td>
<td colspan="1" rowspan="1">{112, 122, 221}</td>
</tr><tr>
<td colspan="1" rowspan="1">T4</td>
<td colspan="1" rowspan="1">{111, 121}</td>
</tr><tr>
<td colspan="1" rowspan="1">Ts</td>
<td colspan="1" rowspan="1">{111, 122, 211, 221}</td>
</tr><tr>
<td colspan="1" rowspan="1">T6</td>
<td colspan="1" rowspan="1">{211}</td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/40e5f12256a738f5.jpg)

XIAN JAOIOSG ENIVIESITY

## 本章内容

3.1 关联规则挖掘的基本概念

3.2 由事务数据库挖掘单维布尔关联规则

3.3 多层关联规则挖掘

3.4 多维关联规则挖掘

3.5 关联规则、相关性、因果关系的区别

西安交通大學


![](https://web-api.textin.com/ocr_image/external/55703490c988762f.jpg)

XIAN JAOIOSG ENIVIRSITY

### 3.4多维关联规则挖掘

## 单维关联规则：

buys(X,“milk”) = buys(X, “bread”)

## 多维关联规则：涉及两个或多个维或谓词的关联规则

维间关联规则：不包含重复的谓词

age(X,”19-25”)Aoccupation(X,"student")⇒buys(X,“coke”)

# 混合维关联规则：包含某些谓词的多次出现

age(X,”19-25”)^buys(X,“popcorn”)=&gt; buys(X,“coke”)

## 在多维关联规则挖掘中，搜索的不是频繁项集，而是频繁谓词集。k-谓词集是包含k个合取谓词的集合。

例如：｛age，occupation，buys｝是一个3-谓词集

西安交通大學


![](https://web-api.textin.com/ocr_image/external/e8a8fb825a812ee3.jpg)

XIAN JAOIOSGENIVIRSITY

## 3.4多维关联规则挖掘

### 数据属性可以分为类别属性和数值属性


![](https://web-api.textin.com/ocr_image/external/02f103fb5ac1846d.jpg)

类别属性：具有有限个不同值，值之间无序

数值属性：数值类型，并且值之间有一个隐含的序

### 对量化属性的处理：


![](https://web-api.textin.com/ocr_image/external/6ee7427921c30221.jpg)

1．静态离散化：使用预定义的概念分层对数值属性进行静态地离散化


![](https://web-api.textin.com/ocr_image/external/4a7ba1ff686715d9.jpg)

2．量化关联规则：根据数据的分布，将数值属性离散化到“箱”

3．基于距离的关联规则：考虑数据点之间的距离，动态地离散化量化

西安交通大學


![](https://web-api.textin.com/ocr_image/external/2b915fee8257031a.jpg)

XIAN JAOIOSGENIVIRSITY

## 3.4多维关联规则挖掘

<table border="1" ><tr>
<td colspan="1" rowspan="1">RecordID Age Married NumCars</td>
</tr><tr>
<td colspan="1" rowspan="1">100 23 No 1</td>
</tr><tr>
<td colspan="1" rowspan="1">200 25 Yes 1</td>
</tr><tr>
<td colspan="1" rowspan="1">300 29 No 0</td>
</tr><tr>
<td colspan="1" rowspan="1">400 34 Yes 2</td>
</tr><tr>
<td colspan="1" rowspan="1">500 38 Yes 2</td>
</tr></table>

&lt;Age: 30..39&gt; and &lt;Married: Yes&gt; =&gt; &lt;NumCars: 2&gt;

Support = 40%, Conf = 100%

西安交通大學


![](https://web-api.textin.com/ocr_image/external/206b91b6d810da3c.jpg)

XIAN JAOIOSG ENIVIRSITY

## 3.4多维关联规则挖掘

# 基本思路：将数值型关联规则挖掘转化为布尔型关联规则挖掘

# 引入＜attribute： value＞ 作为新属性，这个属性是布尔型

<table border="1" ><tr>
<td colspan="1" rowspan="1">ID</td>
<td colspan="1" rowspan="1">Age:20..29</td>
<td colspan="1" rowspan="1">Age:30..39</td>
<td colspan="1" rowspan="1">Married:Yes</td>
<td colspan="1" rowspan="1">Married:No</td>
<td colspan="1" rowspan="1">NumCars: 0</td>
<td colspan="1" rowspan="1">NumCars: 1</td>
</tr><tr>
<td colspan="1" rowspan="1">100</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">1</td>
</tr><tr>
<td colspan="1" rowspan="1">200</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">1</td>
</tr><tr>
<td colspan="1" rowspan="1">300</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">0</td>
</tr><tr>
<td colspan="1" rowspan="1">400</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
</tr><tr>
<td colspan="1" rowspan="1">500</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/6a8f452f1abd5dcd.jpg)

XIAN JADIOSGENIVIRSITY

## 3.4多维关联规则挖掘

## 聚焦于以下形式的2-维量化关联规则：

两个量化属性和一个分类属性间的关联：

Aquan1 ^ Aquan2→Acat

如：age（X，” 30-39”）＾income（X，＂ 42K-48K＂）buys(X," high resolution TV”)

# 关联规则聚类系统（Association Rule Clustering System，

ARCS)

income


![](https://web-api.textin.com/ocr_image/external/5648bb65cc40c0b0.jpg)

<!-- 70-80K 60-70K 50-60K 40-50K 30-40K 20-30K &lt;20K 32 33 34 35 36 37 38 age  -->
![](https://web-api.textin.com/ocr_image/external/ff1255ff010aa26d.jpg)

源于图像处理技术，该技术将量化属性对映射到满足给定分类属性条件的2-D栅格上，然后通过搜索栅格点的聚类而产生关联规则

西安交通大學


![](https://web-api.textin.com/ocr_image/external/e8a8fb825a812ee3.jpg)

XIAN JAOIONG LNIVERSIY

## 3.4多维关联规则挖掘

### ARCS过程：

1.Binning

2.Find frequent predicateset

<!-- Record Data * of x-bins # of y-bins Binner array of binned data min.support Association segmentation criteria min.confidence Rule Engine asssociation rules Heuristic rule to bitmap conversion Optimizer Clustering clustered association rules test data Verifier (cluster analysis)  -->
![](https://web-api.textin.com/ocr_image/external/ec107f7f2159b72f.jpg)

3.Clustering

4.Optimize

西安交通大學


![](https://web-api.textin.com/ocr_image/external/c60459d345f20877.jpg)

XIAN JADIOSGENIVIESITY

## 3.4多维关联规则挖掘

### ARCS过程：

1．分箱（根据不同分箱方法创建一个2-D数组），目的在于减少量化属性相对应的巨大的值个数，使得2-D栅格的大小可控

·等宽分箱

·等深分箱

·基于同质的分箱（每个箱中元组一致分布）

## 2．找出频繁谓词集

·扫描分箱后形成的2-D数组，找出满足最小支持度和置信度的频繁谓词集

西安交通大學


![](https://web-api.textin.com/ocr_image/external/38bab703ba49bb6f.jpg)

XIAN JAOIOSG ENIVIESITY

## 3.4多维关联规则挖掘

### ARCS过程：

## 3．关联规则聚类

## ·将上一步得到的强关联规则映射到2-D栅格上，使用聚类算法，扫描栅格，搜索规则的矩形聚类


![](https://web-api.textin.com/ocr_image/external/f37e338381ae2a5e.jpg)

age(X,35)入∈come(X,$^ { \prime \prime } 3 1 K . . 4 0 K ^ { \prime \prime } ) \Rightarrow b u y s ( X , ^ { \prime \prime } h i g h$_resolution_TV")age(X,34)^ income(X,,{′′}41K..50K{′′})⇒buys(X,{′}$^ { \prime \prime } h i g h$ resolution$T V ^ { \prime \prime } )$ $a g e ( X , 3 5 ) \wedge \in c o m e ( X , ^ { \prime \prime } 4 1 K . . 5 0 K ^ { \prime \prime } ) \Rightarrow b u y s ( X , " h i j h$resolution$T V ^ { \prime \prime } )$

70-80K

60-70K

income

50-60K

40-50K


![](https://web-api.textin.com/ocr_image/external/6af36610659c75cd.jpg)

<!-- 32 33 34 35 36 37 38  -->
![](https://web-api.textin.com/ocr_image/external/750511d99569139c.jpg)

30-40K

20-30K

age(X,34..35)^∈come(X,$^ { \prime \prime } 3 1 K . . 5 0 K ^ { \prime \prime } )$⇒b$b u y s ( X , ^ { \prime \prime } h i g h$ resolution $T V ^ { \prime \prime } )$

&lt;20K

age

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1d5f2dfc1add5fa0.jpg)

XIAN JAOIONGUNIVERSIEY

## 3.4多维关联规则挖掘


![](https://web-api.textin.com/ocr_image/external/b68a2f4fb0f42554.jpg)

## ARCS的局限性：


![](https://web-api.textin.com/ocr_image/external/d6b43704f5173cc5.jpg)

规则的左手边只能有两个量化属性（2-D栅格的限制）

西安交通大學


![](https://web-api.textin.com/ocr_image/external/ec866f65b0c1e63a.jpg)

XIAN JAOIOSG ENIVIRSITY

## 3.4 数值型关联规则挖掘

MinSup 问题：如果数值型属性离散化后产生的区间的数量过多，单个区间的支持度就会较小，那么由于最小支持度限制，涉及这个属性的规则就可能不存在。区间数量增多也是布尔型属性增多，潜在规则会爆炸性增长

MinConf问题：当把数值型属性离散化为区间时，会产生信息丢失，当区间越大时，信息丢失的也就越多。

Catch-22两难境地：

如果区间过大，一些规则由于最小置信度问题可能丢失

如果区间过小，一些规则由于最小支持度问题可能丢失

西安交通大學


![](https://web-api.textin.com/ocr_image/external/b5076cff4e564192.jpg)

XIAN JAOIOSG ENIVIRSITY

## 本章内容

3.1 关联规则挖掘的基本概念

3.2 由事务数据库挖掘单维布尔关联规则

3.3 多层关联规则挖掘

3.4 多维关联规则挖掘

3.5 关联规则、相关性、因果关系的区别

西安交通大學


![](https://web-api.textin.com/ocr_image/external/e17f4a47d0ebf3ef.jpg)

XIAN JAOIOSG ENIVIRSITY

### 3.5关联规则、相关性、因果关系的区别

问题1：强关联规则是否是正相关的？

问题2：强关联规则是否存在因果关系？

问题3：相关性是否意味着因果关系？

问题4：如何定义因果关系？

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1d5f2dfc1add5fa0.jpg)

XIAN JAOIOSG ENIVIRSITY

### 3.5关联规则、相关性、因果关系的区别

问题1：强关联规则是否是正相关的？

 相关性：两个变量存在联系，一个变量会随着另一个变量变化，分为正相关和负相关

两安交通大學


![](https://web-api.textin.com/ocr_image/external/6a8f452f1abd5dcd.jpg)

XIAN JAOIOSG ENIVIRSITY

### 3.5关联规则、相关性、因果关系的区别

<table border="1" ><tr>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">打篮球</td>
<td colspan="1" rowspan="1">不打篮球</td>
<td colspan="1" rowspan="1">合计</td>
</tr><tr>
<td colspan="1" rowspan="1">喝麦片</td>
<td colspan="1" rowspan="1">2000</td>
<td colspan="1" rowspan="1">1750</td>
<td colspan="1" rowspan="1">3750</td>
</tr><tr>
<td colspan="1" rowspan="1">不喝麦片</td>
<td colspan="1" rowspan="1">1000</td>
<td colspan="1" rowspan="1">250</td>
<td colspan="1" rowspan="1">1250</td>
</tr><tr>
<td colspan="1" rowspan="1">合计</td>
<td colspan="1" rowspan="1">3000</td>
<td colspan="1" rowspan="1">2000</td>
<td colspan="1" rowspan="1">5000</td>
</tr></table>

#### 例：（Aggarwal ＆ Yu， PODS98）

#### 在5000个学生中

3000个打篮球

3750个喝麦片粥

·2000个学生既打篮球又喝麦片粥

然而，打篮球 ＝＞ 喝麦片粥 ［？％，？％］是无趣的，因为全部学生中喝麦片粥的比率是75％，比打篮球学生的66.7％要高

打篮球＝＞ 不喝麦片粥 ［20％， 33.3％］这个规则远比上面那个要精确，尽管支持度和置信度都要低的多

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1d5f2dfc1add5fa0.jpg)

XIAN JAOIONG LNIVERSIY

### 3.5关联规则、相关性、因果关系的区别

<table border="1" ><tr>
<td colspan="1" rowspan="1">X</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
</tr><tr>
<td colspan="1" rowspan="1">Y</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
</tr><tr>
<td colspan="1" rowspan="1">Z</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
</tr></table>

X and Y：正相关

X and Z：负相关

<table border="1" ><tr>
<td colspan="1" rowspan="1">Rule</td>
<td colspan="1" rowspan="1">Support</td>
<td colspan="1" rowspan="1">Confidence</td>
</tr><tr>
<td colspan="1" rowspan="1">$X \Rightarrow Y$</td>
<td colspan="1" rowspan="1">25%</td>
<td colspan="1" rowspan="1">50%</td>
</tr><tr>
<td colspan="1" rowspan="1">$x \Rightarrow Z$</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
</tr></table>

#### 强关联规则≠正相关！

西安交通大學


![](https://web-api.textin.com/ocr_image/external/0e9da6c052fb7c13.jpg)

XIAN JADIOSGENIVIESITY

### 3.5关联规则、相关性、因果关系的区别

###### 关联规则与相关性

<!-- 正相关 关联规则 （未去除无趣规则） 负相关  -->
![](https://web-api.textin.com/ocr_image/external/c158d45d2d828031.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/7cdf64717ff6d9c6.jpg)

XIAN JADIOSG LNIVIESIEY

### 3.5关联规则、相关性、因果关系的区别

<!-- 关联规则 正相关 （已去除无趣规则） 负相关  -->
![](https://web-api.textin.com/ocr_image/external/e0ba35c767bcaa20.jpg)

#### 可使用相关度来扩充关联规则的支持度---置信度框架

A→B[sup port,confidence,correlation]

需要一种度量事件间的相关性或者是依赖性的指标

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1d5f2dfc1add5fa0.jpg)

XIAN JAOIOSG ENIVIRSITY

### 3.5关联规则、相关性、因果关系的区别

#### 提升度指标（lift）

A和B间的提升度： $l i f t ( A , B ) = \frac { P ( A \cup B ) } { P ( A ) P ( B ) } = P ( B \vert A ) / P ( B )$

当项集A的出现独立于项集B时，

P（AUB）＝P（A）P（B），即lift（A，B）＝1，表明A与B无关，lift（A，B）＞1表明A与B正相关，lift（A，B）＜1表明A与B负相关

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1d5f2dfc1add5fa0.jpg)

XIAN JAOIOSG ENIVIRSITY

### 3.5关联规则、相关性、因果关系的区别

<table border="1" ><tr>
<td colspan="1" rowspan="1">X</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
</tr><tr>
<td colspan="1" rowspan="1">Y</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
</tr><tr>
<td colspan="1" rowspan="1">Z</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">Itemset</td>
<td colspan="1" rowspan="1">Support</td>
<td colspan="1" rowspan="1">left</td>
</tr><tr>
<td colspan="1" rowspan="1">X,Y</td>
<td colspan="1" rowspan="1">25%</td>
<td colspan="1" rowspan="1">2</td>
</tr><tr>
<td colspan="1" rowspan="1">X,Z</td>
<td colspan="1" rowspan="1">37.50%</td>
<td colspan="1" rowspan="1">0.9</td>
</tr><tr>
<td colspan="1" rowspan="1">Y,Z</td>
<td colspan="1" rowspan="1">12.50%</td>
<td colspan="1" rowspan="1">0.57</td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1d5f2dfc1add5fa0.jpg)

XIAN JAOIOSG ENIVIRSITY

### 3.5关联规则、相关性、因果关系的区别

问题2：强关联规则是否存在因果关系？

因果关系：变量或事件之间的直接作用关系

太阳东 周一上 [1/7,100%]

方升起 DM课

强关联规则≠因果关系！

西安交通大學


![](https://web-api.textin.com/ocr_image/external/0e9da6c052fb7c13.jpg)

XIAN JAOIOSG ENIVIRSITY

### 3.5关联规则、相关性、因果关系的区别

#### 相关性有助于为发现因果关系提供线索

<!-- 饮食 G2029S变异 患帕金森病 除草剂 LRRK 锻炼 2 咖啡 携带者 未变异 不患帕金森病  -->
![](https://web-api.textin.com/ocr_image/external/ca61d3d680de0943.jpg)

LRRK2携带者患帕金森的几率达到30％-75％，普通患症的几率只有1%

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1d5f2dfc1add5fa0.jpg)

XIAN JADIOSG ENIVIESITY

### 3.5关联规则、相关性、因果关系的区别

问题4：如何定义因果关系？


![](https://web-api.textin.com/ocr_image/external/2a4ae99f4744bfde.jpg)

Granger因果关系：若在包含了变量X、Y的过去信息的条件下，对变量Y的预测效果要优于只单独由Y的过去信息对Y的预测效果，即变量X、Y有因果关系，变量X 是变量Y的Granger原因

Clive W.J.Granger

诺贝尔经济学奖获奖者

西安交通大學


![](https://web-api.textin.com/ocr_image/external/6a8f452f1abd5dcd.jpg)

XIAN JAOIOSG ENIVIRSITY

## 总结

Association rule mining consists of first finding frequent itemsets, from which strong association are generated.Associations can be further analyzed to uncover correlation rules, which convey statistical correlations between itemsets A and B.

The Apriori algorithm is a seminal algorithm for mining frequent item sets for Boolean association rules.

Mining frequent itemsets and associations has been extended in various ways to include mining multilevel association rules and multidimensional association rules.

Not all strong association rules are interesting.

西安交通大學


![](https://web-api.textin.com/ocr_image/external/aad69470055e1227.jpg)

XIAN JAOIOSG ENIVIRSITY

