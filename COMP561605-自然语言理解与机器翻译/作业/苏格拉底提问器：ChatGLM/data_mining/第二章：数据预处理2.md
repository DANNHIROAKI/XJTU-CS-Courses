NIIAOTO UNIVERSITY 西安交通大學


![](https://web-api.textin.com/ocr_image/external/2443ba2cf3618e2e.jpg)

1896

XI'AN JIAOTONG UNIVERSITY

## 数据挖掘

## 第二章：数据预处理

## 刘均

## 陕西省天地网技术重点实验室

西安交通大学计算机学院

0..认识数据


![](https://web-api.textin.com/ocr_image/external/e657f2a70387eb53.jpg)

1...为什么要与处理数据

2...数据清理

<!-- 學 諨  -->
![](https://web-api.textin.com/ocr_image/external/c00797af23ea44a3.jpg)

3..数据集成和变换

4..数据归约


![](https://web-api.textin.com/ocr_image/external/c220f7a9c41b59f9.jpg)

基本要求：了解数据质量问题及其对挖掘的影响，掌握数据清理、集成和变换、归约等方法

2.0 认识数据

## 2.1 为什么要预处理数据

2.2 数据清理

2.3 数据集成和变换

2.4 数据归约

西安交通大學


![](https://web-api.textin.com/ocr_image/external/01c365661032acf9.jpg)

NIAN0A010SGENIVEESIEY

### 洞察数据有助于数据预处理与挖掘

数据由什么类型的属性或字段组成

属性具有何种类型的属性值


![](https://web-api.textin.com/ocr_image/external/47231b399cc6f1f2.jpg)

属性是离散的还是连续的

数据分布特性

数据可视化

西安交通大學


![](https://web-api.textin.com/ocr_image/external/116d1dfcc8b42946.jpg)

MIANHADIOSGLNIVESIEY

#### 2.0 认识数据-数据对象与属性类型

数据对象：数据集由数据对象组成，一个数据对象代表一个实体

顾客、商品、患者

又称样本、实例、数据点、元组等

## 属性：表示数据对象的一个特征

维、特征、变量

一个给定对象的一组属性称作属性向量（特征向量）

属性的类型由该属性可能具有的值的集合决定

西安交通大學


![](https://web-api.textin.com/ocr_image/external/a58653b81d0a8e99.jpg)

XIAN JAOIOSG ENIVIRSITY

## 2.0 认识数据-数据对象与属性类型

# 枚举类型（nominal attribute）：分类类型

属性值域是一个由符号、事物构成的有限集合

头发颜色、婚姻状态、职业

不具备有意义的序、不是定量的

可用众数（mode）度量中心趋势

# 二元属性（binary attribute）：布尔属性

只有两个类别与状态：0与1，true与false

对称的：两个状态分布或重要性相同。性别


![](https://web-api.textin.com/ocr_image/external/d7515f75fc817e72.jpg)

非对称的：两个状态分布或重要性不是相同的。HIV 检验。

西安交通大學


![](https://web-api.textin.com/ocr_image/external/aad69470055e1227.jpg)

XIAN JAOIONGLNIVERSIEY

## 2.0 认识数据-数据对象与属性类型

# 序数类型（ordinal attribute）

属性值之间存在有意义的序，相继值之间差是定性的

大中小、职位、军衔

可通过把数值量的值域划分为有限个有序列性得到序数类型

可用众数与中位数表示中心趋势

西安交通大學


![](https://web-api.textin.com/ocr_image/external/0de7a5ad411d9fdd.jpg)

NIAN0A0105GENIVERSIEY

## 2.0 认识数据-数据对象与属性类型

### 数值属性（numeric attribute）

可用整数或实数度量

区间标度（interval-scaled）属性：用相同的单位尺度度量。

可用众数、中位数、均值表示

比例标度（ratio-scaled）属性：可用倍数表示。

可用众数、中位数、均值表示

西安交通大學


![](https://web-api.textin.com/ocr_image/external/472f414bcb2e959b.jpg)

MIANHADIOSG LNIVEESIEY

## 2.0 认识数据-数据对象与属性类型

离散属性：具有有限个或无限可数个值

连续属性：如果属性不是离散的，则它是连续的，用实数表示

西安交通大學


![](https://web-api.textin.com/ocr_image/external/6b3700c07e5a79e6.jpg)

NIAN0A010SGENIVERSIEY

## 2.0 认识数据-数据基本统计描述


![](https://web-api.textin.com/ocr_image/external/5e405d60b1071b43.jpg)

### 动机：为了更好的理解数据

获得数据的总体印象

识别数据的典型特征

凸显噪声或离群点

## 度量数据的中心趋势

均值、中位数、众数（模）

## 度量数据的离散程度

四分位数、四分位数极差、方差等

西安交通大學


![](https://web-api.textin.com/ocr_image/external/913f3d0f95db55c6.jpg)

MIAN0ADIOSGENIVERSIEY

### 2.0 认识数据-数据基本统计描述

## 算术平均值加权算术平均$\overline { x } = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } x _ { i }$ $\overline { x } = \frac { \sum _ { i = 1 } ^ { n } w _ { i } x _ { i } } { \sum _ { i = 1 } ^ { n } w _ { i } }$

截断均值（trimmed mean）：去掉高、低极端值得到的均值

e．g．计算平均工资时，可以截掉上下各2％的值后计算均值，以抵消少数极端值的影响

中位数：有序集的中间值或者中间两个值平均

西安交通大學


![](https://web-api.textin.com/ocr_image/external/a58653b81d0a8e99.jpg)

XIAN JAOIOSG ENIVIRSITY

## 2.0 认识数据-数据基本统计描述

### 众数（Mode，模）：集合中出现频率最高的值

### 单峰的（unimodal，也叫单模态）、双峰的

# （bimodal）、三峰的（trimodal）；多峰的(multimodal)

<!-- ACuenbeL (uonc0eCuunu) 1210 8 6 4 2 456789101112123456 78 a.m. Noon p.m. Time of dav  -->
![](https://web-api.textin.com/ocr_image/external/1734459c192482b4.jpg)

<!-- f 1 2 3 4 5 6 7 8 9 X  -->
![](https://web-api.textin.com/ocr_image/external/9e972b983a531177.jpg)

## 对于适度倾斜（非对称的）的单峰频率曲线，可以使用以下经验公式计算众数

mean-mode=3×(mean-median)

西安交通大學

XIAN JAOIOSG ENIVIRSITY

## 2.0 认识数据-数据基本统计描述

对称数据

<!-- 均值 中位数 众数  -->
![](https://web-api.textin.com/ocr_image/external/34bd8d1f3b8a9763.jpg)

### 对称与正倾斜、负倾斜数据的中位数、均值和众数

负倾斜数据

<!-- 正倾斜数据 众数 均值 中位数  -->
![](https://web-api.textin.com/ocr_image/external/18fbd161988f7c5f.jpg)

<!-- 均值 众数 中位数  -->
![](https://web-api.textin.com/ocr_image/external/56b52668dbca68d0.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/ebc64caeacd4cc01.jpg)

XIAN JAOIONG LNIVERSIY

## 2.0 认识数据-数据基本统计描述

## 评估数值数据散布或发散的度量：极差、五数概括（基于四分位数）、中间四分位数极差和标准差


![](https://web-api.textin.com/ocr_image/external/cf48c91106a47b50.jpg)

极差（range）：数据集的最大值和最小值之差

<!-- 25% 25% 25% 25% Q1 Q2 Q3 Median  -->
![](https://web-api.textin.com/ocr_image/external/b766a45fbf8feefa.jpg)

百分位数（percentile）：第k个百分位数是具有如下性质的值x：k％的数据项位于或低于x

中位数就是第50个百分位数

四分位数： $Q _ { 1 } ( 2 5 ^ { t h } p e r c e n t i l e ) ,$ $Q _ { 3 } ( 7 5 ^ { t h } p e r c e n t i l e )$

中间四分位数极差(IQR): $\vert Q R = Q _ { 3 } - Q _ { 1 }$

孤立点：通常挑出落在至少高于第三个四分位数或低于第一个四分位数1.5XIQR处的值

西安交通大學


![](https://web-api.textin.com/ocr_image/external/ebbf261af6c014c3.jpg)

NIANHA0IOSGLNIVESIEY

## 2.0 认识数据-数据基本统计描述

## 评估数值数据散布或发散的度量：极差、五数概括（基于四分位数）、中间四分位数极差和标准差

<!-- 25% 25% 25% 25% Q1 Q2 Q3 Median  -->
![](https://web-api.textin.com/ocr_image/external/56be568a447a06e3.jpg)

<!-- Outer fence Outer fence =3.0 =13.5 Inner fence Inner fence Extreme Mild =5.25 M _ { d } = 8 = 11.25 outlier outliers Q _ { 1 } = 7 . 5 Q _ { 3 } = 9 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 1.5(IQR) 1.5(IQR) 3(IQR) 3(IQR)  -->
![](https://web-api.textin.com/ocr_image/external/7451da3321272f0e.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/9345fd66d445777b.jpg)

MAN HADIOSG LNIVEESIY

## 2.0 认识数据-数据基本统计描述

<table border="1" ><tr>
<td colspan="1" rowspan="1">State</td>
<td colspan="1" rowspan="1">EmploymentRatio (%)</td>
<td colspan="1" rowspan="1"> State</td>
<td colspan="1" rowspan="1">EmploymentRatio$( \% )$</td>
<td colspan="1" rowspan="1"> State</td>
<td colspan="1" rowspan="1">EmploymentRatio($( \% )$</td>
</tr><tr>
<td colspan="1" rowspan="1">Alabama</td>
<td colspan="1" rowspan="1">60.3</td>
<td colspan="1" rowspan="1">Kentucky</td>
<td colspan="1" rowspan="1">61.5</td>
<td colspan="1" rowspan="1">North Dakota</td>
<td colspan="1" rowspan="1">68.1</td>
</tr><tr>
<td colspan="1" rowspan="1">Alaska</td>
<td colspan="1" rowspan="1">68.8</td>
<td colspan="1" rowspan="1">Louisiana</td>
<td colspan="1" rowspan="1">59.4</td>
<td colspan="1" rowspan="1">Ohio</td>
<td colspan="1" rowspan="1">64.0</td>
</tr><tr>
<td colspan="1" rowspan="1">Arizona</td>
<td colspan="1" rowspan="1">63.3</td>
<td colspan="1" rowspan="1">Maine</td>
<td colspan="1" rowspan="1">65.1</td>
<td colspan="1" rowspan="1">Oklahoma</td>
<td colspan="1" rowspan="1">62.9</td>
</tr><tr>
<td colspan="1" rowspan="1">Arkansas</td>
<td colspan="1" rowspan="1">60.0</td>
<td colspan="1" rowspan="1">Maryland</td>
<td colspan="1" rowspan="1">67.2</td>
<td colspan="1" rowspan="1">Oregon</td>
<td colspan="1" rowspan="1">64.3</td>
</tr><tr>
<td colspan="1" rowspan="1">California</td>
<td colspan="1" rowspan="1">62.8</td>
<td colspan="1" rowspan="1">Mass.</td>
<td colspan="1" rowspan="1">66.5</td>
<td colspan="1" rowspan="1">Pennsylvania</td>
<td colspan="1" rowspan="1">61.6</td>
</tr><tr>
<td colspan="1" rowspan="1">Colorado</td>
<td colspan="1" rowspan="1">71.4</td>
<td colspan="1" rowspan="1">Michigan</td>
<td colspan="1" rowspan="1">66.0</td>
<td colspan="1" rowspan="1">Rhode Island</td>
<td colspan="1" rowspan="1">64.4</td>
</tr><tr>
<td colspan="1" rowspan="1">Connecticut</td>
<td colspan="1" rowspan="1">65.4</td>
<td colspan="1" rowspan="1">Minnesota</td>
<td colspan="1" rowspan="1">73.0</td>
<td colspan="1" rowspan="1">South Carolina</td>
<td colspan="1" rowspan="1">62.7</td>
</tr><tr>
<td colspan="1" rowspan="1">Delaware</td>
<td colspan="1" rowspan="1">64.7</td>
<td colspan="1" rowspan="1">Mississippi</td>
<td colspan="1" rowspan="1">58.0</td>
<td colspan="1" rowspan="1">South Dakota</td>
<td colspan="1" rowspan="1">71.1</td>
</tr><tr>
<td colspan="1" rowspan="1">Dist.Of Col.</td>
<td colspan="1" rowspan="1">63.4</td>
<td colspan="1" rowspan="1">Missouri</td>
<td colspan="1" rowspan="1">66.4</td>
<td colspan="1" rowspan="1">Tennessee</td>
<td colspan="1" rowspan="1">63.6</td>
</tr><tr>
<td colspan="1" rowspan="1">Florida</td>
<td colspan="1" rowspan="1">60.1</td>
<td colspan="1" rowspan="1">Montana</td>
<td colspan="1" rowspan="1">65.6</td>
<td colspan="1" rowspan="1">Texas</td>
<td colspan="1" rowspan="1">65.6</td>
</tr><tr>
<td colspan="1" rowspan="1">Georgia</td>
<td colspan="1" rowspan="1">66.8</td>
<td colspan="1" rowspan="1">Nebraska</td>
<td colspan="1" rowspan="1">71.0</td>
<td colspan="1" rowspan="1">Utah</td>
<td colspan="1" rowspan="1">69.6</td>
</tr><tr>
<td colspan="1" rowspan="1">Hawaii</td>
<td colspan="1" rowspan="1">63.2</td>
<td colspan="1" rowspan="1">Nevada</td>
<td colspan="1" rowspan="1">66.0</td>
<td colspan="1" rowspan="1">Vermont</td>
<td colspan="1" rowspan="1">69.9</td>
</tr><tr>
<td colspan="1" rowspan="1">Idaho</td>
<td colspan="1" rowspan="1">66.1</td>
<td colspan="1" rowspan="1">New Hamp.</td>
<td colspan="1" rowspan="1">70.3</td>
<td colspan="1" rowspan="1">Virginia</td>
<td colspan="1" rowspan="1">65.6</td>
</tr><tr>
<td colspan="1" rowspan="1">Illinois</td>
<td colspan="1" rowspan="1">66.7</td>
<td colspan="1" rowspan="1">New Jersey</td>
<td colspan="1" rowspan="1">64.1</td>
<td colspan="1" rowspan="1">Washington</td>
<td colspan="1" rowspan="1">66.9</td>
</tr><tr>
<td colspan="1" rowspan="1">Indiana</td>
<td colspan="1" rowspan="1">66.2</td>
<td colspan="1" rowspan="1">New Mexico</td>
<td colspan="1" rowspan="1">58.5</td>
<td colspan="1" rowspan="1">West Virginia</td>
<td colspan="1" rowspan="1">52.7</td>
</tr><tr>
<td colspan="1" rowspan="1">Iowa</td>
<td colspan="1" rowspan="1">70.1</td>
<td colspan="1" rowspan="1">New York</td>
<td colspan="1" rowspan="1">59.7</td>
<td colspan="1" rowspan="1">Wisconsin</td>
<td colspan="1" rowspan="1">70.1</td>
</tr><tr>
<td colspan="1" rowspan="1">Kansas</td>
<td colspan="1" rowspan="1">70.0</td>
<td colspan="1" rowspan="1">North Carolina</td>
<td colspan="1" rowspan="1">65.1</td>
<td colspan="1" rowspan="1">Wyoming</td>
<td colspan="1" rowspan="1">67.8</td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1eb3e4c4e179cc27.jpg)

XIAN JADIOSGENIVIRSITY

## 2.0 认识数据-数据基本统计描述

1.52.7 11.62.7 21.64.4 31.66.1 41.68.8

2.58 12.62.8 22.64.7 32.66.2 42.69.6

3.58.5 13.62.9 23.65.1 33.66.4 43.69.9

4.59.4 14.63.2 24.65.1 34.66.5 44.70

5.59.7 15.63.3 25.65.4 35.66.7 45.70.1

6.60 16.63.4 26.65.6 36.66.8 46.70.1

7.60.1 17.63.6 27.65.6 37.66.9 47.70.3

8.60.3 18.64 28.65.6 38.67.2 48.71

9.61.5 19.64.1 29.66 39.67.8 49.71.1

10.61.6 20.64.3 30.66 40.68.1 50.71.4

51.73

西安交通大學


![](https://web-api.textin.com/ocr_image/external/27b0e74c004f60b7.jpg)

XIAN JAOIOSG ENIVIRSITY

## 2.0 认识数据-数据基本统计描述

### 例子

## 60th Percentile

I=(60/100)*51=30.6

30.6不是整数，选择整数31，故数值为66.1


![](https://web-api.textin.com/ocr_image/external/9f518496090e9f51.jpg)

33th Percentile

1=(33/100)*51=16.83

16.83不是整数，选择整数17，故数值为63.6

Q1:13th-62.9;

Q3:38th-67.2

<table border="1" ><tr>
<td colspan="1" rowspan="1">Lower Fence=Q1-1.5(IQR)Upper Fence = Q3+1.5(IQR)</td>
</tr></table>

Q3-Q1=4.3

(62.9-1.5*4.3,

67.2+1.5*4.3)=(56.45,73.65)

The OUTLIER is 52.7

西安交通大學


![](https://web-api.textin.com/ocr_image/external/0cc5283056ec8354.jpg)

XIAN JAOIOSG ENIVIRSITY

## 2.0 认识数据-数据基本统计描述

五数概括：min， Q1， Median，Q3， max

盒图：数据分布的一种直观表示

### 方差和标准差

方差s2：n个观测$之 x _ { 1 } , x _ { 2 } \cdots x _ { n }$的方差是

$s ^ { 2 } = \frac { 1 } { n - 1 } \sum _ { i = 1 } ^ { n } ( x _ { i } - \overline { x } ) ^ { 2 } = \frac { 1 } { n - 1 } \sum _ { i = 1 } ^ { n } x _ { i } ^ { 2 } - \frac { 1 } { n } ( \sum _ { i = 1 } ^ { n } x _ { i } ) ^$

### 标准差s是方差s2的平方根

标准差s是关于平均值的离散的度量，因此仅当选平均值做中心度量时使用

所有观测值相同则s=0，否则s&gt;0

西安交通大學


![](https://web-api.textin.com/ocr_image/external/a987be64694154db.jpg)

XIAN JAOIOSGENIVIRSITY

## 2.0 认识数据-数据基本统计描述

### 例子：5个数据 30.8,31.7,30.1,31.6,32.1

平均值：31.26

$s ^ { 2 } = \frac { \sum _ { i = 1 } ^ { 5 } ( x _ { i } - \overline { x } ) ^ { 2 } } { 5 - 1 }$

$= \frac { ( 3 0 . 8 - 3 1 . 2 6 ) ^ { 2 } + ( 3 1 . 7 - 3 1 . 2 6 ) ^ { 2 } + ( 3 0 . 1 - 3 1 . 2 6 ) ^ { 2 } + ( 3 1 . 6 - 3 1 . 2 6 ) ^ { 2 } + ( 3 2 . 1 - 3 1 . 2 6 ) ^ { 2 } } { 4 }$

$= \frac { 2 . 5 7 2 } { 4 } = 0 . 6 4 3$

$s = \sqrt { s ^ { 2 } } = \sqrt { 0 . 6 4 3 } = 0 . 8 0 1 9$

西安交通大學


![](https://web-api.textin.com/ocr_image/external/ec866f65b0c1e63a.jpg)

NIANHADIOSGLNIVESIY

## 2.0 认识数据-数据基本统计描述


![](https://web-api.textin.com/ocr_image/external/be041179450df213.jpg)

68.26％的数据分布在[μ±s]=[31.6±0.8]=[30.8,32.4]

95.44％的数据分布在[μ±2s]=[31.6±1.6]=[30.0,33.2]

99.73％的数据分布在[μ±3s]=[31.6±2.4]=[29.2,34.0]

至少（1-1／k2）的数据分布在[u-ks,μ+ks]

<!-- (a)The Empirical Rule 68.26% of the population measurements are within (plus or minus) one standard devlation of the mean μ-σ μ μ+σ 95.44% of the population measurements are within (plus or minus) two standard devlations of the mean μ-2σ μ μ+2σ 99.73% of the population measurements are within (plus or minus) three standard devlations of the mean μ-30 μ μ+3σ  -->
![](https://web-api.textin.com/ocr_image/external/28df0576619803ea.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/27b0e74c004f60b7.jpg)

XIAN JAOIONG LNIVERSIEY

## 2.0 认识数据-数据基本统计描述

盒图：数据分布的一种直观表示：

端点在四分位数上，使得盒图的长度是IQR

中位数M用盒内的线标记

胡须延伸到最大最小观测值

该盒图为在给定时间段在AllElectronics的4个分店销售的商品单价的盒图

分店1：中位数＄80，Q1：＄60,Q3:&#36;100

<!-- 200.0 180.0 160.0 140.0 120.0 (2)8F형 100.0 80.0 60.0 40.0 20.0 Branch 1 Branch 2 Branch 3 Branch 4  -->
![](https://web-api.textin.com/ocr_image/external/ea3b5a3aad191513.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/27b0e74c004f60b7.jpg)

XIAN JAOIONG UNIVERSIY

## 2.0 认识数据-数据基本统计描述

## 常用的显示数据汇总和分布的方法

直方图、分位数图、q-q图、散点图和局部回归曲线

###### 直方图：一种单变量图形表示方法

将数据分布划分成不相交的子集或桶，通常每个桶宽度一致并用一个矩形表示，其高度表示桶中数据在给定数据中出现的计数或频率

<!-- 40 35 30 25 20 15 10 5 O 10000 30000 50000 70000 90000  -->
![](https://web-api.textin.com/ocr_image/external/9bed2e217f54e9d8.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/a987be64694154db.jpg)

MIANH010SGLNIVEESIEY

### 2.0 认识数据-数据基本统计描述

#### 直方图能够比盒图展现更？的信息

两个直方图具有相同的min， Q1， median，Q3， max

但是它们具有不同数据分布


![](https://web-api.textin.com/ocr_image/external/fc8e6cf82a505738.jpg)


![](https://web-api.textin.com/ocr_image/external/b3fdb633cd5e6058.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/e8a8fb825a812ee3.jpg)

XIAN JAOIOSGUNIVERSIEY

### 2.0 认识数据-数据基本统计描述

分位数图：一种利用分位数信息观察单变量数据分布的简单有效方法

显示所有数据，允许用户评估总的情况和不寻常情况的出现

设x是递增排序的数据，则每个x都有相对应的f，指出大约有100fj％的数据小于等于xj

<!-- 140 120 (9)aud mn 100 80 60 40 20 0 0.000 0.250 0.500 0.750 1.000 f-value  -->
![](https://web-api.textin.com/ocr_image/external/84074a1d49fd5e52.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/07207d2b06a93c1a.jpg)

NIANHADIOSG LNIVERSIEY

### 2.0 认识数据-数据基本统计描述

分位数-分位数图（Q-Q图）：对着另一个单变量的分位数，绘制一个单变量分布的分位数

允许用户观察是不是有从一个分布到另外一个分布的迁移

Example shows unit price of items sold at Branch 1 vs.Branch 2 for each quantile.Unit prices of items sold at Branch 1 tend to be lower than those at Branch 2.

<!-- 120 (Saoid un)4ueAg 110 100 90 80 70 60 50 40 40 50 60 70 80 90 100 110 120 Branch 1(unit price &#36;)  -->
![](https://web-api.textin.com/ocr_image/external/61bd48e515435ed2.jpg)

西安交通大學

XIANHAOIOSGENIVIRSITY

### 2.0 认识数据-数据基本统计描述

散点图：确定两个量化的变量之间看上去是否有联系、模式或者趋势的最有效的图形方法之一

散点图中的每个值都被视作代数坐标对，作为一个点画在平面上

易于观察双变量数据在平面上的分布

<!-- 700 600 PIos SuanI 500 400 300 200 100 0 0 20 40 60 80 100 120 140 Unit price (&#36;)  -->
![](https://web-api.textin.com/ocr_image/external/a38a6538b57a5302.jpg)

西安交通大學

XIAN JAOIONG ENIVIESITY

### 2.0 认识数据-数据基本统计描述

#### 散点图矩阵

<!-- 60 （日）半 50 40 20 1 18 金 16 14 企鹅种类 240 阿德利 帽带 220 白眉 （半 200 180 6000 ) 州 ( 5000 4000 3000 30 40 50 60 12 14 16 18 20 22 180 200 4000 5000 6000 7000 喙长（mm） 喙深（mm） 鳍长（mm） 220 240 2000 3000 体重（g）  -->
![](https://web-api.textin.com/ocr_image/external/1599aba5c0ab6f10.jpg)

Palmer企鹅数据集包含3种（阿德利、白眉、帽带）共344只企鹅的数据

西安交通大學


![](https://web-api.textin.com/ocr_image/external/448dec58c8d68220.jpg)

XIAN JADIOSGENIVIRSITY

### 2.0 认识数据-数据基本统计描述

### 条件散点图

<!-- 性别＝雄性 性别＝雌性 6000 5500 5000 ( ) 4500 企鹅种类 阿德利 帽带 4000 白眉 3500 3000 35 45 50 55 60 35 50 55 喙长（mm） 喙长（mm） 60  -->
![](https://web-api.textin.com/ocr_image/external/1af14f351451191e.jpg)

一个条件变量

（性别）

<!-- 性别＝维性｜岛屿＝Torgersen 性别＝雄性｜岛屿＝Biscoe 性别＝雄性｜岛屿＝Dream 6000 5500 5000 x 4500 4000 3500 3000 性别＝雌性｜岛屿＝Torgersen 性别＝雌性 岛屿＝Biscoe 性别＝雌性｜岛屿＝Dream 企鹅种类 阿德利 帽带 6000 白眉 5500 5000 4500 4000 3500 3000 35 40 喙长（mm） 50 55 60 35 喙长（mm） 50 55 60 35 40 喙长（mm） 50 55  -->
![](https://web-api.textin.com/ocr_image/external/9bbb318653afca58.jpg)

两个条件变量（性别与岛屿）

西安交通大學


![](https://web-api.textin.com/ocr_image/external/c5f1576af8fd619a.jpg)

XIAN JAOIONG LNIVERSIY

#### 2.0 认识数据-数据基本统计描述

散点图：确定两个量化的变量之间看上去是否有联系、模式或者趋势的最有效的图形方法之一

散点图中的每个值都被视作代数坐标对，作为一个点画在平面上

易于观察双变量数据在平面上的分布

<!-- 700 600 PIos SuanI 500 400 300 200 100 0 0 20 40 60 80 100 120 140 Unit price(&#36;)  -->
![](https://web-api.textin.com/ocr_image/external/ffe73cc28da4a9b8.jpg)

西安交通大學

XIAN JAOIONG ENIVIESITY

#### 2.0 认识数据-数据基本统计描述

loess曲线为散点图添加一条平滑的曲线，以便更好的观察两个变量间的依赖模式

Loess（local regression）意指“局部回归”，为了拟合loess曲线，需要两个参数：平滑参数α，被回归拟合的多项式的阶入

<!-- 700 600 PIos SuaI 500 400 300 200 100 0 0 20 40 60 80 100 120 140 Unit price (&#36;)  -->
![](https://web-api.textin.com/ocr_image/external/b8ed5849070c1f35.jpg)

西安交通大學

XIAN JAOIONG ENIVIESITY

#### 2.0 认识数据-数据基本统计描述

##### 皮尔逊相关系数（Pearson correlation coefficient）度量两个变量X和Y之间的线性相关程度，介于-1与1之间。

$r = \frac { \sum _ { i = 1 } ^ { n } ( x _ { i } - \overline { x } ) ( y _ { i } - \overline { y } ) } { \sqrt { \sum _ { i = 1 } ^ { n } ( x _ { i } - \overline { x } ) ^ { 2 } } \sqrt { \sum _ { i = 1 } ^ { n } ( y _ { i } - \overline { y } ) ^ { 2$

西安交通大學


![](https://web-api.textin.com/ocr_image/external/158b6a91d3c8f24e.jpg)

MIANHADIOSGLNIVESIY

#### 2.0 认识数据-数据基本统计描述


![](https://web-api.textin.com/ocr_image/external/cd7a6ce88ebe9b74.jpg)


![](https://web-api.textin.com/ocr_image/external/af45d0b14a7922e2.jpg)

左半部分是正相关


![](https://web-api.textin.com/ocr_image/external/88a0dc3955137272.jpg)

右半部分是负相关

西安交通大學


![](https://web-api.textin.com/ocr_image/external/3150bfecade90d2b.jpg)

XIAN JAOIONG LNIVERSIY

#### 2.0 认识数据-数据基本统计描述


![](https://web-api.textin.com/ocr_image/external/d9e25f5d8bf5b2ba.jpg)


![](https://web-api.textin.com/ocr_image/external/a148e0bab1ddf869.jpg)


![](https://web-api.textin.com/ocr_image/external/4c5c5473f60871d5.jpg)

## 不相关数据

西安交通大學


![](https://web-api.textin.com/ocr_image/external/5bdedc8ba51c22b5.jpg)

XIAN JAOIONG ENIVIESITY

# 统计量与群智

## 群体智能：群体在宏观层面涌现出的超过个体的智能水平。

<table border="1" ><tr>
<td colspan="1" rowspan="1">CIf(X)X1 X2 X3 Xn范式1：无交互、无反馈<img src="https://web-api.textin.com/ocr_image/external/bee4aaf7182ce864.jpg"></td>
<td colspan="1" rowspan="1">CIf(X, E)X1E范式2：有交互、无反馈<img src="https://web-api.textin.com/ocr_image/external/e5384d36fcf9dddc.jpg"></td>
<td colspan="1" rowspan="1">CIf(X, E)X1 X2 X3E范式3：有交互、有反馈<img src="https://web-api.textin.com/ocr_image/external/8953d367d82005b8.jpg"></td>
</tr><tr>
<td colspan="1" rowspan="1">--NTHE WISDOMOF CROWDSJAMESSUROWIECKI<img src="https://web-api.textin.com/ocr_image/external/6f17e9fb6c2d340d.jpg"><img src="https://web-api.textin.com/ocr_image/external/1449272354c747e9.jpg"></td>
<td colspan="1" rowspan="1">DHT0 x 定理的X0 合作证明<img src="https://web-api.textin.com/ocr_image/external/88f8b4a38a63613a.jpg"></td>
<td colspan="1" rowspan="1">Nest FoodDObstacle<img src="https://web-api.textin.com/ocr_image/external/7cc5f0829d5ff7b3.jpg"></td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/c7c7f4bb86980cf5.jpg)

XIAN JIADIOSG ENIVIESITY

# 统计量与群智

 设个个体的估值为 $x _ { 1 } , x _ { 2 } , \cdots , x _ { i } , \cdots , x _ { n }$ ，真实值为$x _ { T }$，群体误差（Collective Error，CE）则是该估值的均值与真实值的平方离差（Squared Deviation），

即$( x _ { T } - \overline { x } ) ^ { 2 }$, $\overline { x } = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } x _ { i }$

群体多样性（Group Diversity，GD）是估值的方差，即 $\frac { 1 } { n } \sum _ { i = 1 } ^ { n } ( x _ { i } - \overline { x } ) ^ { 2 }$

平均个体误差（Average Individual Error，AIE）是指个体估值与真实值平方离差的均值， $\frac { 1 } { n } \sum _ { i = 1 } ^ { n } ( x _ { i } - x _ { T } ) ^ { 2 }$。多样性预测定理： CE=AIE-GD

当多样性较大时，有助于降低群体误差，促进群智的产生

西安交通大學


![](https://web-api.textin.com/ocr_image/external/4b463883d98187a1.jpg)

XIAN JAOIONGLNIVERSIY

# 统计量与群智

中位数在群智中起作用的一个重要原因：无论真实值是多少，群体估测值的中位数比至少50％的个体的估测值更接近真实值。

# 孔多塞陪审团定理（Condorcet＇s Jury

Theorem）：如果群体中的个体独立进行决策，并且正确决策的概率大于0.5，那么群体按多数票策略正确决策的概率随着群体规模的增大而增大。

西安交通大學


![](https://web-api.textin.com/ocr_image/external/3b4b95610ba40981.jpg)

XIAN JAOIOSG ENIVIESITY

2.0 认识数据

## 2.1 为什么要预处理数据

2.2数据清理

2.3 数据集成和变换

2.4 数据归约

西安交通大學


![](https://web-api.textin.com/ocr_image/external/01c365661032acf9.jpg)

MIANH0105GENIVEESIEY

# 统计量与群智

# 现实世界的数据是“脏的”

## 不完整（incomplete）

缺少数据值；缺乏某些重要属性；仅包含汇总数据

## 有噪声（noisy）

包含错误或者孤立点（outliers）

数据不一致（inconsistent）

e.g.，在编码或者命名上存在差异

e.g., Age= “42” Birthday= “03/07/1997”

GIGO （Garbage in， garbage out）原理：No quality data, no quality mining results!

西安交通大學


![](https://web-api.textin.com/ocr_image/external/5fc6077ce922fb75.jpg)

XIAN JAOIONG LNIVERSIY

### 2.1 为什么要预处理数据

#### 广为认可的数据质量多维度量

精确度........可信度

完整度........可增值性

一致性........可解释性

时效性........可访问性

西安交通大學


![](https://web-api.textin.com/ocr_image/external/b9daf1960f2269d2.jpg)

MIANHADIOSGLNIVESIY

### 2.1 为什么要预处理数据

#### 数据处理的主要任务

## 数据清理

填写空缺的值，平滑噪声数据，识别、删除孤立点，解决不一致性

## 数据集成

集成多个数据库、数据立方体或文件

## 数据变换

规范化和聚集

## 数据归约

得到数据集的压缩表示，但可得到相同或相近的结果

## 数据离散化

通过概念分层和数据离散化来规约数据，对数值型数据特别重要

西安交通大學


![](https://web-api.textin.com/ocr_image/external/e5de76b27c7da00b.jpg)

XIAN JAOIONG ENIVIESITY

### 2.0 认识数据

#### 2.1 为什么要预处理数据

2.2 数据清理

2.3 数据集成和变换

2.4 数据归约

西安交通大學


![](https://web-api.textin.com/ocr_image/external/01c365661032acf9.jpg)

NIAN0A010SGENIVEESIEY

##### 业界对数据清理的认识

“数据清理是数据仓库构建中最重要的问题”-DCI survey

## 数据清理任务

填写空缺值

识别离群点和平滑噪声数据

纠正不一致的数据

解决数据集成造成的冗余

西安交通大學


![](https://web-api.textin.com/ocr_image/external/381d735a5fa43972.jpg)

MIANHADIOSGLNIVERSIEY

## 空缺值

## 数据并不总是完整的

例如：数据库表中，很多条记录的对应字段没有相应值，比如销售表中的顾客收入


![](https://web-api.textin.com/ocr_image/external/e1bc91769823d223.jpg)

## 引起空缺值的原因

设备异常

·与其他已有数据不一致而被删除

·因为误解而没有被输入的数据

在输入时，有些数据应为得不到重视而没有被输入

## 空缺值要经过推断而补上

西安交通大學


![](https://web-api.textin.com/ocr_image/external/2386f9b3a5dcbe55.jpg)

MIANHADIOSGLNIVESIEY

## 如何处理空缺值

忽略元组：当类标号缺少时通常这么做（假定挖掘任务设计分类或描述），当每个属性缺少值的百分比很大时，它的效果非常差。

人工填写空缺值：工作量大，可行性低

使用一个全局变量填充空缺值：比如使用unknown或-

使用属性的平均值填充空缺值

使用与给定元组属同一类的所有样本的平均值

使用最可能的值填充空缺值：使用像Bayesian公式或判定树这样的基于推断的方法

西安交通大學


![](https://web-api.textin.com/ocr_image/external/228e4cef9f3a718c.jpg)

XIAN JAOIOSG LNIVERSIEY

## 噪声数据

噪声：一个测量变量中的随机错误或偏差

## 引起噪声的原因

数据收集工具的问题

·数据输入错误

·数据传输错误

·命名规则的不一致

西安交通大學


![](https://web-api.textin.com/ocr_image/external/4fc84ecbcfd3d815.jpg)

MIANHADIOSG LNIVERSIEY

## 噪声数据处理

# 分箱（binning）：

·首先排序数据，并将他们分到等深的箱中

可以按箱的平均值平滑、按箱中值平滑、按箱的边界平滑


![](https://web-api.textin.com/ocr_image/external/3e4d56318c207836.jpg)

回归：通过让数据适应回归函数来平滑数据

聚类：检测并且去除孤立点

计算机和人工检查结合：计算机检测可疑数据，然后对它们进行人工判断

西安交通大學


![](https://web-api.textin.com/ocr_image/external/8176b752d40c1c4d.jpg)

XIAN JAOIOSGENIVIRSITY

# 分箱方法

price的排序后数据：4,8,15,21,21,24,25,28,34

划分为（等深的）箱：

箱1：4,8,15

箱2：21,21,24

箱3：25,28,34

## 用箱平均值平滑：

箱1：9,9,9

箱2：22,22,22

箱3：29,29,29

## 用箱边界平滑：

箱1：4,4,15

箱2：21,21,24

箱3：25,25,34

西安交通大學


![](https://web-api.textin.com/ocr_image/external/a0b2cdead1bd485a.jpg)

MIANHADIOSGLNIVESIEY

回归

<!-- y 。 Y1 。 。 。 Y1' 。 y=x+1 。 。 。 X1 X  -->
![](https://web-api.textin.com/ocr_image/external/3346814b1c72a850.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/c5f1576af8fd619a.jpg)

NIANHA01SGLNIVESIY

## 聚类

<!-- 十  -->
![](https://web-api.textin.com/ocr_image/external/555c55a58b24727e.jpg)

通过聚类分析检测离群点，消除噪声：聚类将类似的值聚成簇。直观的，落在簇集合之外的值被视为离群点

西安交通大學


![](https://web-api.textin.com/ocr_image/external/5bdedc8ba51c22b5.jpg)

XIAN JAOIONG LNIVERSIY

## 2.0 认识数据

### 2.1 为什么要预处理数据

2.2 数据清理

2.3 数据集成和变换

2.4数据归约

西安交通大學


![](https://web-api.textin.com/ocr_image/external/01c365661032acf9.jpg)

MIANADIOSGENIVEESIEY

### 2.3 数据集成和变换

数据集成：将多个数据源中的数据整合到一个一致的存储中

模式集成：整合不同数据源中的元数据？

e.g.A.cust_id =B.customer_no

#### 实体识别问题：

匹配来自不同数据源的现实世界的实体

e.g. Bill Clinton = William Clinton

#### 检测并解决数据值的冲突

对现实世界中的同一实体，来自不同数据源的属性值可能是不同的

可能的原因：不同的数据表示，不同的度量等

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1ef9580aaacb1ec9.jpg)

XIAN JAOIONG LNIVERSIY

### 2.3 数据集成和变换

## 数据集成中的冗余数据处理


![](https://web-api.textin.com/ocr_image/external/ce421fa47ddfab12.jpg)

集成多个数据库时，经常会出现冗余数据

对象识别：同一属性或对象在不同数据库中会有不同字段名

可导出数据：一个属性可以由另外一个表导出，如“年薪”


![](https://web-api.textin.com/ocr_image/external/d4166bd1fcc475cd.jpg)

## 有些冗余可以被相关分析检测到

$r _ { x y } = \frac { \sum _ { i = 1 } ^ { n } ( x _ { i } - \overline { x } ) ( y _ { i } - \overline { y } ) } { \sqrt { \sum _ { i = 1 } ^ { n } ( x _ { i } - \overline { x } ) ^ { 2 } } \sqrt { \sum _ { i = 1 } ^ { n } ( y _ { i } - \overline { y$

<table border="1" ><tr>
<td colspan="1" rowspan="1">$- 1 < = r _ { x y } < = 1$，大于0时正相关，小</td>
</tr><tr>
<td colspan="1" rowspan="1">于0时负相关。绝对值越接近于1，两素关系越密切；越接近于0，越不密切</td>
</tr></table>

皮尔逊系数

将多个数据源中的数据集成起来，能减少或避免冗余与不一致性，从而可以提高挖掘的速度和质量。

西安交通大學


![](https://web-api.textin.com/ocr_image/external/ca0740c78c62dddd.jpg)

XIAN JAOIOSG ENIVIRSITY

## 相关性分析用于属性选择


![](https://web-api.textin.com/ocr_image/external/476f1bf76d38fa35.jpg)

## 属性A1与A2是相互独立的吗？

·如果它们是相互依赖的，则可以任意去除一个

·如果A1与类标签属性A2是独立的，可以从训练集中去除属性A1

<table border="1" ><tr>
<td colspan="6" rowspan="1">ID Outlook Temperature Humidity Windy Play</td>
</tr><tr>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">100</td>
<td colspan="1" rowspan="1">40</td>
<td colspan="1" rowspan="1">90</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">T</td>
</tr><tr>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">100</td>
<td colspan="1" rowspan="1">40</td>
<td colspan="1" rowspan="1">90</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">F</td>
</tr><tr>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">50</td>
<td colspan="1" rowspan="1">40</td>
<td colspan="1" rowspan="1">90</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">T</td>
</tr><tr>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">10</td>
<td colspan="1" rowspan="1">30</td>
<td colspan="1" rowspan="1">90</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">T</td>
</tr><tr>
<td colspan="1" rowspan="1">5</td>
<td colspan="1" rowspan="1">10</td>
<td colspan="1" rowspan="1">15</td>
<td colspan="1" rowspan="1">70</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">T</td>
</tr><tr>
<td colspan="1" rowspan="1">6</td>
<td colspan="1" rowspan="1">10</td>
<td colspan="1" rowspan="1">15</td>
<td colspan="1" rowspan="1">70</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">F</td>
</tr><tr>
<td colspan="1" rowspan="1">7</td>
<td colspan="1" rowspan="1">50</td>
<td colspan="1" rowspan="1">15</td>
<td colspan="1" rowspan="1">70</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">T</td>
</tr><tr>
<td colspan="1" rowspan="1">8</td>
<td colspan="1" rowspan="1">100</td>
<td colspan="1" rowspan="1">30</td>
<td colspan="1" rowspan="1">90</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">F</td>
</tr><tr>
<td colspan="1" rowspan="1">9</td>
<td colspan="1" rowspan="1">100</td>
<td colspan="1" rowspan="1">15</td>
<td colspan="1" rowspan="1">70</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">T</td>
</tr><tr>
<td colspan="1" rowspan="1">10</td>
<td colspan="1" rowspan="1">10</td>
<td colspan="1" rowspan="1">30</td>
<td colspan="1" rowspan="1">70</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">F</td>
</tr><tr>
<td colspan="1" rowspan="1">11</td>
<td colspan="1" rowspan="1">100</td>
<td colspan="1" rowspan="1">30</td>
<td colspan="1" rowspan="1">70</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">F</td>
</tr><tr>
<td colspan="1" rowspan="1">12</td>
<td colspan="1" rowspan="1">50</td>
<td colspan="1" rowspan="1">30</td>
<td colspan="1" rowspan="1">90</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">T</td>
</tr><tr>
<td colspan="1" rowspan="1">13</td>
<td colspan="1" rowspan="1">50</td>
<td colspan="1" rowspan="1">40</td>
<td colspan="1" rowspan="1">70</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">T</td>
</tr><tr>
<td colspan="1" rowspan="1">14</td>
<td colspan="1" rowspan="1">10</td>
<td colspan="1" rowspan="1">30</td>
<td colspan="1" rowspan="1">90</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">F</td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1d5f2dfc1add5fa0.jpg)

XIAN JIADIOSG ENIVIESITY

## 2.3 数据集成和变换

## 离散数据的相关性分析

### ×2（chi-square）测试（卡方测试）


![](https://web-api.textin.com/ocr_image/external/8041b88dd3496c2d.jpg)

$\chi ^ { 2 } = \sum \frac { ( O b \sec r v e d - E x p e c t e d ) ^ { 2 } } { E x p e c t e d }$


![](https://web-api.textin.com/ocr_image/external/1c381ba0ffe9ce18.jpg)

x2的值越大，意味着两个变量相关的可能性越大


![](https://web-api.textin.com/ocr_image/external/1c62ae74df6940c8.jpg)

期望值和观测值之间相差越大，值也将越大

相关性不意味着因果关系

e.g.我们发现一个地区的医院数和汽车盗窃数相关

西安交通大學


![](https://web-api.textin.com/ocr_image/external/74523a17faa3d028.jpg)

XIAN JAOIOSG ENIVIRSITY

## 相关性分析用于属性选择

<table border="1" ><tr>
<td colspan="1" rowspan="1">Outlook</td>
<td colspan="1" rowspan="1">Temperature</td>
</tr><tr>
<td colspan="1" rowspan="1">Sunny</td>
<td colspan="1" rowspan="1">High</td>
</tr><tr>
<td colspan="1" rowspan="1">Cloudy</td>
<td colspan="1" rowspan="1">Low</td>
</tr><tr>
<td colspan="1" rowspan="1">Sunny</td>
<td colspan="1" rowspan="1">High</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">TemperatureOutlook</td>
<td colspan="1" rowspan="1">High</td>
<td colspan="1" rowspan="1">Low</td>
<td colspan="1" rowspan="1">OutlookSubtotal</td>
</tr><tr>
<td colspan="1" rowspan="1">Sunny</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">2</td>
</tr><tr>
<td colspan="1" rowspan="1">Cloudy</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
</tr><tr>
<td colspan="1" rowspan="1">TemperatureSubtotal:</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">Total countin table=3</td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/b349a95dc08b7d2b.jpg)

XIAN JAOIOSG LNIVERSIEY

### 2.3 数据集成和变换

## 零假设Ho：Outlook与Temperature无关。

<table border="1" ><tr>
<td colspan="1" rowspan="1">Outlook</td>
<td colspan="1" rowspan="1">Temperature</td>
</tr><tr>
<td colspan="1" rowspan="1">Sunny</td>
<td colspan="1" rowspan="1">High</td>
</tr><tr>
<td colspan="1" rowspan="1">Cloudy</td>
<td colspan="1" rowspan="1">Low</td>
</tr><tr>
<td colspan="1" rowspan="1">Sunny</td>
<td colspan="1" rowspan="1">High</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1">Temperature→Outlook</td>
<td colspan="1" rowspan="1">High</td>
<td colspan="1" rowspan="1">Low</td>
<td colspan="1" rowspan="1">OutlookSubtotal</td>
</tr><tr>
<td colspan="1" rowspan="1">Sunny</td>
<td colspan="1" rowspan="1">$3 * 2 / 3 * 2 / 3 =$1.33</td>
<td colspan="1" rowspan="1">$3 * 2 / 3 * 1 / 3$$= 0 . 6 7$</td>
<td colspan="1" rowspan="1">2</td>
</tr><tr>
<td colspan="1" rowspan="1">Cloudy</td>
<td colspan="1" rowspan="1">$3 ^ { * } 1 / 3 ^ { * } 2 / 3 =$0.67</td>
<td colspan="1" rowspan="1">$3 ^ { * } 1 / 3 ^ { * } 1 / 3$$= 0 . 3 3$</td>
<td colspan="1" rowspan="1">1</td>
</tr><tr>
<td colspan="1" rowspan="1">TemperatureSubtotal:</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">Totalcount in$\tan ( e = 3$</td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/10661f88750bb301.jpg)

XIAN JAOIONG LNIVERSIY

## 2.3 数据集成和变换

## 零假设Ho：Outlook与Temperature无关。

The chi-squared formula is:

Chi-square$( x ^ { 2 } ) = \frac { ( 0 _ { 1 } - e _ { 1 } ) ^ { 2 } } { e _ { 1 } } + \frac { ( 0 _ { 2 } - e _ { 2 } ) ^ { 2 } } { \epsilon _ { 2 } } + \cdots \cdots + \frac { ( 0 _ { n } - e _ { n } ) ^ { 2 } } { \epsilon _ { n } }$

$c h i - s q u a r e d ( x ^ { 2 } ) = \frac { ( 2 - 1 . 3 3 ) ^ { 2 } } { 1 . 3 3 } + \frac { ( 0 . 6 7 ) ^ { 2 } } { 0 . 6 7 } + \frac { ( 0 - 0 . 6 7 ) ^ { 2 } } { 0 . 6 7 } + \frac { ( 1 - 0 . 3 3 ) ^ { 2 } } {$

=0.33+0.67+0.67+1.33=3

## 确定自由度（？）为(2-1)×(2-1)=1(if table has n*m items,then freedom＝（n-1）＊（m-1）），选择显著水平α=0.05。

3&lt;3.84!

不能拒绝零假设

<table border="1" ><tr>
<td colspan="1" rowspan="1">Degrees of Freedom</td>
<td colspan="5" rowspan="1">Probability,p</td>
</tr><tr>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">0.99</td>
<td colspan="1" rowspan="1">0.95</td>
<td colspan="1" rowspan="1">0.05</td>
<td colspan="1" rowspan="1">0.01</td>
<td colspan="1" rowspan="1">0.001</td>
</tr><tr>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">0.000</td>
<td colspan="1" rowspan="1">0.004</td>
<td colspan="1" rowspan="1">3.84</td>
<td colspan="1" rowspan="1">6.64</td>
<td colspan="1" rowspan="1">10.83</td>
</tr><tr>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">0.020</td>
<td colspan="1" rowspan="1">0.103</td>
<td colspan="1" rowspan="1">5.99</td>
<td colspan="1" rowspan="1">9.21</td>
<td colspan="1" rowspan="1">13.82</td>
</tr></table>

西安交通大學

XIAN JAOIONGUNIVERSIY

## 2.3 数据集成和变换

# 数据变换：将数据转换或统一成适合挖掘的形式

规范化：将数据按比例缩放，使之落入一个小的特定区间

·最小-最大规范化

z-score规范化

小数定标规范化


![](https://web-api.textin.com/ocr_image/external/ae8a58cf4ebbf1dc.jpg)

属性构造：通过现有属性构造新的属性，并添加到属性集中；以增加对高维数据的结构的理解和精确度

数据泛化：沿概念分层向上汇总

西安交通大學


![](https://web-api.textin.com/ocr_image/external/4fc84ecbcfd3d815.jpg)

MIANHADIOSGLNIVESIEY

## 2.3 数据集成和变换

##  最小-最大规范化

$V ^ { \prime } = \frac { v - \min _ { A } } { m a x _ { A } - \min _ { A } } ( n e w - m a x _ { A } - n e w _ { A } ) + n e w _ { - } m \in$

 z-score规范化：最大最小值未知，或者离群点影响较大的时候适用

$v ^ { \prime } = \frac { v - m e a n _ { A } } { s \tan d a r d _ { - } d e v _ { A } }$

## 小数定标规范化

$v ^ { \prime } = \frac { v } { 1 0 ^ { j } }$

其中，j是使 Max（W＇）＜1的最小整数

西安交通大學


![](https://web-api.textin.com/ocr_image/external/4fc84ecbcfd3d815.jpg)

MIANHADIOSGLNIVESIY

## 2.3 数据集成和变换

### 虚拟变量陷阱（Dummy Variable Trap）

指虚拟变量之间是多重共线性（Multicollinearity），一个变量可以预测其它变量的值。

·Dummy variable trap collinearity)This model cannot be estimated (perfect

$w a g e = \beta _ { 0 } + \gamma o m a l e + \delta _ { 0 } f e m a l e + \beta _ { 1 } e d u c + u$

原特征有m个类别时，可转换成m-1个虚拟变量。


![](https://web-api.textin.com/ocr_image/external/f8be8e02532673f9.jpg)

http://www.ce.memphis.edu/7012/Lecture17_MLR_Dummy.pdf

西安交通大學


![](https://web-api.textin.com/ocr_image/external/b0a28b4873a847ee.jpg)

XIAN JADIONG ENIVIESITY

## 2.0 认识数据

### 2.1 为什么要预处理数据

2.2 数据清理

2.3 数据集成和变换

2.4 数据归约

西安交通大學


![](https://web-api.textin.com/ocr_image/external/01c365661032acf9.jpg)

NIAN0A010SGENIVEESIEY

### 2.4 数据归约

## 为什么需要进行数据规约？

在海量数据上进行复杂数据分析与挖掘需要很大的时空开销

数据归约（data reduction）：用来得到数据集的归约表示，它小得多，但可产生相同或几乎相同的分析结果

常用的归约策略

维归约，e.g.移除不重要的属性

数据压缩

数值归约，e.g.使用模型来表示数据

离散化和概念分层产生

# 用于数据归约的时间不应当超过或“抵消”在归约后的数据上挖掘节省的时间

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1ef9580aaacb1ec9.jpg)

XIAN JAOIOSG LNIVERSIEY

## 2.4 数据归约

# 数据压缩

有损压缩 VS.无损压缩

<!-- 原始数据 压缩后 的数据 无损压缩 近似的 有损压缩 原始数据  -->
![](https://web-api.textin.com/ocr_image/external/2324a81ab9620c0d.jpg)

字符串压缩

·有广泛的理论基础和精妙的算法

·通常是无损压缩

·在解压缩前对字符串的操作非常有限

## 音频／视频压缩

通常是有损压缩，压缩精度可以递进选择

·有时可以在不解压整体数据的情况下，重构某个片断

两种有损数据压缩的方法：小波变换和主要成分分析

西安交通大學

NIANHADIOSGLNIVESIY

## 2.4 数据归约- 数值规约

### 维归约

通过删除不相干的属性或维减少数据量

属性子集选择（特征选择）

数值规约

通过选择替代的、较小的数据表示形式来减少数据量

有参方法

·使用一个参数模型估计数据，最后只要存储参数即可，不用存储数据（除了可能的离群点）

常用方法：线性回归方法；多元回归；对数线性模型；

#### 无参方法

·不使用模型的方法存储数据

·常用方法：直方图，聚类，选样

西安交通大學


![](https://web-api.textin.com/ocr_image/external/ec866f65b0c1e63a.jpg)

MIANHADIOSGLNIVESIEY

##### 2.4 数据归约- 数值规约

## 回归分析

线性回归：数据被拟合为一条直线Y=wX+b

·两个回归系数，w和b，由手头数据来进行估算

通常适用最小二乘法来确定这条直线


![](https://web-api.textin.com/ocr_image/external/ec8d6a18bce3a3f1.jpg)

多元回归：线性回归的扩充，允许响应变量Y被建模为两个或多个预测变量的线性或非线性函数$Y = b _ { 0 } + b _ { 1 } X _ { 1 } + b _ { 2 } X _ { 2 } .$

西安交通大學


![](https://web-api.textin.com/ocr_image/external/cac108a78f2e48c8.jpg)

MIANHADIOSG LNIVERSIEY

## 采样

允许用数据的较小随机样本（子集）表示大的数据集

对数据集D的样本选择：

s个样本无放回简单随机抽样（Simple random sampling without replacement， SRSWOR）：由D的N个元组中抽取s个样本（s＜N）

s个样本有放回简单随机抽样（Simple Random Sampling With Replacement， SRSWR）：过程同上，只是元组被抽取后，将被回放，可能再次被抽取

聚类选样：D中元组被分入M个互不相交的簇中，可在其中的m个簇上进行简单随机选择（SRS，m＜M）

西安交通大學


![](https://web-api.textin.com/ocr_image/external/2dd44a6721246afb.jpg)

XIAN JAOIOSG ENIVIRSITY

## 2.4 数据归约- 数值规约

## 采样


![](https://web-api.textin.com/ocr_image/external/5e70262d9264a2d4.jpg)

SRSWOR （简单随机选样，不回放）


![](https://web-api.textin.com/ocr_image/external/da69112018611764.jpg)


![](https://web-api.textin.com/ocr_image/external/3f368ceae582d0e9.jpg)

SRSWR

原始数据

西安交通大學


![](https://web-api.textin.com/ocr_image/external/5bdedc8ba51c22b5.jpg)

XIAN JAOIOSGLNIVERSIEY

## 2.4 数据归约-离散化和概念分层


![](https://web-api.textin.com/ocr_image/external/ecf30c3bea32b985.jpg)

### 采样-聚类采样

### 原始数据 聚类采样

<!-- O  -->
![](https://web-api.textin.com/ocr_image/external/64c24fb737fae0a4.jpg)


![](https://web-api.textin.com/ocr_image/external/e5264477d2f84172.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/395d2260b1f808d6.jpg)

XIAN JAOIONG LNIVERSIY

## 2.4 数据归约- 离散化和概念分层

## 离散化

有些分类算法只接受离散属性值

将连续属性的范围划分为区间，区间的标号可以代替实际的数据值，减少给定连续属性值的个数

概念分层：使用高层概念（比如：青年、中年、老年）来替代底层的属性值（比如：实际年龄）来规约数据

聚类分析产生概念分层可能会将一个工资区间划分为：

[51263.98,60872.34]

通常数据分析人员希望看到划分的形式为［50000,60000］

西安交通大學


![](https://web-api.textin.com/ocr_image/external/e5de76b27c7da00b.jpg)

XIAN JAOIONGLNIVERSIEY

## 2.4 数据归约-离散化和概念分层

分类数据是指无序的离散数据，它有有限个值（可能很多个）。

根据在给定属性集中，每个属性所包含的不同值的个数，可以自动的生成概念分层；不同值个数最多的属性将被放在概念分层的最底层。

5个不同值

65个不同值

<!-- country province city street  -->
![](https://web-api.textin.com/ocr_image/external/f21a675a5107bc2f.jpg)

3567个不同值

674,339个不同值

西安交通大學


![](https://web-api.textin.com/ocr_image/external/905f8039aae80a8c.jpg)

XIAN JAOIONG ENIVIESITY

Data attribute types: nominal, binary, ordinal, interval-scaled,ratio-scaled

Basic statistical data description: central tendency,dispersion,graphical displays

Data quality: accuracy, completeness, consistency,timeliness, believability,interpretability

Data cleaning: e.g. missing/noisy values,outliers

Data reduction: Dimensionality reduction, Numerosity reduction, Data compression

Data transformation and data discretization: Normalization,Concept hierarchy generation

西安交通大學


![](https://web-api.textin.com/ocr_image/external/deea91225c9a332f.jpg)

XIAN JAOIOSGENIVIRSITY

