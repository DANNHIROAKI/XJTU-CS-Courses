<!-- 西安交通大學 XI'AN JIAOTONG UNIVERSITY  -->
![](https://web-api.textin.com/ocr_image/external/c27de857964cecc6.jpg)


![](https://web-api.textin.com/ocr_image/external/f53ef8a155d36f46.jpg)

NA0T00 UNIVERSITY

# 数据挖掘

## 第六章： 聚类

### 范铭

### 智能网络与网络安全教育部重点实验室

西安交通大学网络空间安全学院

### 本章内容

6.1 什么是聚类分析

6.2 聚类分析中的数据类型

6.3 划分方法

6.4 层次方法

6.5 基于密度的方法

基本要求：掌握聚类的定义、相似度的量化方法问题，掌握基于划分、层次、密度等典型聚类算法

西安交通大學


![](https://web-api.textin.com/ocr_image/external/5fceb703e99f8234.jpg)

XIAN HAOIOSG LNIVIESIEY

#### 6.1 什么是聚类分析（Clusting analysis）

聚类分析（简称聚类）：把一个数据对象划分为子集的过程。每个子集称为一个簇（cluster）：

✓同一簇中的数据对象尽可能相似

不同簇中的数据对象尽可能不相似

✓社团分析

##### 无监督学习（unsupervised learning）

✓未指定类标签

✓不是通过样本学习

簇的数目也是未知的

西安交通大學


![](https://web-api.textin.com/ocr_image/external/01abc2a6b65e46e1.jpg)

XIAN HAOIOSG LNIVIESIEY

#### 6.1 什么是聚类分析

##### Hard Clustering一每个数据对象仅属于一个簇


![](https://web-api.textin.com/ocr_image/external/c374c17927036f4d.jpg)

##### Soft Clustering-每个数据对象可能属于多个簇


![](https://web-api.textin.com/ocr_image/external/29989ca6e3b010d7.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/2af42a744d063c65.jpg)

XIAN JAOIOSGUNIVERSIEY

#### 6.1 什么是聚类分析

##### 好的聚类算法能产生高质量的簇：


![](https://web-api.textin.com/ocr_image/external/b9a092949350a3ff.jpg)

较高的簇内相似度

✓7较低的簇间相似度

好的聚类结果同时依赖于相似度计算方法与聚类算法

相似度计算方法通常比聚类算法更重要

西安交通大學


![](https://web-api.textin.com/ocr_image/external/f12b37805d8bece9.jpg)

XIAN HAOIOSGLNIVERSIEY

#### 6.1 什么是聚类分析


![](https://web-api.textin.com/ocr_image/external/e7f2da1e6a18b38d.jpg)

Facebook的用户关系数据集进行可视化

西安交通大學

XIAN HAOIOSGLNIVERSIEY

#### 6.1 什么是聚类分析

<!-- 1 9 2 4 5 6 8 10 3 7 11  -->
![](https://web-api.textin.com/ocr_image/external/eed39ca215b9aac1.jpg)

<!-- 0.5 2 3 9 _ { 1 0 } 1 1 0.0 7 -0.5 56 -1.0 -1.5 4 8 -1.4 -1.2 -1.0 -0.8  -->
![](https://web-api.textin.com/ocr_image/external/8872bc59b5dddfb4.jpg)

<!-- 48 1.5 1.0 6 0.5 5 7 0.0 2 39 -0.5 10 11 0.7 0.8 0.9 1.0 1.1  -->
![](https://web-api.textin.com/ocr_image/external/60ef85bec4cf0103.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/319037559fe58bf7.jpg)

XIAN HAOIOSG LNIVIESIY

#### 6.1 什么是聚类分析-难点


![](https://web-api.textin.com/ocr_image/external/294ab30bcaeaf099.jpg)


![](https://web-api.textin.com/ocr_image/external/cb79bdee28a2f318.jpg)

<!-- b  -->
![](https://web-api.textin.com/ocr_image/external/b2f06aeed7bbfbd6.jpg)


![](https://web-api.textin.com/ocr_image/external/b938266cadb700e5.jpg)


![](https://web-api.textin.com/ocr_image/external/3594a91fae45b015.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1f32249430491faf.jpg)

XIAN HAOIOSG LNIVIESIEY

#### 6.1什么是聚类分析-难点


![](https://web-api.textin.com/ocr_image/external/c732f067097e3553.jpg)

Consider N data points to be split into “C”groups (clusters). The number of possible splits (partitions) is described as

$\frac { 1 } { c ! } \sum _ { i = 1 } ^ { c } ( - 1 ) ^ { c - i } ( c )$:N

Even for a small problem of N =100 and c=5we end up with 1067 partitions

西安交通大學


![](https://web-api.textin.com/ocr_image/external/0df23ad7314494ae.jpg)

XIAN HAOIOSG LNIYERSIEY

#### 6.1 什么是聚类分析-需求与挑战

可伸缩性：如何应对海量数据？

##### -处理不同数据类型：


![](https://web-api.textin.com/ocr_image/external/8765063b380ce651.jpg)

数值，布尔，枚举，序数，连接以及混合类型

##### -发现任意形状的簇：

✓球形簇：欧几里得距离、曼哈顿距离


![](https://web-api.textin.com/ocr_image/external/7209f1a681219eb4.jpg)

任意形状：森林火灾边缘

##### -基于约束的聚类：

各种约束条件下的聚类：ATM部署（考虑河流、公路网）

西安交通大學

XIAN HAOIOSG LNIVIRSIEY

#### 6.1 什么是聚类分析-需求与挑战

### 一利用领域知识确定输入参数

✓许多聚类算法要求用户输入一定的参数，如希望产生的簇的数目.聚类结果对于输入参数十分敏感

✓参数难以确定，增加了用户的负担，使聚类质量难以控制

### 一处理噪音数据的能力：

一些聚类算法对于噪音数据敏感，可能导致低质量的聚类结果

现实世界中的数据库大都包含了错误数据、缺失数据、离群点

### -聚类高维数据的能力

### 一可解释性与可用性

✓聚类结果可用特定的语义解释或与应用相连

西安交通大學


![](https://web-api.textin.com/ocr_image/external/9f10557b99409735.jpg)

XIAN JAOIONGLNIVIESIEY

#### 6.1典型应用

-市场销售：帮助市场人员发现客户中的不同群体，然后用这些知识来开展一个目标明确的市场计划

-土地使用：在一个陆地观察数据库中标识那些土地使用相似的地区

-保险：对购买了汽车保险的客户，标识那些有较高平均赔偿成本的客户

-城市规划：根据类型、价格、地理位置等来划分不同类型的住宅

-地震研究：根据地质断层特点把已观察到的地震中心分成不同类

-WEB文档分类

-恒星分类

-孤立点分析

西安交通大學


![](https://web-api.textin.com/ocr_image/external/0df23ad7314494ae.jpg)

XIAN HAOIOSG LNIYIRSIEY

6.1 什么是聚类分析

6.2 聚类分析中的数据类型

6.3 划分方法

6.4层次方法

6.5 基于密度的方法

西安交通大學


![](https://web-api.textin.com/ocr_image/external/c4657ed4d3aae63f.jpg)

XIAN JAOIOSGLNIVIESIEY

#### 6.2聚类分析中的数据类型

数据矩阵

(two modes)

<!-- [ \begin{matrix} x _ { I I } \cdots x _ { I I } - x _ { I p } \\ x _ { i I } - x _ { i j } - \cdots x _ { i p } \\ x _ { i I } \cdots x _ { n j } \\ x _ { n I } \cdots x _ { n j } \end{matrix} ]  -->
![](https://web-api.textin.com/ocr_image/external/55b45841a5969602.jpg)

差异度矩阵

<!-- [ \begin{matrix} \theta \\ d ( 2 , 1 ) & d ( 3 , 2 ) & 0 \\ d ( 3 , 1 ) & d ( 3 , 2 ) & 0 \\ d ( n , 1 ) & d ( n , 2 ) & \cdots 0 \end{matrix} ]  -->
![](https://web-api.textin.com/ocr_image/external/765a87efd220fd67.jpg)

(one mode)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1fdab953a6daec61.jpg)

XIAN HAOIOSG LNIVIESIEY

#### 6.2聚类分析中的数据类型

差异度／相似度矩阵：相似度通常用距离函数来表示

对不同类型的变量，距离函数的定义通常是不同的

根据实际的应用和数据的语义，在计算距离的时候，不同的变量有不同的权值相联系

西安交通大學


![](https://web-api.textin.com/ocr_image/external/5c2b396b6bc4752f.jpg)

XIAN HAOIOSG LNIVIESIEY

#### 6.2聚类分析中的数据类型

区间标度变量（Interval-scaled variables）

二元变量（Binary variables）

枚举型，序数型和比例型变量（Nominal，ordinal, and ratio variables)

混合类型变量（Variables of mixed types）

西安交通大學


![](https://web-api.textin.com/ocr_image/external/5aea7858f1c64ca8.jpg)

XIAN HAOIOSG LNIVIESIEY

#### 6.2聚类分析中的数据类型-区间标度变量

### 区间标度变量：一种线形标度的连续度量

## 数据标准化

计算绝对偏差的平均值：

$s _ { f } = \frac { 1 } { n } ( \vert x _ { 1 f } - m _ { f } \vert + \vert x _ { 2 f } - m _ { f } \vert + \cdots + \vert x _ { n f } - m _ { f } \vert )$

其中 $m _ { f } = \frac { 1 } { n } ( x _ { 1 f } + x _ { 2 f } + \cdots + x _ { n f } )$

计算标准度量值（z-score）

$z _ { i f } = \frac { x _ { i f } - m _ { f } } { S _ { f } }$

使用绝对偏差的平均值比使用标准偏差更健壮(robust)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/f12b37805d8bece9.jpg)

XIAN HAOIOSG LNIVIESIY

### 6.2聚类分析中的数据类型-区间标度变量

假设有两个数据集：

·数据集A：［1,2,3,4， 5］

·数据集B：［1,2,3,4,100］（带有一个异常值100）

计算这两个数据集的标准偏差和平均绝对偏差：

## ·数据集A：

·标准偏差σ=1.58

·平均绝对偏差MAD=1.2

## ·数据集B：

·标准偏差σ=39.4 （由于异常值100的存在，标准偏差急剧增大）

·平均绝对偏差MAD=18(MAD增加了，但远没有标准偏差变化那么大）

西安交通大學


![](https://web-api.textin.com/ocr_image/external/6dd824454d41eea7.jpg)

XIAN HAOIOSGLNIVIESIEY

## 6.2聚类分析中的数据类型

# 距离可用于测量两个数据对象间的相似性或差异性

常用的距离表示： Minkowski Distance

$d ( i , j ) = \sqrt [ 9 ] { \vert x _ { i 1 } - x _ { j 1 } \vert ^ { q } + \vert x _ { i 2 } - x _ { j 2 } \vert ^ { q } + \cdots + \vert x _ { i p } - x _ { j p } \vert q }$

$i = ( x _ { i _ { 1 } } , x _ { i _ { 2 } } , \cdots , x _ { i _ { p } } )$ $j = ( x _ { j _ { 1 } } , x _ { j _ { 2 } } , \cdots , x _ { j _ { p } } )$ 是两

个p-维的数据对象，p为正整数

如果q=1，d为Manhattan Distance

$d ( i , j ) = \vert x _ { i 1 } - x _ { j 1 } \vert + \vert x _ { i 2 } - x _ { j 2 } \vert + \cdots + \vert x _ { i p } - x _ { j p } \vert$

西安交通大學


![](https://web-api.textin.com/ocr_image/external/b3716b5653fa7033.jpg)

XIAN HAOIOSGLNIVERSIEY

## 6.2聚类分析中的数据类型数值型

# 如果q=2, d为Euclidean Distance

$d ( i , j ) = \sqrt { \vert x _ { i 1 } - x _ { j 1 } \vert ^ { 2 } + \vert x _ { i 2 } - x _ { j 2 } \vert ^ { 2 } + \cdots + \vert x _ { i p } - x _ { j p } \vert ^ { 2 } }$

## 性质

d(i,j)≥0

d(i,i)=0

d(i,j)=d(j,i)

d(i,j)≤d(i,k)+d(k,j)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/4cc9edfb365c8e6c.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.2聚类分析中的数据类型-布尔型

###### 布尔型数据的列联表（Contingency table）

<table border="1" ><tr>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
<td colspan="3" rowspan="1">Object j</td>
</tr><tr>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">sum</td>
</tr><tr>
<td colspan="1" rowspan="3">Objecti</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">a</td>
<td colspan="1" rowspan="1">b</td>
<td colspan="1" rowspan="1">$a + b$</td>
</tr><tr>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">C</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">$c + d$</td>
</tr><tr>
<td colspan="1" rowspan="1">sum</td>
<td colspan="1" rowspan="1">$a + c$</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">p</td>
</tr></table>

# 简单匹配系数（Simple matching coefficient）

$d ( i , j ) = \frac { b + c } { a + b + c + d }$ 二元变量是对称的

## Jaccard系数

$d ( i , j ) = \frac { b + c } { a + b + c }$ 二元变量是非对称的

西安交通大學

XIAN HAOIOSG LNIVIESIY

### 6.2聚类分析中的数据类型-布尔型

#### 例子

<table border="1" ><tr>
<td colspan="1" rowspan="1">Name</td>
<td colspan="1" rowspan="1">Gender</td>
<td colspan="1" rowspan="1">Fever</td>
<td colspan="1" rowspan="1">Cough</td>
<td colspan="1" rowspan="1">Test-1</td>
<td colspan="1" rowspan="1">Test-2</td>
<td colspan="1" rowspan="1">Test-3</td>
<td colspan="1" rowspan="1">Test-4</td>
</tr><tr>
<td colspan="1" rowspan="1">Jack</td>
<td colspan="1" rowspan="1">M</td>
<td colspan="1" rowspan="1">Y</td>
<td colspan="1" rowspan="1">N</td>
<td colspan="1" rowspan="1">P</td>
<td colspan="1" rowspan="1">N</td>
<td colspan="1" rowspan="1">N</td>
<td colspan="1" rowspan="1">N</td>
</tr><tr>
<td colspan="1" rowspan="1">Mary</td>
<td colspan="1" rowspan="1">F</td>
<td colspan="1" rowspan="1">Y</td>
<td colspan="1" rowspan="1">N</td>
<td colspan="1" rowspan="1">P</td>
<td colspan="1" rowspan="1">N</td>
<td colspan="1" rowspan="1">P</td>
<td colspan="1" rowspan="1">N</td>
</tr><tr>
<td colspan="1" rowspan="1">Jim</td>
<td colspan="1" rowspan="1">M</td>
<td colspan="1" rowspan="1">Y</td>
<td colspan="1" rowspan="1">P</td>
<td colspan="1" rowspan="1">N</td>
<td colspan="1" rowspan="1">N</td>
<td colspan="1" rowspan="1">N</td>
<td colspan="1" rowspan="1">N</td>
</tr></table>

Gender是对称属性 $d ( J a c k , M a r y ) = \frac { 0 + 1 } { 2 + 0 + 1 } = 0 . 3 3$

✓其余属性是非对称的

✓设属性值Y、P为1，N为0$d ( J a c k , J i m ) = \frac { 1 + 1 } { 1 + 1 + 1 } = 0 . 6 7$

d(Jim,Mary)=? $d ( J i m , M a r y ) = \frac { 1 + 2 } { 1 + 1 + 2 } = 0 . 7 5$

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1fdab953a6daec61.jpg)

XIAN HAOIOSG LNIVIESIY

### 6.2聚类分析中的数据类型-枚举型

标称变量（Nominal Variables）是二元变量的推广，具有多于两个的状态，如变量color可有red，yellow，blue，green四种状态。两种计算相异度的方法：

方法1：简单匹配方法

·m是匹配的数目，p是全部变量的数目

方法2：使用二元变量 $d ( i , j ) = \frac { p - m } { p }$

·为每一个状态创建一个新的二元变量，可以用非对称的二元变量来编码标称变量。

西安交通大學


![](https://web-api.textin.com/ocr_image/external/5aea7858f1c64ca8.jpg)

XIAN HAOIOSG LNIVIESIEY

### 6.2聚类分析中的数据类型序数型

##  一个序数型变量可以是离散的也可以是连续的

离散的序数型变量类似于标称变量，除了它的m个状态是以有意义的序列排序的，比如职称

连续的序数型变量类似于区间标度变量，但是它没有单位，值的相对顺序是必要的，而其实际大小并不重要。

# 相异度计算：与区间标度变量的计算方法相类似

将xf用它对应的秩代替 $r _ { i f } \in \{ 1 , \cdots , M _ { f } \}$

将每个变量的值域映射到［0.0,1.0］上，使得每个变量都有相同的权重。这通过用$Z _ { i f }$来替代$r _ { i f }$来实现$i f = \frac { r _ { i j } - 1 } { M _ { f } - 1 }$


![](https://web-api.textin.com/ocr_image/external/fe7c31bc44a3e2fa.jpg)

用前面所述的区间标度变量的任一种距离计算方法来计算

西安交通大學


![](https://web-api.textin.com/ocr_image/external/6dd824454d41eea7.jpg)

XIAN JAOTOSG LNIVIE

## 6.2聚类分析中的数据类型-比例标度型

比例标度型变量（Ratio-scaled variable）：总是取正的度量值，有一个非线性的标度，近似的遵循指数标度，比如$A e ^ { B t } O r A e ^ { - B t }$

## 相异度计算：

采用与区间标度变量相同的方法-不是一个好的选择

进行对数变换，对变换得到的值在采用与处理区间标度变量相同的方法对变换得到的值在采用与处理区间标度变量相同的方法 $y _ { i f } = \log ( x _ { i f } )$

将其作为连续的序数型数据，将其秩作为区间标度的值来对待

西安交通大學


![](https://web-api.textin.com/ocr_image/external/92d3c817b17ec2b6.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.2聚类分析中的数据类型-混合类型

## 一个数据库可能包含了多种类型的变量，可用以下公式计算对象i，j之间的相异度.

$d ( i , j ) = \frac { \sum _ { f } p _ { f } = 1 } \delta _ { i j } ( f ) d _ { i j } ( f ) } { \sum _ { f } ^ { p } = 1 } \delta _ { \overline { y } } ^ { ( f ) } }$

其中，p为对象中的变量个数；

如果$X _ { i f }$或$x _ { j f }$缺失（即对象域对象股有变量的值），或者$x _ { i f } = x _ { j f } = 0 ,$ 且变量是不对称的二元变量，则指示项$\delta _ { i j } ( f ) = 0 ;$否则$\delta _ { i j } ( f ) = 1$

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1fdab953a6daec61.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.2聚类分析中的数据类型-混合类型

一f是二元变量或标称变量：

$i f \times _ { i f } = X _ { j f } d _ { i j } ( t ) = 0 , e \vert \sec d _ { i j } ( t ) = 1$

-f是区间标度变量：

$d _ { i j } ( t ) = \vert x _ { i + } x _ { j + } \vert / m a \times _ { n } x _ { n } + \min _ { n } x _ { n } +$

其中h遍取变量f的所有非空缺对象

# -f是序数型或比例标度型

✓计算秩$r _ { i f }$

✓计算$Z _ { i f }$并将其作为区间标度变量值对待

$z _ { i f } = \frac { r _ { i j } - 1 } { M _ { f } - 1 }$

西安交通大學


![](https://web-api.textin.com/ocr_image/external/4cc9edfb365c8e6c.jpg)

XIAN HAOIONGLNIYIESIEY

6.1 什么是聚类分析

6.2 聚类分析中的数据类型

6.3 划分方法

6.4 层次方法

6.5 基于密度的方法

西安交通大學


![](https://web-api.textin.com/ocr_image/external/423e62dd29ae1895.jpg)

XIAN JAOIOSGLNIVIESIEY

## 6.3划分方法-主要的聚类算法

##  聚类算法种类繁多，具体的算法选择取决于数据类型，聚类应用和目的，常用聚类算法包括：

划分方法（Partitioning Methods）

层次方法（Hierarchical Methods）

基于密度的方法（Density-Based Methods）

✓基于网格的方法（Grid-Based Methods）

基于模型的聚类方法（Model-Based Methods）

实际应用中，往往是多种聚类算法中方法的整合

西安交通大學


![](https://web-api.textin.com/ocr_image/external/2ef02cb5ab37c794.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.3划分方法 -主要的聚类算法

###  划分方法：给定n个对象或元组的数据库，一个划分方法构建数据的k个划分，每个划分表示一个簇，并且k&lt;=n。

·每个组至少包含一个对象

·每个对象属于且仅属于一个组

划分准则：同一个聚类中的对象尽可能的接近或相关，不同聚类中的对象尽可能远离或不同

簇的表示

·k-means算法：由簇的平均值来代表整个簇

·k-medoids算法：由处于簇的中心区域的某个值代表整个簇

✓适合发现中小规模数据库中的球状聚类，不适合大规模数据库和处理任意形状的聚类

西安交通大學


![](https://web-api.textin.com/ocr_image/external/8f1da8cc060088cf.jpg)

XIAN JAOIOSGUNIVERSIEY

## 6.3划分方法-主要的聚类算法

###  层次方法：对给定数据对象集合进行层次的分解

✓凝聚方法（自底向上）：开始将每个对象作为单独的一个组；然后继续地合并相近的对象或组，直到所有的组合并为一个（层次的最上层），或者达到一个终止条件

✓分裂方法（自顶向下）：开始将所有的对象置于一个簇；在迭代的每一步，一个簇被分裂为更小的簇，直到最终每个对象在单独的一个簇中，或者达到一个终止条件

西安交通大學

XIAN HAOIOSG LNIVIESIEY

## 6.3划分方法-主要的聚类算法

 基于密度的方法：只要临近区域的密度（对象或数据点的数目）超过某个阀值，就继续聚类.也就是说，对给定类中的每个数据点，在一个给定范围的区域中必须至少包含一定数目的点

 该方法可以用来过滤“噪音”与“离群点”数据，发现任意形状的簇

<!-- %  -->
![](https://web-api.textin.com/ocr_image/external/148e827530665276.jpg)


![](https://web-api.textin.com/ocr_image/external/1818cdf1b4fdb52b.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/8f1da8cc060088cf.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.3划分方法 -k-means

##  簇中对象的均值可以看作簇的质心（centroid）

## k均值算法流程


![](https://web-api.textin.com/ocr_image/external/2c1e2c1bfbbcc5f7.jpg)

随机选择k个对象，每个对象代表一个簇的初始均值或中心


![](https://web-api.textin.com/ocr_image/external/55e14c405396726e.jpg)

对剩余的每个对象，根据它与簇均值的距离，将他指派到最相似的簇


![](https://web-api.textin.com/ocr_image/external/ffab04c4620a14a5.jpg)

计算每个簇的新均值

回到步骤2，循环，直到准则函数收敛

## -常用准则函数：平方误差准则

$E = \sum _ { i = 1 } ^ { k } \sum _ { p \in C _ { i } } \vert p - m _ { i } \vert ^ { 2 }$ （p是空间中的点，m是簇C的均值）

西安交通大學


![](https://web-api.textin.com/ocr_image/external/a1a5d92ce96b5b70.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.3划分方法 -k-means

<!-- 10 9 8 7 6 5 4 3 Update 2 1 the 0 0 1 2 3 4 5 6 7 8 9 10 cluster means  -->
![](https://web-api.textin.com/ocr_image/external/dc51addb5d0c7e05.jpg)

<!-- 10- 9 8 7 6 4 4 3- 2 - 0 0 1 2 3 4 5 6 7 8 9 10  -->
![](https://web-api.textin.com/ocr_image/external/34fb0b2945b022e6.jpg)

Arbitrarily choose K

object as initial

cluster

center.Assign each

objects to most

similar center reassign reassign

Update

<!-- 10 9 8 7 6 5 4 3 2 1 0 0 1 2 3 4 5 6 7 8 9 10  -->
![](https://web-api.textin.com/ocr_image/external/edc22046af82644f.jpg)

<!-- 10 9 8 7 6 5 4 3 2 1 0 0 1 2 3 4 5 6 7 8 9 10  -->
![](https://web-api.textin.com/ocr_image/external/38f20c37ecf19049.jpg)

the

cluster

means

西安交通大學


![](https://web-api.textin.com/ocr_image/external/4dd68d4e6a1249c6.jpg)

XIAN JAOIOSGLNIVERSIEY

## 6.3划分方法-k-means

# 例子2：药品聚类；k=2

<table border="1" ><tr>
<td colspan="1" rowspan="1">Medicine</td>
<td colspan="1" rowspan="1">Weight</td>
<td colspan="1" rowspan="1">pH-Index</td>
</tr><tr>
<td colspan="1" rowspan="1">A</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
</tr><tr>
<td colspan="1" rowspan="1">B</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">1</td>
</tr><tr>
<td colspan="1" rowspan="1">C</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">D</td>
<td colspan="1" rowspan="1">5</td>
<td colspan="1" rowspan="1">4</td>
</tr></table>

<!-- 4.5 D 1 Hd: 3.5 3 2emn은11e 2.5 2 15 A B 1 0.5 0 0 2 6 attribute 1 (X): weight index  -->
![](https://web-api.textin.com/ocr_image/external/c269c87b353fa112.jpg)

西安交通大學

XIAN HAOIOSG LNIVIESIY

## 6.3划分方法 -k-means

#  例子2：药品聚类； k=2

## Step1：选择两个种子节点作为中心

<!-- iteration 0 4.5 4 Hd:と)NΦina1e 3.5 3 2.5 2 1.5 1 0.5 0 0 1 2 3 4 5 6 attribute 1 (X): weight index  -->
![](https://web-api.textin.com/ocr_image/external/48097c759904cefe.jpg)

<table border="1" ><tr>
<td colspan="1" rowspan="4">$A B$$[ \begin{matrix} 1 & 2 & 4 & 5 \\ 1 & 1 & 3 & 4 \end{matrix} ]$</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">$c _ { 1 } = ( 1 , 1 )$</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">$g r o u p - 1$</td>
<td colspan="1" rowspan="1"></td>
</tr><tr>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">$c _ { 2 } = ( 2 , 1 )$</td>
<td colspan="1" rowspan="1"></td>
<td colspan="2" rowspan="1">$g r o u p - 2$</td>
</tr><tr>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">C</td>
<td colspan="1" rowspan="1">D</td>
<td colspan="1" rowspan="1">Euclid</td>
<td colspan="2" rowspan="1">ean distance</td>
</tr><tr>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">$\checkmark$</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
</tr><tr>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">Y</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
</tr></table>

$d D , G ) = \sqrt { ( 5 - 1 ) ^ { 2 } + ( 4 - 1 ) ^ { 2 } } = 5$

d$( D , C _ { 2 } ) = \sqrt { ( 5 - 2 ) ^ { 2 } + ( 4 - 1 ) ^ { 2 } } = 4 . 2 4$

## 将每个数据对象分配给

## 最近的中心

西安交通大學


![](https://web-api.textin.com/ocr_image/external/058ae775d3f8f888.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.3划分方法 -k-means

#  例子2：药品聚类；k=2

## Step2：计算新的中心

<!-- iteration 1 4.5 4 Hd:とNΦindIe 3.5 3 2.5 2 1.5 1 0.5 0 0 1 2 3 4 5 6 attribute 1 (X): weight index  -->
![](https://web-api.textin.com/ocr_image/external/e2c54676b59e44b6.jpg)

$c _ { 1 } = ( 1 , 1 )$

$C _ { 2 } = ( \frac { 2 + 4 + 5 } { 3 } , \frac { 1 + 3 + 4 } { 3 } )$

=(11/3,8/3)

=(3.67,2.67)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/0b4f0ce29ac76b97.jpg)

XIAN HAOIOSGLNIVIESIEY

# 例子2：药品聚类；k=2

## Step3：根据新的中心重新划分数据对象

<!-- iteration 1 4.5 4 Hd:とNΦindIe 3.5 3 2.5 2 1.5 1 0.5 0 0 1 2 3 4 5 6 attribute 1 (X): weight index  -->
![](https://web-api.textin.com/ocr_image/external/d74b327ff85f839f.jpg)

<table border="1" ><tr>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">$7 1 . 8 9$</td>
<td colspan="1" rowspan="1">$\checkmark$$($</td>
<td colspan="1" rowspan="1">$c _ { 2 } = ( \frac { 1 1 } { 3 } , \frac { 8 } { 3 } )$$) g r o u p - 2$</td>
</tr><tr>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
</tr><tr>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">A</td>
<td colspan="1" rowspan="1">B $($</td>
<td colspan="1" rowspan="1">$C$$($$D$</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
</tr><tr>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">2 $。$</td>
<td colspan="1" rowspan="1">$4$$($</td>
<td colspan="1" rowspan="1">$5$</td>
<td colspan="1" rowspan="1"></td>
</tr><tr>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1"></td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/5c2b396b6bc4752f.jpg)

XIAN HAOIOSG LNIVIESIEY

#  例子2：药品聚类； k=2

Step4：重复Step1-3，指导结果收敛。

<!-- iteration 2 4.5 4 Hd:とNeinduue 3.5 3 2.5 2 1 0.5 0 0 1 2 3 4 5 6 attribute 1 (X):weight index  -->
![](https://web-api.textin.com/ocr_image/external/57bd2d74d2d54210.jpg)

$G = ( \frac { 1 + 2 } { 2 } ,$ $\frac { 1 + 1 } { 2 } ) = ( 1 \frac { 1 } { 2 }$,1)

$C _ { 2 } = ( \frac { 4 + 5 } { 2 } ,$ $\frac { 3 + 4 } { 2 } ) = ( 4 \frac { 1 } { 2 } , 3 \frac { 1 } { 2 } )$

西安交通大學


![](https://web-api.textin.com/ocr_image/external/2fb9d3687b9642d0.jpg)

XIAN HAOIOSG LNIVIESIEY

# 例子2：药品聚类； k=2

Step4:重复Step1-3，直到结果收敛。

<!-- iteration 2 4.5 4 Hd:とNeinduue 3.5 3 2.5 2 1.5 1 0.5 0 0 1 2 3 4 5 6 attribute 1 (X): weight index  -->
![](https://web-api.textin.com/ocr_image/external/adf6092918e51f11.jpg)

<!-- D ^ { 2 } = [ \begin{matrix} 0 . 5 & 0 . 5 & 3 . 2 0 & 4 . 6 1 \\ 4 . 3 0 & 3 . 5 4 & 0 . 7 1 & 0 . 7 1 \end{matrix} ] c _ { 1 } = ( 1 \frac { 1 } { 2 } , 1 ) group-1 c _ { 2 } = ( 4 \frac { 1 } { 2 } , 3 \frac { 1 } { 2 } ) group-2 A 1 ( B 1 C D 一 2 4 5 \\ 1 3 4  -->
![](https://web-api.textin.com/ocr_image/external/f94c686d891c6cb5.jpg)

## 当簇与中心值不再改变时，算法结束。

西安交通大學


![](https://web-api.textin.com/ocr_image/external/4e35ae5fd734f720.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.3划分方法-k-means

可扩展性较好，算法复杂度为O(nkt),，其中n为对象总数，k是簇的个数，堤迭代次数。

经常终止于局部最优解

## 缺点

只有当簇均值有定义的情况下，k-means才能使用。

（某些分类属性的均值可能没有定义）

必须首先给定簇数目k

✓不适合发现非凸形状（non-convex shapes）的簇，或者大小差别很大的簇✓对噪声和离群点数据敏感

西安交通大學


![](https://web-api.textin.com/ocr_image/external/0d6e005d4185762a.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.3划分方法 -k-means

<!-- outlier  -->
![](https://web-api.textin.com/ocr_image/external/a04e2bccd2894933.jpg)

(A):Undesirable clusters

outlier


![](https://web-api.textin.com/ocr_image/external/a75f5349fef7a541.jpg)

<!-- 0  -->
![](https://web-api.textin.com/ocr_image/external/506158b51d2a1cdf.jpg)


![](https://web-api.textin.com/ocr_image/external/e3b77fa24dbd11cf.jpg)

(B):Ideal clusters

西安交通大學


![](https://web-api.textin.com/ocr_image/external/01abc2a6b65e46e1.jpg)

XIAN HAOIOSG LNIYIRSIEY


![](https://web-api.textin.com/ocr_image/external/3cb8403767d4ba16.jpg)

(A). Random selection of seeds (centroids)


![](https://web-api.textin.com/ocr_image/external/200f30c8fcd8db6a.jpg)

<!-- 0  -->
![](https://web-api.textin.com/ocr_image/external/dd338080d069ce9a.jpg)

(B).Iteration 1 (C).Iteration 2


![](https://web-api.textin.com/ocr_image/external/53b515adf3bcaf12.jpg)


![](https://web-api.textin.com/ocr_image/external/a1cfc885640afbba.jpg)

(B).Iteration 1 (C).Iteration 2

西安交通大學


![](https://web-api.textin.com/ocr_image/external/6b91f5687b52793f.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.3划分方法 -k-means


![](https://web-api.textin.com/ocr_image/external/37a7f5ba4585098f.jpg)


![](https://web-api.textin.com/ocr_image/external/d2ecca3f42ca225d.jpg)

(A):Two natural clusters (B):k-means clusters

西安交通大學


![](https://web-api.textin.com/ocr_image/external/058ae775d3f8f888.jpg)

XIAN HAOIOSG LNIVIESIEY

# k-means方法的变种，区别在于


![](https://web-api.textin.com/ocr_image/external/b521435c78690522.jpg)

初始k个均值的选择

✓相异度计算

✓计算簇均值的策略

西安交通大學


![](https://web-api.textin.com/ocr_image/external/a2bbde86fa0de0d1.jpg)

XIAN HAOIOSG LNIVIESIY

# k-means方法对于离群点敏感

一个具有很大极端值的对象可能显著扭曲数据的分布

## k中心点（K-Medoids）方法：采用簇的中心点，即

# 最靠近中心的对象来代表簇

# ✓降低算法对离群点的敏感度

<!-- 10 9 8 7 6 5 4 3 2 1 0 0 1 2 3 4 5 6 7 8 9 10  -->
![](https://web-api.textin.com/ocr_image/external/0b6e7fa083bbd8a2.jpg)

<!-- 10 9 8 7 6 5 4 3 2 1 0 0 1 2 3 4 5 6 7 8 9 10  -->
![](https://web-api.textin.com/ocr_image/external/65b9f66a996a3422.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/5fceb703e99f8234.jpg)

XIAN HAOIOSG LNIVIESIY


![](https://web-api.textin.com/ocr_image/external/a0bc34704cda565e.jpg)

## K-Medoids基本思想：

✓首先为每个簇随意选择选择一个代表对象；剩余的对象根据其与代表对象的距离分配给最近的一个簇

✓然后反复地用非代表对象来替代代表对象，以改进聚类的质量

✓聚类结果的质量用一个代价函数来估算，该函数评估了对象与其参照对象之间的平均相异度

-PAM (Partitioning Around Medoids) (Kaufman and Rousseeuw, 1987)

✓最早提出的K-Medoids聚类算法

西安交通大學


![](https://web-api.textin.com/ocr_image/external/a086844b3e20a3ec.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.3划分方法 -PAM:A Typical K-Medoids Algorithm

### PAM算法

① 随机选择k个对象作为初始的代表对象；

### ② repeat

指派每个剩余的对象给离它最近的代表对象所代表的簇；随意地选择一个非代表对象Orandomi

计算用Orandom代替O的总代价S；

如果S&lt;0，用Orandom $O _ { j } ,$ 形成新k个代表对象的集合；替换③until 不发生变化

西安交通大學


![](https://web-api.textin.com/ocr_image/external/0df23ad7314494ae.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.3划分方法 -PAM: A Typical K-Medoids Algorithm

Arbitrary choose k object as initial medoids

<!-- 10 9 8 7 6 5 4 3 2 1 0 0 1 2 3 4 5 6 7 8 9 10  -->
![](https://web-api.textin.com/ocr_image/external/de42ff55046d3b55.jpg)

<!-- 10 9 8 7 6 5 4 3 2 1 0 0 1 2 3 4 5 6 7 8 9 10  -->
![](https://web-api.textin.com/ocr_image/external/4938eb0c7ce03b71.jpg)

<!-- Total Cost=20 10 9 8 Assign 7 each 6 remaining 5 object to 4 3 nearest 2 medoids 1 0 0 1 2 3 4 5 6 7 8 9 10 Randomly select a nonmedoid object,Oramdom 10 Compute 9 total cost of 8 7 swapping 6 5 4 3 2 1 0 10 0 1 2 3 4 5 6 7 8 9 10  -->
![](https://web-api.textin.com/ocr_image/external/36dbd3761b97bbc2.jpg)

K=2

TotalCost=26

Swapping O

Do loop and Oramdom

<!-- 10 9 8 7 6 5 4 3 2 1 0 0 1 2 3 4 5 6 7 8 9  -->
![](https://web-api.textin.com/ocr_image/external/cf45d4c88ce67c86.jpg)

Until no change If quality is

improved.

西安交通大學


![](https://web-api.textin.com/ocr_image/external/058ae775d3f8f888.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.3划分方法 -PAM: A Typical K-Medoids Algorithm

<!-- 10 9 8 x 7 6 5 4 h 3 2 1 0 0 1 2 3 4 5 6 7 8 9 10  -->
![](https://web-api.textin.com/ocr_image/external/59fa12bb5234f85a.jpg)

<!-- 10 9 8 7 6 5 4 h 3 2 1 0 0 1 2 345 6 7 8 9 10  -->
![](https://web-api.textin.com/ocr_image/external/6368502f841667e8.jpg)

$C _ { j i h } = d ( j , h ) - d ( j , i )$ $C _ { j i h } = 0$

<!-- 10 9 8 7 6 5 4 h 3 2 1 0 0 1 2 34 5 6 7 8 9 10  -->
![](https://web-api.textin.com/ocr_image/external/be9f84e753ae79ac.jpg)

<!-- 10 9 8 h 7 6 5 4 3 2 1 0 0 1 2 3 5 6 7 8 9 10  -->
![](https://web-api.textin.com/ocr_image/external/7db7311d59fd515f.jpg)

$C _ { j i h } = d ( j , t ) - d ( j , i )$ $C _ { j i h } = d ( j , h ) - d ( j , t )$

西安交通大學


![](https://web-api.textin.com/ocr_image/external/81b36a59d78d9944.jpg)

XIAN HAOIONG LNIVIESIY

## 6.3划分方法-PAM：A Typical K-Medoids Algorithm

v 1,2,6,7,8,10,15,17, 20 - break into 3 clusters

Cluster=6-1,2

/ Cluster=7

-Cluster=8-10,15,17,20

# v Random non-medoid - 15 replace 7 (total cost=-13)

-Cluster=6-1(cost 0),2(cost 0),7(1-0=1

- Cluster = 8 -10(cost 0)

- New Cluster = 15-17(cost 2-9=-7),20(cost 5-12=-7)

v Replace medoid 7 with new medoid (15) and reassign

/ Cluster=6-1,2,7

-Cluster=8-10

/ Cluster=15-17,20

西安交通大學


![](https://web-api.textin.com/ocr_image/external/5f6ee93348f5e41b.jpg)

XIAN HAOIOSGLNIVIESIEY

## 6.3划分方法-PAM：A Typical K-Medoids Algorithm

## v Random non-medoid-1 replaces 6

-Cluster=8-6(cost2-0=2)7(cost1-1=0)10(cost0)

- Cluster = 15 -17 (cost 0), 20(cost 0)

- New Cluster = 1 - 2 (cost 1-4=-3)

v 2 replaces 6 (total cost=1)

## v Don't replace medoid 6

- Cluster=6-1,2,7

-Cluster=8-10

-Cluster=15-17,20

# v Random non-medoid-7 replaces 6 (total cost=3)

- Cluster=8-10(cost 0)

- Cluster = 15 -17(cost 0),20(cost 0)

- New Cluster = 7 - 6 (cost 1-0=1), 2 (cost5-4=1),?

西安交通大學

XIAN JAOIOSGLNIVERSIEY

## 6.3划分方法-PAM：A Typical K-Medoids Algorithm

## v Don't Replace medoid 6

、 Cluster=6-1,2,7

-Cluster=8-10

-Cluster=15-17,20

## v Random non-medoid - 10 replaces 8 (total cost=2) don't replace

- Cluster = 6-1(cost 0), 2(cost 0), 7(cost 0)

- Cluster = 15 -17 (cost 0), 20(cost 0)

- New Cluster = 10-8(cost 2-0=2)

v Random non-medoid -17 replaces 15 (total cost=0) don't replace

- Cluster = 6-1(cost 0), 2(cost 0), 7(cost 0)

- Cluster=8-10(cost 0)

- New Cluster = 17-15(cost 2-0=2),20(cost 3-5=-2) 西安交通大學


![](https://web-api.textin.com/ocr_image/external/ac401dfb36644863.jpg)

XIAN HAOIOSG LNIVIESIY

## 6.3划分方法-PAM：A Typical K-Medoids Algorithm

## v Random non-medoid- 20 replaces 15 (total cost=3) don't replace

- Cluster= 6 -1(cost 0), 2(cost 0), 7(cost 0)

- Cluster=8-10(cost 0)

-New Cluster=20-15(cost 5-0=2),17(cost3-2=1)

## v Other possible changes all have high costs

- 1 replaces 15, 2 replaces 15, 1 replaces 8,...

## v No changes, final clusters

/ Cluster=6-1,2,7

-Cluster=8-10

-Cluster=15-17,20

西安交通大學


![](https://web-api.textin.com/ocr_image/external/d4312609eb5756fe.jpg)

XIAN HAOIOSG LNIVIESIY

### 6.3划分方法-PAM：A Typical K-Medoids Algorithm

<table border="1" ><tr>
<td colspan="1" rowspan="1">x1</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">6</td>
</tr><tr>
<td colspan="1" rowspan="1">x2</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">4</td>
</tr><tr>
<td colspan="1" rowspan="1">x3</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">8</td>
</tr><tr>
<td colspan="1" rowspan="1">x4</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">7</td>
</tr><tr>
<td colspan="1" rowspan="1">x5</td>
<td colspan="1" rowspan="1">6</td>
<td colspan="1" rowspan="1">2</td>
</tr><tr>
<td colspan="1" rowspan="1">x6</td>
<td colspan="1" rowspan="1">6</td>
<td colspan="1" rowspan="1">4</td>
</tr><tr>
<td colspan="1" rowspan="1">x7</td>
<td colspan="1" rowspan="1">7</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">x8</td>
<td colspan="1" rowspan="1">7</td>
<td colspan="1" rowspan="1">4</td>
</tr><tr>
<td colspan="1" rowspan="1">x9</td>
<td colspan="1" rowspan="1">8</td>
<td colspan="1" rowspan="1">5</td>
</tr><tr>
<td colspan="1" rowspan="1">x10</td>
<td colspan="1" rowspan="1">7</td>
<td colspan="1" rowspan="1">6</td>
</tr></table>

<!-- 9 8 7 6 3 5 1 4 4 10 Series1 3 2 6 8 9 2 1 7 0 0 2 4 5 6 8 10  -->
![](https://web-api.textin.com/ocr_image/external/eeff269501bc5520.jpg)

## Assume k=2

## Select X5 and X9 as medoids

Current clustering: {X2,X5,X6,X7},{X1,X3,X4,X8,X9,x10}

<table border="1" ><tr>
<td colspan="1" rowspan="1">Distance</td>
<td colspan="1" rowspan="1">to X5</td>
<td colspan="1" rowspan="1">to X9</td>
<td colspan="1" rowspan="1"></td>
</tr><tr>
<td colspan="1" rowspan="1">X1</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">8</td>
<td colspan="1" rowspan="1">7</td>
</tr><tr>
<td colspan="1" rowspan="1">X2</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">5</td>
<td colspan="1" rowspan="1">6</td>
</tr><tr>
<td colspan="1" rowspan="1">X3</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">9</td>
<td colspan="1" rowspan="1">8</td>
</tr><tr>
<td colspan="1" rowspan="1">X4</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">7</td>
<td colspan="1" rowspan="1">6</td>
</tr><tr>
<td colspan="1" rowspan="1">X6</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">X7</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">X8</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">2</td>
</tr><tr>
<td colspan="1" rowspan="1">X10</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">5</td>
<td colspan="1" rowspan="1">2</td>
</tr></table>

FROM Data Mining Lab of BYU

西安交通大學


![](https://web-api.textin.com/ocr_image/external/0ae932391bb1b0b1.jpg)

XIAN HAOIOSG LNIVIESIY

## 6.3划分方法-PAM：A Typical K-Medoids Algorithm

### Replace X5 by X3 and compute the change

<table border="1" ><tr>
<td colspan="1" rowspan="1">x1</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">6</td>
</tr><tr>
<td colspan="1" rowspan="1">x2</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">4</td>
</tr><tr>
<td colspan="1" rowspan="1">x3</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">8</td>
</tr><tr>
<td colspan="1" rowspan="1">x4</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">7</td>
</tr><tr>
<td colspan="1" rowspan="1">x5</td>
<td colspan="1" rowspan="1">6</td>
<td colspan="1" rowspan="1">2</td>
</tr><tr>
<td colspan="1" rowspan="1">x6</td>
<td colspan="1" rowspan="1">6</td>
<td colspan="1" rowspan="1">4</td>
</tr><tr>
<td colspan="1" rowspan="1">x7</td>
<td colspan="1" rowspan="1">7</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">x8</td>
<td colspan="1" rowspan="1">7</td>
<td colspan="1" rowspan="1">4</td>
</tr><tr>
<td colspan="1" rowspan="1">x9</td>
<td colspan="1" rowspan="1">8</td>
<td colspan="1" rowspan="1">5</td>
</tr><tr>
<td colspan="1" rowspan="1">x10</td>
<td colspan="1" rowspan="1">7</td>
<td colspan="1" rowspan="1">6</td>
</tr></table>

<table border="1" ><tr>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">to X3</td>
<td colspan="1" rowspan="1">to X9</td>
</tr><tr>
<td colspan="1" rowspan="1">X1</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">7</td>
</tr><tr>
<td colspan="1" rowspan="1">X2</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">6</td>
</tr><tr>
<td colspan="1" rowspan="1">X4</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">6</td>
</tr><tr>
<td colspan="1" rowspan="1">X5</td>
<td colspan="1" rowspan="1">9</td>
<td colspan="1" rowspan="1">5</td>
</tr><tr>
<td colspan="1" rowspan="1">X6</td>
<td colspan="1" rowspan="1">7</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">X7</td>
<td colspan="1" rowspan="1">9</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">X8</td>
<td colspan="1" rowspan="1">8</td>
<td colspan="1" rowspan="1">2</td>
</tr><tr>
<td colspan="1" rowspan="1">X10</td>
<td colspan="1" rowspan="1">6</td>
<td colspan="1" rowspan="1">2</td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/7a987b15293b19c3.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.3划分方法-PAM： A Typical K-Medoids Algorithm

<!-- 9 8 3 7 6 4 1 10 5 9 Series1 4 2 6 8 3 7 2 5 1 0 0 2 4 6 8 10  -->
![](https://web-api.textin.com/ocr_image/external/4901061210d6653e.jpg)

to X3 to X9

X1 3 7

X2 4 6

X4 2 6

<table border="1" ><tr>
<td colspan="1" rowspan="1">Distance</td>
<td colspan="1" rowspan="1">to X5</td>
<td colspan="2" rowspan="1">to X9</td>
</tr><tr>
<td colspan="1" rowspan="1">X1</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">8</td>
<td colspan="1" rowspan="1">7</td>
</tr><tr>
<td colspan="1" rowspan="1">X2</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">5</td>
<td colspan="1" rowspan="1">6</td>
</tr><tr>
<td colspan="1" rowspan="1">X3</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">9</td>
<td colspan="1" rowspan="1">8</td>
</tr><tr>
<td colspan="1" rowspan="1">X4</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">7</td>
<td colspan="1" rowspan="1">6</td>
</tr><tr>
<td colspan="1" rowspan="1">X6</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">X7</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">X8</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">2</td>
</tr><tr>
<td colspan="1" rowspan="1">X10</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">5</td>
<td colspan="1" rowspan="1">2</td>
</tr></table>

X5 9 5

X6 7 3

X7 9 3

X8 8 2

X10 6 2

<table border="1" ><tr>
<td colspan="1" rowspan="1">Repl.X5 by X3</td>
<td colspan="1" rowspan="1">Bef</td>
<td colspan="1" rowspan="1">Aft</td>
<td colspan="1" rowspan="1"></td>
</tr><tr>
<td colspan="1" rowspan="1">X1</td>
<td colspan="1" rowspan="1">7</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">-4</td>
</tr><tr>
<td colspan="1" rowspan="1">X2</td>
<td colspan="1" rowspan="1">5</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">-1</td>
</tr><tr>
<td colspan="1" rowspan="1">X3</td>
<td colspan="1" rowspan="1">8</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">-8</td>
</tr><tr>
<td colspan="1" rowspan="1">X4</td>
<td colspan="1" rowspan="1">6</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">-4</td>
</tr><tr>
<td colspan="1" rowspan="1">X5</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">5</td>
<td colspan="1" rowspan="1">-5</td>
</tr><tr>
<td colspan="1" rowspan="1">X6</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">1</td>
</tr><tr>
<td colspan="1" rowspan="1">X7</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">1</td>
</tr><tr>
<td colspan="1" rowspan="1">X8</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">0</td>
</tr><tr>
<td colspan="1" rowspan="1">X9</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
</tr><tr>
<td colspan="1" rowspan="1">X10</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">0</td>
</tr><tr>
<td colspan="1" rowspan="1">totalChange</td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">-20</td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/4914101bba800843.jpg)

XIAN HAOIOSG LNIVIESIY

## 6.3划分方法-PAM：A Typical K-Medoids Algorithm

## X3 and X9 are new medoids

<!-- 9 8 7 6 5 4 Series1 3 2 1 0 0 2 4 6 8 10  -->
![](https://web-api.textin.com/ocr_image/external/1df26b3bd13f96f8.jpg)

<table border="1" ><tr>
<td colspan="1" rowspan="1">Distances</td>
<td colspan="1" rowspan="1">to X3</td>
<td colspan="1" rowspan="1">to X9</td>
</tr><tr>
<td colspan="1" rowspan="1">X1</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">7</td>
</tr><tr>
<td colspan="1" rowspan="1">X2</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">6</td>
</tr><tr>
<td colspan="1" rowspan="1">X4</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">6</td>
</tr><tr>
<td colspan="1" rowspan="1">X5</td>
<td colspan="1" rowspan="1">9</td>
<td colspan="1" rowspan="1">5</td>
</tr><tr>
<td colspan="1" rowspan="1">X6</td>
<td colspan="1" rowspan="1">7</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">X7</td>
<td colspan="1" rowspan="1">9</td>
<td colspan="1" rowspan="1">3</td>
</tr><tr>
<td colspan="1" rowspan="1">X8</td>
<td colspan="1" rowspan="1">8</td>
<td colspan="1" rowspan="1">2</td>
</tr><tr>
<td colspan="1" rowspan="1">X10</td>
<td colspan="1" rowspan="1">6</td>
<td colspan="1" rowspan="1">2</td>
</tr></table>

Current clustering:{x1,x2,x3,x4},{x5,x6,x7,x8,x9,x10}

# No change in medoids yields better quality →DONE!

西安交通大學


![](https://web-api.textin.com/ocr_image/external/978c0061537f73ae.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.3划分方法-PAM:A Typical K-Medoids Algorithm

# 当存在噪声和离群点时， k-medoids比k-means 更加鲁棒

中心点较少的受离群点影响

k-medoids方法的执行代价比k-means方法要高

✓k-means方法： O(nkt)

k-medoids方法： $O ( k ( n - k ) ^ { 2 } )$

两种方法都要用户指定簇的数目k

西安交通大學


![](https://web-api.textin.com/ocr_image/external/01abc2a6b65e46e1.jpg)

XIAN HAOIOSG LNIVIESIEY

6.1 什么是聚类分析

6.2 聚类分析中的数据类型

6.3 划分方法

6.4 层次方法

6.5 基于密度的方法

西安交通大學


![](https://web-api.textin.com/ocr_image/external/41407e9bf4abc802.jpg)

XIAN HAOIONG LNIVIESIEY

## 6.4层次方法（Hierarchical Methods）

层次聚类方法将数据对象组成一棵聚类的树

 根据层次分解是自底向上，还是自顶向下形成，层次聚类方法可分为凝聚的（agglomerative）和分裂的(divisive)

 聚类质量受限于如下特点：一旦一个合并或分裂被执行，就不能修正

 使用距离矩阵作为聚类标准.该方法不需要输入聚类数目k，但需要终止条件

西安交通大學


![](https://web-api.textin.com/ocr_image/external/0df23ad7314494ae.jpg)

XIAN HAOIONGLNIVIESIEY

## 6.4层次方法

# 凝聚的和分裂的层次聚类

<table border="1" ><tr>
<td colspan="1" rowspan="1">Step</td>
<td colspan="1" rowspan="1">Step</td>
<td colspan="1" rowspan="1">Step</td>
<td colspan="1" rowspan="1">Step</td>
<td colspan="1" rowspan="1">Step</td>
<td colspan="1" rowspan="2">agglomerative(AGNES)</td>
</tr><tr>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">4</td>
</tr></table>


![](https://web-api.textin.com/ocr_image/external/6f2cd94d10e42e1b.jpg)

<!-- a ab b abcde C d cde de e divisive Step Step Step Step Step (DIANA) 4 3 2 1 0  -->
![](https://web-api.textin.com/ocr_image/external/ff9c1d514f09c6bf.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1fdab953a6daec61.jpg)

XIAN HAOIONGLNIVERSIEY

## 6.4层次方法

# AGNES （Agglomerative Nesting）： 由 Kaufmann 和Rousseeuw提出（1990）


![](https://web-api.textin.com/ocr_image/external/a43cb4bfbe1a68f5.jpg)

✓使用单链接（Single-Link）方法和相异度矩阵


![](https://web-api.textin.com/ocr_image/external/687faadc0bc1913e.jpg)

✓合并具有最小相异度的节点


![](https://web-api.textin.com/ocr_image/external/cda39ae845fc3c21.jpg)

✓以非递减的方式继续

✓最终所有的节点属于同一个簇

<!-- 10 10 10 9 9 9 8 8 8 7 7 7 6 6 6 5 5 5 4 4 4 3 3 3 2 2 2 1 1 1 0 0 1 2 3 ☑ 0 0 5 6 7 8 9 10 0 1 2 3 4 5 6 7 8 9 10 0 1 2 3 5 6 7 8 9 10  -->
![](https://web-api.textin.com/ocr_image/external/94b95f7f75f8e485.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/5fceb703e99f8234.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.4层次方法

# DIANA （Divisive Analysis）： 由 Kaufmann和

Rousseeuw提出（1990）

✓是AGNES的逆

✓最终每个节点自己形成一个簇

<!-- 10 10 10 9 9 9 8 8 8 7 7 7 6 6 6 5 5 5 4 4 4 3 3 3 2 2 2 1 1 1 0 7 9 0 0 0 1 2 3 4 5 6 8 10 0 1 2 3 5 6 7 8 9 10 0 1 2 3 4 5 6 7 8 9 10  -->
![](https://web-api.textin.com/ocr_image/external/539e2c0ea415dc4c.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/f12b37805d8bece9.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.4层次方法

## 四个广泛采用的簇间距离度量方法

Single linkage: $d _ { \min } ( C _ { i } , C _ { j } ) = \min _ { p \in C i , p ^ { * } \in C j \vert p - p ^ { \prime } \vert$

Complete linkage: $d _ { \max } ( C _ { i } , C _ { j } ) = \max _ { p \in C _ { 1 } , p ^ { * } \in C _ { j } \vert p - p ^ { \prime } \vert$

Distance Between Centroids: $d _ { m e a n } ( C _ { i } , C _ { j } ) = \vert m _ { i } - m _ { j } \vert$

Group Average: $d _ { a v g } ( C _ { i } , C _ { j } ) = \sum _ { p \in C i } \sum _ { p ^ { \prime } \in C j \vert p - p ^ { \prime } \vert / n _ { i } n _ { j }$

其中，$\vert p - p ^ { \prime } \vert$是两个对象p和p＇之间的距离，m；是簇$C _ { i }$的平均值，$n _ { i }$是簇$C _ { i }$中对象的数目

<!-- Cluster A Cluster B  -->
![](https://web-api.textin.com/ocr_image/external/e6bb48596d93b575.jpg)

<!-- Cluster B  -->
![](https://web-api.textin.com/ocr_image/external/18eedf72f4d01340.jpg)

<!-- 4 3 5 Cluster B Cluster A 1 2  -->
![](https://web-api.textin.com/ocr_image/external/814acc33a2f3b312.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/0b4f0ce29ac76b97.jpg)

XIAN HAOIOSGLNIVERSIEY

### 6.4层次方法

#### 例子 - Single Link


![](https://web-api.textin.com/ocr_image/external/666aea866e52957f.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/c34e5ab3f13cab69.jpg)

XIAN HAOIOSG LNIVIESIEY

### 6.4层次方法

#### 例子-Complete Link


![](https://web-api.textin.com/ocr_image/external/cae6d60f86a5d921.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/bf15267a0a1a3877.jpg)

XIAN HAOIOSG LNIVIESIY

### 6.4层次方法

#### 例子 - Single Link


![](https://web-api.textin.com/ocr_image/external/4019742f95b36450.jpg)


![](https://web-api.textin.com/ocr_image/external/971fe2deaf48c246.jpg)

优点：Can handle non-globular shapes

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1f32249430491faf.jpg)

XIAN JAOIONGLNIVIESIEY

### 6.4层次方法

#### 例子 - Single Link


![](https://web-api.textin.com/ocr_image/external/6ce2c892c2508007.jpg)


![](https://web-api.textin.com/ocr_image/external/7c328dc18c22d98c.jpg)


![](https://web-api.textin.com/ocr_image/external/52fbb5e3351b67a9.jpg)


![](https://web-api.textin.com/ocr_image/external/dfe5bd984c4813d8.jpg)


![](https://web-api.textin.com/ocr_image/external/fab6686382b7c7d2.jpg)

Original Points Four clusters Three clusters:

The yellow points got 缺点：Sensitive to noise and outliers red ones, as opposed to wrongly merged with the the green one.

西安交通大學


![](https://web-api.textin.com/ocr_image/external/112fd4632c59e9d2.jpg)

XIAN HAOIOSG LNIVIESIY

### 6.4层次方法

# 例子-Complete Link


![](https://web-api.textin.com/ocr_image/external/849119dab4193f90.jpg)


![](https://web-api.textin.com/ocr_image/external/67ea2591a8e5b584.jpg)

Original Points Two Clusters

缺点：Tends to break large clusters

西安交通大學


![](https://web-api.textin.com/ocr_image/external/5c2b396b6bc4752f.jpg)

XIAN HAOIOSG LNIVIRSIEY

## 6.4层次方法

## 例子

<table border="1" ><tr>
<td colspan="1" rowspan="1">点</td>
<td colspan="1" rowspan="1">x坐标</td>
<td colspan="1" rowspan="1">y坐标</td>
</tr><tr>
<td colspan="1" rowspan="1">pl</td>
<td colspan="1" rowspan="1">0.4005</td>
<td colspan="1" rowspan="1">0.5306</td>
</tr><tr>
<td colspan="1" rowspan="1">p2</td>
<td colspan="1" rowspan="1">0.2148</td>
<td colspan="1" rowspan="1">0.3854</td>
</tr><tr>
<td colspan="1" rowspan="1">p3</td>
<td colspan="1" rowspan="1">0.3457</td>
<td colspan="1" rowspan="1">0.3156</td>
</tr><tr>
<td colspan="1" rowspan="1">p4</td>
<td colspan="1" rowspan="1">0.2652</td>
<td colspan="1" rowspan="1">0.1875</td>
</tr><tr>
<td colspan="1" rowspan="1">p5</td>
<td colspan="1" rowspan="1">0.0789</td>
<td colspan="1" rowspan="1">0.4139</td>
</tr><tr>
<td colspan="1" rowspan="1">p6</td>
<td colspan="1" rowspan="1">0.4548</td>
<td colspan="1" rowspan="1">0.3022</td>
</tr></table>

<!-- 0.6 0.5 -1 0.4 *2 1 0.3 3 *G 0.2 - 0.1 60 0.1 0.2 0.3 0.4 0.5 0.6  -->
![](https://web-api.textin.com/ocr_image/external/b2d51154fe74533a.jpg)

<table border="1" ><tr>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">p1</td>
<td colspan="1" rowspan="1">p2</td>
<td colspan="1" rowspan="1">p3</td>
<td colspan="1" rowspan="1">p4</td>
<td colspan="1" rowspan="1">p5</td>
<td colspan="1" rowspan="1">p6</td>
</tr><tr>
<td colspan="1" rowspan="1">p1</td>
<td colspan="1" rowspan="1">0.0000</td>
<td colspan="1" rowspan="1">0.2357</td>
<td colspan="1" rowspan="1">0.2218</td>
<td colspan="1" rowspan="1">0.3688</td>
<td colspan="1" rowspan="1">0.3421</td>
<td colspan="1" rowspan="1">0.2347</td>
</tr><tr>
<td colspan="1" rowspan="1">p2</td>
<td colspan="1" rowspan="1">0.2357</td>
<td colspan="1" rowspan="1">0.0000</td>
<td colspan="1" rowspan="1">0.1483</td>
<td colspan="1" rowspan="1">0.2042</td>
<td colspan="1" rowspan="1">0.1388</td>
<td colspan="1" rowspan="1">0.2540</td>
</tr><tr>
<td colspan="1" rowspan="1">p3</td>
<td colspan="1" rowspan="1">0.2218</td>
<td colspan="1" rowspan="1">0.1483</td>
<td colspan="1" rowspan="1">0.0000</td>
<td colspan="1" rowspan="1">0.1513</td>
<td colspan="1" rowspan="1">0.2843</td>
<td colspan="1" rowspan="1">0.1100</td>
</tr><tr>
<td colspan="1" rowspan="1">p4</td>
<td colspan="1" rowspan="1">0.3688</td>
<td colspan="1" rowspan="1">0.2042</td>
<td colspan="1" rowspan="1">0.1513</td>
<td colspan="1" rowspan="1">0.0000</td>
<td colspan="1" rowspan="1">0.2932</td>
<td colspan="1" rowspan="1">0.2216</td>
</tr><tr>
<td colspan="1" rowspan="1">p5</td>
<td colspan="1" rowspan="1">0.3421</td>
<td colspan="1" rowspan="1">0.1388</td>
<td colspan="1" rowspan="1">0.2843</td>
<td colspan="1" rowspan="1">0.2932</td>
<td colspan="1" rowspan="1">0.0000</td>
<td colspan="1" rowspan="1">0.3921</td>
</tr><tr>
<td colspan="1" rowspan="1">p6</td>
<td colspan="1" rowspan="1">0.2347</td>
<td colspan="1" rowspan="1">0.2540</td>
<td colspan="1" rowspan="1">0.1100</td>
<td colspan="1" rowspan="1">0.2216</td>
<td colspan="1" rowspan="1">0.3921</td>
<td colspan="1" rowspan="1">0.0000</td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/048783a775de845a.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.4层次方法


![](https://web-api.textin.com/ocr_image/external/8ad7d0c319d3c696.jpg)

### Single linkage

dist({3,6},{2,5}) = min(dist(3, 2), dist(6, 2), dist(3,5), dist(6,5))

=min(0.15,0.25,0.28,0.39)

=0.15

<!-- ·1 2 3 5 5 2 1 6 4  -->
![](https://web-api.textin.com/ocr_image/external/d9d022e246ba6f13.jpg)

<!-- 0.2 0.15 0.1 0.05 0 3 6 2 5 4 1  -->
![](https://web-api.textin.com/ocr_image/external/d87a12a2ac823b56.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/5f6ee93348f5e41b.jpg)

XIAN HAOIONGLNIIESIEY

## 6.4层次方法

# Complete linkage

<table border="1" ><tr>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">p1</td>
<td colspan="1" rowspan="1">p2</td>
<td colspan="1" rowspan="1">p3</td>
<td colspan="1" rowspan="1">p4</td>
<td colspan="1" rowspan="1">p5</td>
<td colspan="1" rowspan="1">p6</td>
</tr><tr>
<td colspan="1" rowspan="1">p1</td>
<td colspan="1" rowspan="1">0.0000</td>
<td colspan="1" rowspan="1">0.2357</td>
<td colspan="1" rowspan="1">0.2218</td>
<td colspan="1" rowspan="1">0.3688</td>
<td colspan="1" rowspan="1">0.3421</td>
<td colspan="1" rowspan="1">0.2347</td>
</tr><tr>
<td colspan="1" rowspan="1">p2</td>
<td colspan="1" rowspan="1">0.2357</td>
<td colspan="1" rowspan="1">0.0000</td>
<td colspan="1" rowspan="1">0.1483</td>
<td colspan="1" rowspan="1">0.2042</td>
<td colspan="1" rowspan="1">0.1388</td>
<td colspan="1" rowspan="1">0.2540</td>
</tr><tr>
<td colspan="1" rowspan="1">p3</td>
<td colspan="1" rowspan="1">0.2218</td>
<td colspan="1" rowspan="1">0.1483</td>
<td colspan="1" rowspan="1">0.0000</td>
<td colspan="1" rowspan="1">0.1513</td>
<td colspan="1" rowspan="1">0.2843</td>
<td colspan="1" rowspan="1">0.1100</td>
</tr><tr>
<td colspan="1" rowspan="1">p4</td>
<td colspan="1" rowspan="1">0.3688</td>
<td colspan="1" rowspan="1">0.2042</td>
<td colspan="1" rowspan="1">0.1513</td>
<td colspan="1" rowspan="1">0.0000</td>
<td colspan="1" rowspan="1">0.2932</td>
<td colspan="1" rowspan="1">0.2216</td>
</tr><tr>
<td colspan="1" rowspan="1">p5</td>
<td colspan="1" rowspan="1">0.3421</td>
<td colspan="1" rowspan="1">0.1388</td>
<td colspan="1" rowspan="1">0.2843</td>
<td colspan="1" rowspan="1">0.2932</td>
<td colspan="1" rowspan="1">0.0000</td>
<td colspan="1" rowspan="1">0.3921</td>
</tr><tr>
<td colspan="1" rowspan="1">p6</td>
<td colspan="1" rowspan="1">0.2347</td>
<td colspan="1" rowspan="1">0.2540</td>
<td colspan="1" rowspan="1">0.1100</td>
<td colspan="1" rowspan="1">0.2216</td>
<td colspan="1" rowspan="1">0.3921</td>
<td colspan="1" rowspan="1">0.0000</td>
</tr></table>

dist({3,6}, {4}) = max(dist(3,4), dist(6,4))

=max(0.15,0.22)

=0.22

dist({3,6},{2,5})=max(dist(3,,2),dist(6, 2), dist(3,5),dist(6,5))

=max(0.15,,0.25,0.28,0.39)

=0.39

dist({3,6},{1})=max(dist(3,1),dist(6,1))

=max(0.22,0.23)

=0.23

西安交通大學


![](https://web-api.textin.com/ocr_image/external/615763da987ca016.jpg)

XIAN HAOIOSGLNIERSIEY

## 6.4层次方法

# Complete linkage

<!-- 4 ·1 2 5 5 2 3 3 6 1 4  -->
![](https://web-api.textin.com/ocr_image/external/a559793cd5df45c1.jpg)

<!-- 0.4 0.3 0.2 0.1 0 3 6 4 1 2 5  -->
![](https://web-api.textin.com/ocr_image/external/1fe6f317ea84d56e.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/319037559fe58bf7.jpg)

XIAN HAOIOSGLNIVIESIEY

## 6.4层次方法


![](https://web-api.textin.com/ocr_image/external/95c1bdf2d46e3d5d.jpg)

## Group Average

<table border="1" ><tr>
<td colspan="1" rowspan="1">点</td>
<td colspan="1" rowspan="1">x坐标</td>
<td colspan="1" rowspan="1">y坐标</td>
</tr><tr>
<td colspan="1" rowspan="1">pl</td>
<td colspan="1" rowspan="1">0.400 5</td>
<td colspan="1" rowspan="1">0.5306</td>
</tr><tr>
<td colspan="1" rowspan="1">p2</td>
<td colspan="1" rowspan="1">0.2148</td>
<td colspan="1" rowspan="1">0.3854</td>
</tr><tr>
<td colspan="1" rowspan="1">p3</td>
<td colspan="1" rowspan="1">0.3457</td>
<td colspan="1" rowspan="1">0.3156</td>
</tr><tr>
<td colspan="1" rowspan="1">p4</td>
<td colspan="1" rowspan="1">0.265 2</td>
<td colspan="1" rowspan="1">0.1875</td>
</tr><tr>
<td colspan="1" rowspan="1">p5</td>
<td colspan="1" rowspan="1">0.078 9</td>
<td colspan="1" rowspan="1">0.4139</td>
</tr><tr>
<td colspan="1" rowspan="1">p6</td>
<td colspan="1" rowspan="1">0.454 8</td>
<td colspan="1" rowspan="1">0.3022</td>
</tr></table>

## 画出聚类树？

<table border="1" ><tr>
<td colspan="1" rowspan="1"></td>
<td colspan="1" rowspan="1">p1</td>
<td colspan="1" rowspan="1">p2</td>
<td colspan="1" rowspan="1">p3</td>
<td colspan="1" rowspan="1">p4</td>
<td colspan="1" rowspan="1">p5</td>
<td colspan="1" rowspan="1">p6</td>
</tr><tr>
<td colspan="1" rowspan="1">p1</td>
<td colspan="1" rowspan="1">0.0000</td>
<td colspan="1" rowspan="1">0.2357</td>
<td colspan="1" rowspan="1">0.2218</td>
<td colspan="1" rowspan="1">0.3688</td>
<td colspan="1" rowspan="1">0.3421</td>
<td colspan="1" rowspan="1">0.2347</td>
</tr><tr>
<td colspan="1" rowspan="1">p2</td>
<td colspan="1" rowspan="1">0.2357</td>
<td colspan="1" rowspan="1">0.0000</td>
<td colspan="1" rowspan="1">0.1483</td>
<td colspan="1" rowspan="1">0.2042</td>
<td colspan="1" rowspan="1">0.1388</td>
<td colspan="1" rowspan="1">0.2540</td>
</tr><tr>
<td colspan="1" rowspan="1">p3</td>
<td colspan="1" rowspan="1">0.2218</td>
<td colspan="1" rowspan="1">0.1483</td>
<td colspan="1" rowspan="1">0.0000</td>
<td colspan="1" rowspan="1">0.1513</td>
<td colspan="1" rowspan="1">0.2843</td>
<td colspan="1" rowspan="1">0.1100</td>
</tr><tr>
<td colspan="1" rowspan="1">p4</td>
<td colspan="1" rowspan="1">0.3688</td>
<td colspan="1" rowspan="1">0.2042</td>
<td colspan="1" rowspan="1">0.1513</td>
<td colspan="1" rowspan="1">0.0000</td>
<td colspan="1" rowspan="1">0.2932</td>
<td colspan="1" rowspan="1">0.2216</td>
</tr><tr>
<td colspan="1" rowspan="1">p5</td>
<td colspan="1" rowspan="1">0.3421</td>
<td colspan="1" rowspan="1">0.1388</td>
<td colspan="1" rowspan="1">0.2843</td>
<td colspan="1" rowspan="1">0.2932</td>
<td colspan="1" rowspan="1">0.0000</td>
<td colspan="1" rowspan="1">0.3921</td>
</tr><tr>
<td colspan="1" rowspan="1">p6</td>
<td colspan="1" rowspan="1">0.2347</td>
<td colspan="1" rowspan="1">0.2540</td>
<td colspan="1" rowspan="1">0.1100</td>
<td colspan="1" rowspan="1">0.2216</td>
<td colspan="1" rowspan="1">0.3921</td>
<td colspan="1" rowspan="1">0.0000</td>
</tr></table>

西安交通大學


![](https://web-api.textin.com/ocr_image/external/5f6ee93348f5e41b.jpg)

XIAN HAOIOSGUNIVERSIEY

## 6.4层次方法


![](https://web-api.textin.com/ocr_image/external/9580e6531e389156.jpg)

## Group Average

dist([3,6,4],[1])=(0.22+0.37+0.23)/(3*1)

=0.28

disr([2,5],[1])=(0.2357+0.3421)/(2*1)

=0.2889

disr((3,6,4),(2,51)=(0.15+0.28+0.25+0.39+0.20+0.29)/(3+2)

= 0.26

<!-- 1 5 2 5 2 3 3 6 4 1 ·4  -->
![](https://web-api.textin.com/ocr_image/external/243aacc5267314d7.jpg)

<!-- 0.25 0.2 0.15 0.1 0.05 0 3 6 4 2 5 1  -->
![](https://web-api.textin.com/ocr_image/external/b6a92faf5a67f0bc.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/c91e877da07c6500.jpg)

XIAN HAOIONG LNIVIESIY

### 6.4层次方法

### 层次聚类的主要缺点

✓不具有很好的可扩展性：时间复杂性至少是$O ( n ^ { 2 } ) ,$，其中n 对象总数

✓合并或分裂的决定需要检查和估算大量的对象或簇

✓不能撤消已做的处理，聚类之间不能交换对象.如果某一步没有很好地选择合并或分裂的决定，可能会导致低质量的聚类结果

西安交通大學


![](https://web-api.textin.com/ocr_image/external/1fdab953a6daec61.jpg)

XIAN HAOIOSG LNIVIESIEY

#### 6.4层次方法

改进层次聚类质量的方法：将层次聚类和其他的聚类技术进行集成，形成多阶段聚类

BIRCH（1996）：使用CF-tree对对象进行层次划分，然后采用其他的聚类算法对聚类结果进行求精

ROCK1999：基于簇间的互联性进行合并

CHAMELEON（1999）：使用动态模型进行层次聚类

✓CURE（1998）：采用固定数目的代表对象来表示每个簇，然后依据一个指定的收缩因子向着聚类中心对它们进行收缩

西安交通大學


![](https://web-api.textin.com/ocr_image/external/f12b37805d8bece9.jpg)

XIAN HAOIOSG LNIVIESIEY

6.1 什么是聚类分析

6.2 聚类分析中的数据类型

6.3 划分方法

6.4 层次方法

6.5 基于密度的方法

西安交通大學


![](https://web-api.textin.com/ocr_image/external/41407e9bf4abc802.jpg)

XIAN HAOIONG LNIVIESIEY

#### 6.5基于密度的方法

基于密度的聚类：把簇看做数据空间中被 区域分开的 密区域


![](https://web-api.textin.com/ocr_image/external/2fd48bd39e5b7c93.jpg)

能发现任意形状的簇


![](https://web-api.textin.com/ocr_image/external/9b392309e743e355.jpg)


![](https://web-api.textin.com/ocr_image/external/204ea97913a8f66d.jpg)


![](https://web-api.textin.com/ocr_image/external/bb40bf2e3b1de2db.jpg)

不需要事先确定划分的聚类个数k


![](https://web-api.textin.com/ocr_image/external/f1c444207c1efdf3.jpg)

对噪音数据不


![](https://web-api.textin.com/ocr_image/external/6f196da76e7734a2.jpg)

需要密度参数作为 条件

典型算法


![](https://web-api.textin.com/ocr_image/external/54e72bb8c0ba92ed.jpg)

DBSCAN: Ester, et al. (KDD'96)


![](https://web-api.textin.com/ocr_image/external/e4c51975818f17df.jpg)

OPTICS: Ankerst, et al (SIGMOD'99).


![](https://web-api.textin.com/ocr_image/external/00b28d18f645411c.jpg)

DENCLUE:Hinneburg & D. Keim (KDD'98)


![](https://web-api.textin.com/ocr_image/external/d298992c03e490a4.jpg)

CLIQUE: Agrawal, et al. (SIGMOD'98) (more grid-based)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/a285d518b17c285e.jpg)

XIAN HAOIOSGLNIVERSIEY

#### 6.5基于密度的方法-DBSCAN

DBSCAN: Density-Based Spatial Clustering of Applications with Noise

假设：一个簇能够被其中任意一个 心对象所确定

基本 ：考察数据库 D中的 心对象 P，则通过区域查 得到该对象的 域， 域中的对象和P同属于一个簇，这些对象将作为下一 的考察对象，并通过不断地对种子对象进行区域查 来扩展它们所在的簇，直至 到一个完整的簇

西安交通大學


![](https://web-api.textin.com/ocr_image/external/956f30374385f374.jpg)

XIAN HAOIOSG LNIVIESIEY

#### 6.5 基于密度的方法-DBSCAN

## 两个参数


![](https://web-api.textin.com/ocr_image/external/2ca5c58a7257fdf9.jpg)

ε：数据对象的 域半

MinPts: 密区域的密度 值，域的密度是指 域内的对象数

## 定义

✓核心对象：如果一个数据对象的ε-邻域至少包含MinPts个对象，则该对象为 心对象。

p是核心对象（MinPts＝4）

<!-- ε ε q P  -->
![](https://web-api.textin.com/ocr_image/external/b09569b3bebac7f8.jpg)

q不是核心对象

西安交通大學

XIAN JAOIOSGLNIERSIEY

## 6.5 基于密度的方法-DBSCAN

## 定义

✓直接密度可 的（Directly density-reachable）：如果p是从q（关于ε与MinPts）直接密度可 的，当且仅当q是心对象，并且p在q的ε-邻域。

q是从p直接密度可达的

<!-- ε ε 9 P  -->
![](https://web-api.textin.com/ocr_image/external/c65f3c6d5923d3ad.jpg)

p不是从q直接密度可达的？

西安交通大學


![](https://web-api.textin.com/ocr_image/external/0d6e005d4185762a.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.5基于密度的方法-DBSCAN

## 定义

✓密度可的（Density-reachable）：如果存在一个对象$p _ { 1 } , \cdots , p _ { n } ,$使得$p _ { 1 } = p , p _ { n } = q ,$并且对于pi(1&lt;=i&lt;n),$p _ { i + 1 }$是从Pi（关于ε与MinPts）直接密度可 的，则q是从p密度可的。

q是从p密度可 的

p不是从q直接密度可 的？

<!-- q P  -->
![](https://web-api.textin.com/ocr_image/external/eebbc0d08f388804.jpg)

密度可 不是等价关系因为不是对称的

西安交通大學


![](https://web-api.textin.com/ocr_image/external/4d266bfd5bcbb1a9.jpg)

XIAN HAOIOSGUNIVERSIEY

## 6.5基于密度的方法 - DBSCAN

## 定义

# 密度可 是直接密度可 的传递 包，是可传递的，但不

对称性，只有 心对象之间的密度可 关系 对称性。

一个基于密度的簇是基于密度可 性的最大的密度相连对象的集合，不包含在任何簇中的对象被认为是噪声点

西安交通大學


![](https://web-api.textin.com/ocr_image/external/0d6e005d4185762a.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.5基于密度的方法-DBSCAN

# 例子（MinPts＝3）

✓q是从p密度可；p不是从q密度可（q非心）

✓s和r从o密度？；o从r密度？；

✓r，s，o密度相连

<!-- q m p r 0  -->
![](https://web-api.textin.com/ocr_image/external/48a204737158d2f3.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/5c2b396b6bc4752f.jpg)

XIAN JAOIOSGUNIVIRSIEY

## 6.5 基于密度的方法-DBSCAN

## 定义


![](https://web-api.textin.com/ocr_image/external/4fb8c36fb71dca7e.jpg)

✓边界点：对象ε-邻域内的样本点数小于MinPts，但是其位于某个 心对像ε-邻域内。

✓噪声点：非 心点也非边界点的任何点。

<!-- 噪声点 边界点 核心对象 ε=1 M∈Pts=5  -->
![](https://web-api.textin.com/ocr_image/external/d87de007b27904a8.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/954b25ec7b079b82.jpg)

XIAN HAOIOSGLNIVIESIEY

## 6.5基于密度的方法-DBSCAN

## 算法描述：

1．选择任意点P

2．如果P未被分类，那么检查 心点条件

3．如果为 心点，到所有由P关于ε，MinPts密度可点

4．用这些点形成一个新簇，给每一个点分配一个簇ID（同一个簇中的所有点 有相同的簇ID）

西安交通大學


![](https://web-api.textin.com/ocr_image/external/f12b37805d8bece9.jpg)

XIAN HAOIONG LNIVIESIEY

## 6.5 基于密度的方法-DBSCAN

## 算法描述：

5．如果点P为非 心点（即没有从P密度可 的点），则继续访问数据中的下一个点

6．继续这个过程，直到处理完所有点为


![](https://web-api.textin.com/ocr_image/external/3fca0ff455495ff2.jpg)


![](https://web-api.textin.com/ocr_image/external/7b0f6fd9345be68d.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/0d6e005d4185762a.jpg)

XIAN HAOIOSG LNIVIESIY

## 6.5 基于密度的方法-DBSCAN

# 例子：

If Epsilon is 2 and minpoint is 2, what are the clusters that DBScan would discover with the following 8

examples:A1=(2,10),A2=(2,5),A3=(8,4),A4=(5,8),

A5=(7,5),A6=(6,4),A7=(1,2),A8=(4,9).·

discovered clusters. What if Epsilon is increased to square root10?

西安交通大學


![](https://web-api.textin.com/ocr_image/external/112fd4632c59e9d2.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.5基于密度的方法-DBSCAN

What is the Epsilon neighborhood of each point?

N2(A1)={};N2(A2)={};N2(A3)={A5,A6};

N2(A4)={A8};N2(A5)={A3,A6};

N2(A6)={A3,A5};N2(A7)={};N2(A8)={A4}

西安交通大學


![](https://web-api.textin.com/ocr_image/external/0d6e005d4185762a.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.5基于密度的方法-DBSCAN

# So A1, A2, and A7 are outliers, while we have two clustersCl={A4,A8}andC2={A3,A5,A6}

<!-- 10 A1 9 A8 8 A4 7 6 5 A2 A5 4 A6 A3 3 2 A7 1 0 0 1 2 3 4 5 6 7 8 9 1  -->
![](https://web-api.textin.com/ocr_image/external/5ff6e563a8762f5e.jpg)

Epsilon=2

西安交通大學


![](https://web-api.textin.com/ocr_image/external/b7536feca64f934e.jpg)

XIAN HAOIOSGLNIVIESIEY

## 6.5基于密度的方法-DBSCAN

If Epsilon is square root 10 then the neighborhood of some points will increase:

examples:A1=(2,10),A2=(2,5),A3=(8,4),A4=(5,8),

A5=(7,5), A6=(6,4),A7=(1,2),A8=(4,9).·


![](https://web-api.textin.com/ocr_image/external/9df58942ddb8e286.jpg)

西安交通大學


![](https://web-api.textin.com/ocr_image/external/21a0142c532b2dc4.jpg)

XIAN HAOIOSG LNIVIESIEY

<!-- 10 A1 9 A8 8 A4 7 6 5 A2 A5 4 A6 A3 3 2 A7 1 0 0 1 2 3 4 5 6 7 8 9 1  -->
![](https://web-api.textin.com/ocr_image/external/884c8b37d292e830.jpg)

$E p \sin \omega = \sqrt { 1 0 }$

西安交通大學


![](https://web-api.textin.com/ocr_image/external/d3eb27cfede8f74e.jpg)

XIAN HAOIOSG LNIVIESIY

## 6.5 基于密度的方法-DBSCAN

## 点：


![](https://web-api.textin.com/ocr_image/external/b13f6e058a9b2a93.jpg)

相对 噪声，并且能够处理任意形状和大小的簇，可以自动确定形成的簇数

## 缺点：

✓对于簇密度变化较大或高维数据时，密度定义会比较

近 计算需要计算所有点对的 近度，因此开销较大（采用空间 引，复杂度为O（nlog n），否则为O（n2））


![](https://web-api.textin.com/ocr_image/external/b7e0a1589611a27b.jpg)

DBSCAN算法对参数ε及Minpts非常敏感

西安交通大學


![](https://web-api.textin.com/ocr_image/external/01abc2a6b65e46e1.jpg)

XIAN HAOIOSG LNIVIESIY

## 6.5基于密度的方法-DBSCAN

Epsilon 与minpoint 对结果的影响？

<!-- O 8 。  -->
![](https://web-api.textin.com/ocr_image/external/2c056e37742bbe41.jpg)

https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/

西安交通大學


![](https://web-api.textin.com/ocr_image/external/5750dac58e333f0f.jpg)

XIAN HAOIOSG LNIVIESIEY

## 6.5基于密度的方法-DBSCAN


![](https://web-api.textin.com/ocr_image/external/e3d13ad240d37b69.jpg)

## 对参数具有 性

Figure 8.DBScan results for DS1 with MinPts at 4 and Eps at (a)0.5 and (b)0.4.


![](https://web-api.textin.com/ocr_image/external/0112b9140c690035.jpg)


![](https://web-api.textin.com/ocr_image/external/471c8082f9c3f8bf.jpg)

Figure 9.DBScan results for DS2 with MinPts at 4 and Eps at (a)5.0,(b)3.5,and (c)3.0.

(a) (b)


![](https://web-api.textin.com/ocr_image/external/37001c4faf2673ce.jpg)


![](https://web-api.textin.com/ocr_image/external/238e123b8027d4ba.jpg)


![](https://web-api.textin.com/ocr_image/external/2bef880380953009.jpg)

(a) (b) (c)

## From Jiawei Han and Micheline Kamber's PPT

西安交通大學


![](https://web-api.textin.com/ocr_image/external/3d5b7172d1fe871f.jpg)

XIAN HAOIOSGLNIVERSIEY

## 6.5基于密度的方法-DBSCAN

如何确定Minpts和ε

点到它的第k个最近 的 离，称为k-距离

对于簇内的点，其k-距离较小；对于不在簇中的点，其k-距离相对较大

<!-- 50 45 ①ueIsIO o등beN 7SeJeeN 导 40 35 30 25 20 15 10 5 00 500 1000 1500 2000 2500 3000 Points Sorted According to Distance of 4th Nearest Neighbor  -->
![](https://web-api.textin.com/ocr_image/external/1742d8e8735d6e1e.jpg)

对所有点的k-距离以递增排序，绘制排序后的值。

k-距离 变化点对应于合适的ε值，取k做为Minpts的值。

用此方法确定的ε值取决于k，但并不会随k 变而 变化。

西安交通大學


![](https://web-api.textin.com/ocr_image/external/33347b3ac3ddf228.jpg)

XIAN HAOIONG LNIVIESIY

Cluster analysis groups objects based on their similarity and has wide applications

Measure of similarity can be computed for various types of data

Clustering algorithms can be categorized into partitioning methods, hierarchical methods, density-based methods, grid-based methods, and model-based methods

K-means and K-medoids algorithms are popular partitioning-based clustering algorithms

AGNES and DIANA are interesting hierarchical clustering algorithms

DBSCAN, OPTICS are interesting density-based algorithms

Quality of clustering results can be evaluated in various ways

西安交通大學

XIAN JAOIOSGLNIVIESIEY

